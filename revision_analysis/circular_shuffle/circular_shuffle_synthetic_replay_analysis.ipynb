{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import + functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "136_1_3\n",
      "chunk1_8700to9300\n",
      "chunk2_10000to11600\n",
      "chunk3_11900to12500\n",
      "1\n",
      "136_1_4\n",
      "chunk1_7600to8200\n",
      "chunk2_8800to9400\n",
      "chunk3_9950to10550\n",
      "2\n",
      "148_2_2\n",
      "chunk1_3000to4000\n",
      "chunk2_4000to5000\n",
      "chunk3_5000to6000\n",
      "3\n",
      "149_1_1\n",
      "chunk1_8300to9300\n",
      "chunk2_9600to10600\n",
      "chunk3_12600to13600\n",
      "4\n",
      "178_1_4\n",
      "chunk1_7500to8100\n",
      "chunk2_8500to9100\n",
      "chunk3_9500to10100\n",
      "5\n",
      "178_1_5\n",
      "chunk1_8000to8600\n",
      "chunk2_9000to9600\n",
      "chunk3_12200to12800\n",
      "6\n",
      "178_1_6\n",
      "chunk1_8600to9300\n",
      "chunk2_10000to10600\n",
      "chunk3_12000to12600\n",
      "7\n",
      "178_1_7\n",
      "chunk1_8300to10000\n",
      "chunk2_10500to11200\n",
      "chunk3_13300to14300\n",
      "8\n",
      "178_1_8\n",
      "chunk1_11300to12000\n",
      "chunk2_13200to13800\n",
      "chunk3_16400to17000\n",
      "9\n",
      "178_1_9\n",
      "chunk1_9000to9900\n",
      "chunk2_10100to10700\n",
      "chunk3_11300to11900\n",
      "10\n",
      "178_2_1\n",
      "chunk1_8500to9200\n",
      "only 3 seqs\n",
      "chunk2_9900to10500\n",
      "only 3 seqs\n",
      "chunk3_14000to14600\n",
      "only 3 seqs\n",
      "11\n",
      "178_2_2\n",
      "chunk1_12300to12900\n",
      "chunk2_13600to14200\n",
      "chunk3_15400to16000\n",
      "12\n",
      "178_2_3\n",
      "chunk1_9500to10500\n",
      "chunk2_11800to12800\n",
      "chunk3_13000to14000\n",
      "!!!!!\n",
      "13\n",
      "178_2_4\n",
      "chunk1_9700to10500\n",
      "chunk2_11500to12100\n",
      "chunk3_14000to14400\n",
      "chunk4_15600to16000\n",
      "17\n",
      "255_1_1\n",
      "chunk1_7350to8350\n",
      "chunk2_8900to9900\n",
      "chunk3_10900to11900\n",
      "18\n",
      "255_1_2\n",
      "chunk1_4900to5900\n",
      "only 3 seqs\n",
      "chunk2_6200to7200\n",
      "only 3 seqs\n",
      "chunk3_8500to9500\n",
      "only 3 seqs\n",
      "19\n",
      "255_1_4\n",
      "chunk1_8000to9000\n",
      "chunk2_10500to11500\n",
      "chunk3_12700to13700\n",
      "!!!!!\n",
      "20\n",
      "256_1_1\n",
      "chunk1_9500to10500\n",
      "only 3 seqs\n",
      "chunk2_11700to12700\n",
      "chunk3_14300to15300\n",
      "21\n",
      "262_1_1\n",
      "chunk1_8900to9900\n",
      "chunk2_10300to11300\n",
      "chunk3_12000to13000\n",
      "!!!!!\n",
      "22\n",
      "262_1_2\n",
      "chunk1_12000to13000\n",
      "chunk2_14000to15000\n",
      "chunk3_16000to17000\n",
      "23\n",
      "262_1_4\n",
      "chunk1_10000to11000\n",
      "chunk2_11000to12000\n",
      "chunk3_14000to15000\n",
      "24\n",
      "262_1_5\n",
      "chunk1_14000to15000\n",
      "chunk2_15500to16500\n",
      "chunk3_18500to19500\n",
      "25\n",
      "262_1_6\n",
      "chunk1_8500to9500\n",
      "chunk2_11000to12000\n",
      "chunk3_13000to14000\n",
      "26\n",
      "268_1_2\n",
      "chunk1_9000to10000\n",
      "chunk2_11200to12200\n",
      "chunk3_14000to15000\n",
      "27\n",
      "269_1_1\n",
      "chunk1_7900to8900\n",
      "chunk2_10000to11000\n",
      "chunk3_13000to14000\n",
      "28\n",
      "269_1_2\n",
      "chunk1_8500to9500\n",
      "chunk2_10000to11000\n",
      "chunk3_12000to13000\n",
      "29\n",
      "269_1_3\n",
      "chunk1_8000to9000\n",
      "chunk2_9000to10000\n",
      "chunk3_11500to12500\n",
      "30\n",
      "269_1_4\n",
      "chunk1_8000to9000\n",
      "chunk2_10500to11500\n",
      "chunk3_11500to12500\n",
      "33\n",
      "269_1_7\n",
      "chunk1_9000to10000\n",
      "chunk2_12000to13000\n",
      "chunk3_16000to17000\n",
      "34\n",
      "270_1_1\n",
      "chunk1_9000to10000\n",
      "chunk2_10200to11200\n",
      "chunk3_13000to14000\n",
      "!!!!!\n",
      "35\n",
      "270_1_3\n",
      "chunk1_9100to10100\n",
      "chunk2_10200to11200\n",
      "chunk3_12000to13000\n",
      "36\n",
      "270_1_5\n",
      "chunk1_8300to9300\n",
      "chunk2_9300to10300\n",
      "chunk3_11800to12800\n",
      "!!!!!\n",
      "37\n",
      "270_1_6\n",
      "chunk1_7000to8000\n",
      "chunk2_11000to12000\n",
      "chunk3_16000to17000\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "# ignore_list = ['269_1_5','269_1_6','270_1_1','178_2_3']\n",
    "ignore_list = ['269_1_5','269_1_6']\n",
    "\n",
    "\n",
    "dat_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\paper_submission\\post_sleep\\\\\"\n",
    "\n",
    "## set up empty vars \n",
    "mirs = []\n",
    "\n",
    "expert = []\n",
    "hlesion = []\n",
    "learning = []\n",
    "\n",
    "\n",
    "# 1\n",
    "reactivations_per_min = []\n",
    "# 2\n",
    "event_rate_binned = []\n",
    "er_bins_relative_to_so = []\n",
    "# 3\n",
    "event_lens = []\n",
    "# 4\n",
    "av_coactive_len_per_chunk = []\n",
    "\n",
    "e_coactive_freqs_counts = {}\n",
    "hl_coactive_freqs_counts = {}\n",
    "l_coactive_freqs_counts = {}\n",
    "\n",
    "all_total_events = []\n",
    "rel_task_nontask = []\n",
    "chunks_task_nontask = []\n",
    "\n",
    "task_nontask_num_spikes = []\n",
    "task_nontask_e_len = []\n",
    "\n",
    "chunk_expert = []\n",
    "chunk_mid_time_post_onset = []\n",
    "#5 \n",
    "mouse_summed_amounts = []\n",
    "ordered_sum = []\n",
    "ordered_misordered_total = []\n",
    "\n",
    "\n",
    "# warps = []\n",
    "\n",
    "\n",
    "# loop across all mouse files\n",
    "for run_index,pp_file in enumerate(os.listdir(dat_path)):\n",
    "    if not 'sleep_time_points' in pp_file:\n",
    "        # current mouse\n",
    "        mouse = '_'.join(pp_file.split('_')[0:3])\n",
    "        \n",
    "        if not mouse in ignore_list:\n",
    "\n",
    "            # if session in one of the groups (and define which)   \n",
    "            if mouse in list(expert_mice) + list(hlesion_mice) + list(learning_mice):\n",
    "                if mouse in expert_mice:\n",
    "                    expert += [1]\n",
    "                    hlesion += [0]\n",
    "                    learning += [0]               \n",
    "                elif mouse in hlesion_mice:                \n",
    "                    expert += [0]\n",
    "                    hlesion += [1]\n",
    "                    learning += [0]\n",
    "                elif mouse in learning_mice:                \n",
    "                    expert += [0]\n",
    "                    hlesion += [0]\n",
    "                    learning += [1]\n",
    "\n",
    "                print(run_index)\n",
    "\n",
    "                print(mouse)\n",
    "\n",
    "\n",
    "\n",
    "                # load in sleep start time \n",
    "                current_sleep_start = sleep_start[mouse]\n",
    "                params_file = dat_path + pp_file + r'\\trainingData\\\\' + 'params_' + mouse + '.json'\n",
    "                with open(params_file, 'r') as file:\n",
    "                    params = json.load(file)\n",
    "                time_spans = params['time_span']\n",
    "\n",
    "                # set path to processed files \n",
    "                current_mouse_path = dat_path + pp_file + '\\\\analysis_output'\n",
    "                mirs += [mouse]\n",
    "\n",
    "                ## set chunk vars \n",
    "                #1\n",
    "                chunk_rpm = []\n",
    "    #             chunk_warps = []\n",
    "                #2\n",
    "                chunk_binned_rate = []\n",
    "                chunk_bins_relative_so = []\n",
    "                #3\n",
    "                chunk_event_lens = []\n",
    "\n",
    "                #4\n",
    "                coactive_freqs_chunk  = {}\n",
    "                chunk_total_nontask_task_related_events = []\n",
    "                total_events = 0\n",
    "                chunk_task_num_spikes = []\n",
    "                chunk_nontask_num_spikes = []\n",
    "                chunk_task_e_len = []\n",
    "                chunk_nontask_e_len = []\n",
    "\n",
    "                #5\n",
    "                chunk_summed_amounts = []\n",
    "                chunk_ordered_sum = 0\n",
    "                chunk_coactive_total = 0\n",
    "                \n",
    "                \n",
    "                task_related = 0\n",
    "                non_task_related = 0\n",
    "\n",
    "                ## lopp across all chunk files\n",
    "                for file in os.listdir(current_mouse_path):\n",
    "                    if 'chunk' in file:\n",
    "                        print(file)\n",
    "                        current_data_path = current_mouse_path + '\\\\' + file + '\\\\'\n",
    "                        chunk_time = np.load(current_data_path + 'chunk_time_interval.npy')\n",
    "                        data = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "\n",
    "                        ## filter this data\n",
    "                        if sequential_filter == True: \n",
    "                            sequential_condition = data.ordering_classification == 'sequential'\n",
    "                        else:\n",
    "                            sequential_condition = np.array([True]*len(data.ordering_classification))\n",
    "\n",
    "                        if sleep_filters_on == True:\n",
    "                            if nrem_filter == True: \n",
    "                                nrem_condition = nrem__condition = data.nrem_events == 1\n",
    "                            else:\n",
    "                                nrem_condition = np.array([False]*len(data.nrem_events))\n",
    "\n",
    "                            if rem_filter == True: \n",
    "                                rem_condition = rem__condition = data.rem_events == 1\n",
    "                            else:\n",
    "                                rem_condition = np.array([False]*len(data.rem_events))\n",
    "\n",
    "                            if background_only == True:\n",
    "                                rem_condition = rem__condition = data.rem_events == 0\n",
    "                                nrem_condition = nrem__condition = data.nrem_events == 1\n",
    "\n",
    "                        else:\n",
    "                            nrem_condition = np.array([True]*len(data))\n",
    "                            rem_condition = np.array([True]*len(data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # filter is set up so that any true will carry forward \n",
    "                        filter_mask = sequential_condition * (nrem_condition + rem_condition)\n",
    "\n",
    "                        filtered_chunk_data = data[filter_mask].reset_index()\n",
    "\n",
    "\n",
    "                        # save out data\n",
    "                        reactivations_found = len(filtered_chunk_data)\n",
    "\n",
    "\n",
    "\n",
    "                        # this one depends on rem/nrem filter... \n",
    "\n",
    "    #                         # if sleep_filters_on is false, use all chunk time\n",
    "                        if sleep_filters_on == False:\n",
    "                            mins = np.diff(chunk_time)[0]\n",
    "                        else:\n",
    "                            # load in state times\n",
    "                            rem_state_times = np.load(current_data_path + 'rem_state_times.npy')\n",
    "                            nrem_state_times = np.load(current_data_path + 'nrem_state_times.npy')\n",
    "                            if len(rem_state_times) > 0:\n",
    "                                tot_rem = sum(np.diff(rem_state_times))[0]\n",
    "                            else:\n",
    "                                tot_rem = 0\n",
    "                            if len(nrem_state_times) > 0:\n",
    "                                tot_nrem = sum(np.diff(nrem_state_times))[0]\n",
    "                            else:\n",
    "                                tot_nrem = 0\n",
    "\n",
    "                            # if background then use all non rem an dnon nrem times\n",
    "                            if background_only:\n",
    "                                mins = np.diff(chunk_time)[0] - (tot_rem+tot_nrem)\n",
    "                            else:\n",
    "                                # if both, use both \n",
    "                                if nrem_filter == True and rem_filter == True:\n",
    "                                    mins = tot_rem+tot_nrem\n",
    "                                elif nrem_filter == True and rem_filter == False:\n",
    "                                    mins = tot_nrem\n",
    "                                elif nrem_filter == False and rem_filter == True:\n",
    "                                    mins = tot_rem\n",
    "                        # convert to mins            \n",
    "                        mins = mins/60\n",
    "\n",
    "                        if mins > 0:\n",
    "                            chunk_rpm += [reactivations_found/mins]\n",
    "\n",
    "                        #2################################\n",
    "\n",
    "#                             current_sleep_start = sleep_start[mouse] - 400\n",
    "                            chunk_number = int(file.split('_')[0][-1])\n",
    "                            start_offset = ([0]+list(np.cumsum(np.diff(time_spans))))[chunk_number-1]\n",
    "\n",
    "\n",
    "                            # take away cumulative chunk offset - this gives time in terms of chunk\n",
    "                            f_spike_times = filtered_chunk_data.first_spike_time.values - start_offset\n",
    "                            # add on ephys time that chunk started - so its in ephys timestamps \n",
    "                            f_spike_times = f_spike_times + chunk_time[0]\n",
    "\n",
    "                            # now make relative to sleep start time\n",
    "                            f_spike_times_relative_to_so = f_spike_times - current_sleep_start \n",
    "                            # do the same but for rem and nrem start\n",
    "\n",
    "                            # filter out anything that happened before sleep onset\n",
    "                            f_spike_times_relative_to_so = f_spike_times_relative_to_so[f_spike_times_relative_to_so > 0]\n",
    "\n",
    "                            ## calculate rate over time:\n",
    "                            time_data = pd.Series(f_spike_times_relative_to_so)\n",
    "                            if len(time_data) > 0:\n",
    "#                                 # Calculate the number of bins required # 5 minute bins\n",
    "#                                 num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "#                                 # Create bins and count the occurrences in each bin\n",
    "#                                 chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "#                                 #remove extra final bin and convert to mins\n",
    "#                                 chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "                                # Calculate the number of bins required # 20s bins\n",
    "                            #     num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "                                if time_data.max() - time_data.min() > 19:\n",
    "                                    num_bins = int((time_data.max() - time_data.min())//20)\n",
    "                                    # Create bins and count the occurrences in each bin\n",
    "                                    chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "                                    #remove extra final bin and convert to mins\n",
    "                                    chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "\n",
    "                                    chunk_binned_rate += [list((chunk_event_rate*3).astype(float))] # *3 because its per 20s so we want it per minute )\n",
    "                                    chunk_bins_relative_so += [list(chunk_relative_time_bins.astype(float))]\n",
    "\n",
    "                        \n",
    "                        #3########################################################\n",
    "\n",
    "                        chunk_event_lens += list(filtered_chunk_data.event_length.values)\n",
    "\n",
    "                        #4 ################################################# coactive stuff -300ms = coactive\n",
    "                        event_proximity_filter =  0.3 #s (how close events have to be to each other to be clustered together as coacitve \n",
    "\n",
    "                        task_seqs = np.load(current_data_path + 'task_order_seqs.npy')+1\n",
    "            \n",
    "                        for motif_type in filtered_chunk_data.cluster_seq_type:\n",
    "                            if motif_type in task_seqs:\n",
    "                                task_related += 1\n",
    "                            else:\n",
    "                                non_task_related += 1\n",
    "        \n",
    "                        total_events += len(filtered_chunk_data.cluster_seq_type)\n",
    "\n",
    "                        # normalise by number of each type: \n",
    "#                         if (6-len(task_seqs)) == 0:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "#                         else:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]\n",
    "\n",
    "                        chunk_mid_time_post_onset += [((sum(chunk_time)/2)-current_sleep_start)]\n",
    "\n",
    "                        ### ignore the origonal clusterg rosp and remake them: \n",
    "                        start_times = filtered_chunk_data.first_spike_time.values\n",
    "                        end_times = filtered_chunk_data.last_spike_time.values\n",
    "\n",
    "                        clustered_events = cluster_events(start_times, end_times,event_proximity_filter)\n",
    "\n",
    "                        cluster_group = np.zeros(len(filtered_chunk_data))\n",
    "                        for index,cluster in enumerate(clustered_events):\n",
    "                            for item in cluster:\n",
    "                                cluster_group[item] = int(index)\n",
    "                        filtered_chunk_data['coactive_cluster_group'] = cluster_group\n",
    "\n",
    "                        # work out how mnay coacitve in chunk: \n",
    "                        current_coactive_freqs_chunk = {}\n",
    "                        for cluster in filtered_chunk_data.coactive_cluster_group.unique():\n",
    "                            num = list(filtered_chunk_data.coactive_cluster_group.values).count(cluster)\n",
    "                            if num in current_coactive_freqs_chunk:\n",
    "                                current_coactive_freqs_chunk[num] += 1\n",
    "                            else:\n",
    "                                current_coactive_freqs_chunk[num] = 1\n",
    "\n",
    "                        avs =[]\n",
    "                        for item in current_coactive_freqs_chunk:\n",
    "                            avs += current_coactive_freqs_chunk[item] * [item]\n",
    "                        av_coactive_len_per_chunk += [np.mean(avs)]\n",
    "                        if mouse in expert_mice:\n",
    "                            chunk_expert += [1]\n",
    "                        elif mouse in hlesion_mice:\n",
    "                            chunk_expert += [2]\n",
    "                        elif mouse in learning_mice:\n",
    "                            chunk_expert += [3]\n",
    "\n",
    "\n",
    "                        # make it relative:\n",
    "                        current_coactive_freqs_chunk = relative_dict(current_coactive_freqs_chunk)\n",
    "\n",
    "                        coactive_freqs_keys = list(current_coactive_freqs_chunk.keys())\n",
    "                        rel_coactive_freqs = list(current_coactive_freqs_chunk.values())\n",
    "                        for index,item in enumerate(rel_coactive_freqs):\n",
    "                            num = int(coactive_freqs_keys[index])\n",
    "                            if num in coactive_freqs_chunk:\n",
    "                                coactive_freqs_chunk[num] += [item]\n",
    "                            else:\n",
    "                                coactive_freqs_chunk[num] = [item]\n",
    "\n",
    "\n",
    "                        task_events = filtered_chunk_data[filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "                        non_task_events = filtered_chunk_data[~filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "\n",
    "                        chunk_task_num_spikes+=list(task_events.num_spikes)\n",
    "                        chunk_nontask_num_spikes+=list(non_task_events.num_spikes)\n",
    "                        chunk_task_e_len+=list(task_events.event_length)\n",
    "                        chunk_nontask_e_len+=list(non_task_events.event_length)\n",
    "\n",
    "\n",
    "                        # 5 ##############################################################################\n",
    "\n",
    "                        ############################################## split into multi clusters and process\n",
    "\n",
    "                        multi_cluster_df = pd.DataFrame({'cluster_seq_type':[],\n",
    "                         'num_spikes':[],\n",
    "                         'num_neurons':[],\n",
    "                         'first_spike_time':[],\n",
    "                         'event_length':[],\n",
    "                         'last_spike_time':[],\n",
    "                         'cluster_spike_times':[],\n",
    "                         'cluster_neurons':[],\n",
    "                         'spike_plotting_order':[],\n",
    "                         'coactive_cluster_group':[],\n",
    "                         'new_cluster_group':[],\n",
    "                         'cluster_order_first_spike_defined':[],\n",
    "                         'cluster_order_mean_weighted_spikes_defined':[],\n",
    "                         'pairs_mean_ordering':[],\n",
    "                         'catagories_mean_ordering':[],\n",
    "                         'pairs_fs_ordering':[],\n",
    "                         'catagories_fs_ordering':[],\n",
    "                         'real_sequence_order':[]})\n",
    "                        meaned_order = []\n",
    "                        fs_order = []\n",
    "                        event_times = []\n",
    "                        multi_cluster_df\n",
    "                        count = 0\n",
    "                        for i,group in enumerate(filtered_chunk_data.coactive_cluster_group.unique()):\n",
    "                            group_mask = filtered_chunk_data.coactive_cluster_group == group\n",
    "                            current_cluster = filtered_chunk_data[group_mask]\n",
    "                            if len(current_cluster) > 1:\n",
    "                                means = []\n",
    "                                event_types = []\n",
    "                                fs_orders = []\n",
    "                                for index,events in enumerate(current_cluster.cluster_spike_times):\n",
    "                                    event_types += [current_cluster.cluster_seq_type.values[index]]\n",
    "                                    # calculate event order based on spike time weighted mean\n",
    "                                    means += [np.mean(ast.literal_eval(events))]\n",
    "                                    # calculate order based on first spike time:\n",
    "                                    fs_orders += [current_cluster.first_spike_time.values[index]]\n",
    "\n",
    "                                # order by mean time:    \n",
    "                                meaned_order += [list(np.array(event_types)[np.argsort(means)])]\n",
    "                                # order by first spike:\n",
    "                                fs_order += [list(np.array(event_types)[np.argsort(fs_orders)])]\n",
    "\n",
    "                                event_times += [fs_orders]\n",
    "\n",
    "                                current_cluster['new_cluster_group'] =  [count]*len(current_cluster)\n",
    "                                current_cluster['cluster_order_first_spike_defined'] =  list(np.argsort(np.argsort(fs_orders)))\n",
    "                                current_cluster['cluster_order_mean_weighted_spikes_defined'] =  list(np.argsort(np.argsort(means)))\n",
    "\n",
    "                                if count == 0:\n",
    "                                    multi_cluster_df = current_cluster.copy()\n",
    "                                else:\n",
    "                                    # Concatenate the DataFrames vertically (row-wise)\n",
    "                                    multi_cluster_df = pd.concat([multi_cluster_df, current_cluster], axis=0)\n",
    "                                    # Reset the index if needed\n",
    "                                    multi_cluster_df = multi_cluster_df.reset_index(drop=True)\n",
    "\n",
    "                                count += 1\n",
    "\n",
    "                        ############################################## Load in seq order data \n",
    "\n",
    "                        awake_PP_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\awake\\\\\"\n",
    "\n",
    "                        for index_,M_I_R in enumerate(os.listdir(awake_PP_path)):\n",
    "                            if not M_I_R == 'not_suitable':\n",
    "                                mir = '_'.join(M_I_R.split('_')[0:3])\n",
    "                                if mir == mouse:\n",
    "                                    c_path = awake_PP_path + M_I_R + r\"\\analysis_output\\reordered_recolored\\\\\" \n",
    "\n",
    "                        sequence_order_df = pd.read_csv(awake_PP_path+\"sequence_order.csv\")\n",
    "\n",
    "                        import ast\n",
    "                        seq_order= ast.literal_eval(sequence_order_df[sequence_order_df.mir == mouse].seq_order.values[0])\n",
    "                        num_dominant_seqs = int(sequence_order_df[sequence_order_df.mir == mouse].dominant_task_seqs)\n",
    "\n",
    "                        ############################################## calculate catagory breakdown\n",
    "\n",
    "                        if len(multi_cluster_df.coactive_cluster_group.unique()) > 1:\n",
    "\n",
    "                            real_order = list(np.array(seq_order)+1)\n",
    "\n",
    "                            # # mean ordering first : \n",
    "                            if len(real_order) > 3: # 3 will always be ordered so exclude\n",
    "                                relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,meaned_order)\n",
    "                                summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "                            #     labels = ['ordered','reverse','repeat','misordered','other_to_task','task_to_other','other']\n",
    "                            #     fig, ax = plt.subplots()\n",
    "                            #     ax.bar(labels,summed_amounts)\n",
    "                            #     ax.set_title('catagory occurances (seqs ordered by mean spike time)')\n",
    "\n",
    "                            #     SaveFig('catagory occurances_1___chunk'+ str(index_+1) + '.png',chunk_path)\n",
    "\n",
    "                                all_pair_outcomes_todf = []\n",
    "                                all_pairs_todf = []\n",
    "                                for group in multi_cluster_df.new_cluster_group.unique():\n",
    "                                    group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    all_pairs = []\n",
    "                                    all_pair_outcomes = []\n",
    "                                    for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "                                        all_pairs += [pair_]\n",
    "                                        all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "                                    all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "                                    all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "                                multi_cluster_df['pairs_mean_ordering'] = all_pairs_todf\n",
    "                                multi_cluster_df['catagories_mean_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "                                multi_cluster_df['real_sequence_order'] = [real_order]*len(multi_cluster_df)\n",
    "\n",
    "                                chunk_summed_amounts += [list(np.array(summed_amounts)/sum(summed_amounts))]\n",
    "\n",
    "                                chunk_ordered_sum += sum(summed_amounts[0:3])\n",
    "                                chunk_coactive_total += sum(summed_amounts[0:4])\n",
    "                            else:\n",
    "                                print('only 3 seqs')\n",
    "\n",
    "                            \n",
    "                            \n",
    "#                             print(chunk_summed_amounts)\n",
    "                            \n",
    "        \n",
    "                # outside of chunk loop ################################################\n",
    "                \n",
    "                # changed how i do this, now task freq is worke dout by adding up instances across all chunks and lookig at the proportion rather than averageing across chunks \n",
    "                if (6-len(task_seqs)) == 0:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "                else:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]      \n",
    "\n",
    "                ### add to animal vars\n",
    "                #1\n",
    "                reactivations_per_min += [np.mean(chunk_rpm)]\n",
    "                if np.mean(chunk_rpm) < 3:\n",
    "                    print('!!!!!')\n",
    "                #2\n",
    "                event_rate_binned +=[chunk_binned_rate]\n",
    "                er_bins_relative_to_so +=[chunk_bins_relative_so]\n",
    "                #3\n",
    "                event_lens += [chunk_event_lens]\n",
    "\n",
    "\n",
    "                #4 #########    \n",
    "                relative = []\n",
    "                totals = [sum(item) for item in chunk_total_nontask_task_related_events]\n",
    "                for i,item in enumerate(chunk_total_nontask_task_related_events):\n",
    "                    relative += [list(np.array(item)/totals[i])]\n",
    "\n",
    "                all_total_events += [total_events]\n",
    "\n",
    "                num_task_order_seqs = len(np.load(current_data_path+ 'task_order_seqs.npy')+1)\n",
    "\n",
    "                rel_task_nontask += [[np.mean(conactinate_nth_items(relative)[1]),np.mean(conactinate_nth_items(relative)[0])]]\n",
    "\n",
    "                chunks_task_nontask += conactinate_nth_items(relative)[1]\n",
    "\n",
    "                for item in coactive_freqs_chunk:\n",
    "                    if mouse in expert_mice:\n",
    "                        if item in e_coactive_freqs_counts:\n",
    "                            e_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            e_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in hlesion_mice:\n",
    "                        if item in hl_coactive_freqs_counts:\n",
    "                            hl_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            hl_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in learning_mice:\n",
    "                        if item in l_coactive_freqs_counts:\n",
    "                            l_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            l_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "\n",
    "\n",
    "\n",
    "                task_nontask_num_spikes+= [[np.mean(chunk_task_num_spikes),np.mean(chunk_nontask_num_spikes)]]\n",
    "                task_nontask_e_len+= [[np.mean(chunk_task_e_len),np.mean(chunk_nontask_e_len)]]\n",
    "\n",
    "                #5 #############\n",
    "\n",
    "                if len(chunk_summed_amounts) > 0:\n",
    "                    c_summed_amounts = []\n",
    "                    for item in conactinate_nth_items(chunk_summed_amounts):\n",
    "                        c_summed_amounts +=[np.mean(item)]\n",
    "                    mouse_summed_amounts += [c_summed_amounts]\n",
    "                else:\n",
    "                    mouse_summed_amounts += [[]]\n",
    "                    \n",
    "                    \n",
    "                ordered_sum += [chunk_ordered_sum]\n",
    "                ordered_misordered_total += [chunk_coactive_total]\n",
    "\n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the shuffled data - extract number of sequenes found\n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\synthetic_data\\shuffled\\ppseq_output\\\\\"\n",
    "# shuffle_events_per_min = []\n",
    "# for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "#     file = os.listdir(PP_PATH)[iteration_]\n",
    "#     data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "#     clust_events_per_min = 0\n",
    "#     all_chunks_len = 0\n",
    "#     current_mir = file.split('run')[0][:-1]\n",
    "#     for file in os.listdir(data_path):\n",
    "#         if 'chunk' in file:\n",
    "#             current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "#             replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "#             if 'ordering_classification' in list(replay_clusts):\n",
    "#                 interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "#                 # only sequential events\n",
    "#                 clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "#                 # clust_events_per_min += len(replay_clusts)\n",
    "#                 all_chunks_len += interval_length/60\n",
    "#             else:\n",
    "#                 print('no ordering classification...')\n",
    "            \n",
    "#     if all_chunks_len > 0:\n",
    "#         shuffle_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "\n",
    "\n",
    "# # load in the non shuffle - extract number of sequuences found \n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\synthetic_data\\non_shuffled\\ppseq_output\\\\\"\n",
    "# non_shuff_events_per_min = []\n",
    "# for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "#     file = os.listdir(PP_PATH)[iteration_]\n",
    "#     data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "#     clust_events_per_min = 0\n",
    "#     all_chunks_len = 0\n",
    "#     current_mir = file.split('run')[0][:-1]\n",
    "#     for file in os.listdir(data_path):\n",
    "#         if 'chunk' in file:\n",
    "#             current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "#             replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "#             if 'ordering_classification' in list(replay_clusts):\n",
    "#                 interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "#                 # only sequential events\n",
    "#                 # clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "#                 clust_events_per_min += len(replay_clusts)\n",
    "#                 all_chunks_len += interval_length/60\n",
    "#             else:\n",
    "#                 print('no ordering classification...')\n",
    "\n",
    "#     if all_chunks_len > 0:\n",
    "#         non_shuff_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "        \n",
    "# outpath = r'Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\\\'\n",
    "# pd.DataFrame({'id':mirs,'c_shuffled_epm':shuffle_events_per_min,'non_shuffled_epm':non_shuff_events_per_min}).to_csv(outpath+ 'circular_shuffle_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveFig(file_name,figure_dir):\n",
    "    if not os.path.isdir(figure_dir):\n",
    "        os.makedirs(figure_dir)\n",
    "    plt.savefig(figure_dir + file_name, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the csv:\n",
    "circular_shuffle_df = pd.read_csv(r'Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\circular_shuffle_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle_events_per_min = circular_shuffle_df.c_shuffled_epm.values\n",
    "non_shuff_events_per_min = circular_shuffle_df.non_shuffled_epm.values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 5))\n",
    "\n",
    "ax.plot([0.2]*len(shuffle_events_per_min),shuffle_events_per_min,'o', color = 'blue')\n",
    "ax.plot([0.8]*len(non_shuff_events_per_min),non_shuff_events_per_min,'o', color = 'red')\n",
    "\n",
    "ax.set_ylim(0,40)\n",
    "\n",
    "# for i in range(len(shuffle_events_per_min)):\n",
    "#     ax.plot([0.2,0.8],[shuffle_events_per_min[i],non_shuff_events_per_min[i]], 'o-')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['circular shuffle'] * len(shuffle_events_per_min)) + (['no shuffle'] * len(non_shuff_events_per_min)) , 'replay rate': list(shuffle_events_per_min)+list(non_shuff_events_per_min)})\n",
    "ax = sns.boxplot(y='replay rate', x='group', data=plt_df, color='blue', width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "SaveFig('circular_shuff.pdf',r'C:\\Users\\Emmett Thompson\\Documents\\plots\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=np.float64(0.9547968582522977), pvalue=np.float64(0.7077844361790105))\n",
      "ShapiroResult(statistic=np.float64(0.8884986168405241), pvalue=np.float64(0.11270468066831035))\n",
      "TtestResult(statistic=np.float64(-12.174829248104608), pvalue=np.float64(1.0024376812768496e-07), df=np.int64(11))\n",
      "3.514570471865462\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "print(scipy.stats.shapiro(shuffle_events_per_min))\n",
    "print(scipy.stats.shapiro(non_shuff_events_per_min))\n",
    "\n",
    "#paired t-test\n",
    "print(scipy.stats.ttest_rel(shuffle_events_per_min, non_shuff_events_per_min))\n",
    "\n",
    "diff =  non_shuff_events_per_min - shuffle_events_per_min\n",
    "cohen_d = diff.mean() / diff.std(ddof=1)\n",
    "print(cohen_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
