{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import + functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "136_1_3\n",
      "chunk1_8700to9300\n",
      "chunk2_10000to11600\n",
      "chunk3_11900to12500\n",
      "1\n",
      "136_1_4\n",
      "chunk1_7600to8200\n",
      "chunk2_8800to9400\n",
      "chunk3_9950to10550\n",
      "2\n",
      "148_2_2\n",
      "chunk1_3000to4000\n",
      "chunk2_4000to5000\n",
      "chunk3_5000to6000\n",
      "3\n",
      "149_1_1\n",
      "chunk1_8300to9300\n",
      "chunk2_9600to10600\n",
      "chunk3_12600to13600\n",
      "4\n",
      "178_1_4\n",
      "chunk1_7500to8100\n",
      "chunk2_8500to9100\n",
      "chunk3_9500to10100\n",
      "5\n",
      "178_1_5\n",
      "chunk1_8000to8600\n",
      "chunk2_9000to9600\n",
      "chunk3_12200to12800\n",
      "6\n",
      "178_1_6\n",
      "chunk1_8600to9300\n",
      "chunk2_10000to10600\n",
      "chunk3_12000to12600\n",
      "7\n",
      "178_1_7\n",
      "chunk1_8300to10000\n",
      "chunk2_10500to11200\n",
      "chunk3_13300to14300\n",
      "8\n",
      "178_1_8\n",
      "chunk1_11300to12000\n",
      "chunk2_13200to13800\n",
      "chunk3_16400to17000\n",
      "9\n",
      "178_1_9\n",
      "chunk1_9000to9900\n",
      "chunk2_10100to10700\n",
      "chunk3_11300to11900\n",
      "10\n",
      "178_2_1\n",
      "chunk1_8500to9200\n",
      "only 3 seqs\n",
      "chunk2_9900to10500\n",
      "only 3 seqs\n",
      "chunk3_14000to14600\n",
      "only 3 seqs\n",
      "11\n",
      "178_2_2\n",
      "chunk1_12300to12900\n",
      "chunk2_13600to14200\n",
      "chunk3_15400to16000\n",
      "12\n",
      "178_2_3\n",
      "chunk1_9500to10500\n",
      "chunk2_11800to12800\n",
      "chunk3_13000to14000\n",
      "!!!!!\n",
      "13\n",
      "178_2_4\n",
      "chunk1_9700to10500\n",
      "chunk2_11500to12100\n",
      "chunk3_14000to14400\n",
      "chunk4_15600to16000\n",
      "17\n",
      "255_1_1\n",
      "chunk1_7350to8350\n",
      "chunk2_8900to9900\n",
      "chunk3_10900to11900\n",
      "18\n",
      "255_1_2\n",
      "chunk1_4900to5900\n",
      "only 3 seqs\n",
      "chunk2_6200to7200\n",
      "only 3 seqs\n",
      "chunk3_8500to9500\n",
      "only 3 seqs\n",
      "19\n",
      "255_1_4\n",
      "chunk1_8000to9000\n",
      "chunk2_10500to11500\n",
      "chunk3_12700to13700\n",
      "!!!!!\n",
      "20\n",
      "256_1_1\n",
      "chunk1_9500to10500\n",
      "only 3 seqs\n",
      "chunk2_11700to12700\n",
      "chunk3_14300to15300\n",
      "21\n",
      "262_1_1\n",
      "chunk1_8900to9900\n",
      "chunk2_10300to11300\n",
      "chunk3_12000to13000\n",
      "!!!!!\n",
      "22\n",
      "262_1_2\n",
      "chunk1_12000to13000\n",
      "chunk2_14000to15000\n",
      "chunk3_16000to17000\n",
      "23\n",
      "262_1_4\n",
      "chunk1_10000to11000\n",
      "chunk2_11000to12000\n",
      "chunk3_14000to15000\n",
      "24\n",
      "262_1_5\n",
      "chunk1_14000to15000\n",
      "chunk2_15500to16500\n",
      "chunk3_18500to19500\n",
      "25\n",
      "262_1_6\n",
      "chunk1_8500to9500\n",
      "chunk2_11000to12000\n",
      "chunk3_13000to14000\n",
      "26\n",
      "268_1_2\n",
      "chunk1_9000to10000\n",
      "chunk2_11200to12200\n",
      "chunk3_14000to15000\n",
      "27\n",
      "269_1_1\n",
      "chunk1_7900to8900\n",
      "chunk2_10000to11000\n",
      "chunk3_13000to14000\n",
      "28\n",
      "269_1_2\n",
      "chunk1_8500to9500\n",
      "chunk2_10000to11000\n",
      "chunk3_12000to13000\n",
      "29\n",
      "269_1_3\n",
      "chunk1_8000to9000\n",
      "chunk2_9000to10000\n",
      "chunk3_11500to12500\n",
      "30\n",
      "269_1_4\n",
      "chunk1_8000to9000\n",
      "chunk2_10500to11500\n",
      "chunk3_11500to12500\n",
      "33\n",
      "269_1_7\n",
      "chunk1_9000to10000\n",
      "chunk2_12000to13000\n",
      "chunk3_16000to17000\n",
      "34\n",
      "270_1_1\n",
      "chunk1_9000to10000\n",
      "chunk2_10200to11200\n",
      "chunk3_13000to14000\n",
      "!!!!!\n",
      "35\n",
      "270_1_3\n",
      "chunk1_9100to10100\n",
      "chunk2_10200to11200\n",
      "chunk3_12000to13000\n",
      "36\n",
      "270_1_5\n",
      "chunk1_8300to9300\n",
      "chunk2_9300to10300\n",
      "chunk3_11800to12800\n",
      "!!!!!\n",
      "37\n",
      "270_1_6\n",
      "chunk1_7000to8000\n",
      "chunk2_11000to12000\n",
      "chunk3_16000to17000\n",
      "!!!!!\n"
     ]
    }
   ],
   "source": [
    "# ignore_list = ['269_1_5','269_1_6','270_1_1','178_2_3']\n",
    "ignore_list = ['269_1_5','269_1_6']\n",
    "\n",
    "\n",
    "dat_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\paper_submission\\post_sleep\\\\\"\n",
    "\n",
    "## set up empty vars \n",
    "mirs = []\n",
    "\n",
    "expert = []\n",
    "hlesion = []\n",
    "learning = []\n",
    "\n",
    "\n",
    "# 1\n",
    "reactivations_per_min = []\n",
    "# 2\n",
    "event_rate_binned = []\n",
    "er_bins_relative_to_so = []\n",
    "# 3\n",
    "event_lens = []\n",
    "# 4\n",
    "av_coactive_len_per_chunk = []\n",
    "\n",
    "e_coactive_freqs_counts = {}\n",
    "hl_coactive_freqs_counts = {}\n",
    "l_coactive_freqs_counts = {}\n",
    "\n",
    "all_total_events = []\n",
    "rel_task_nontask = []\n",
    "chunks_task_nontask = []\n",
    "\n",
    "task_nontask_num_spikes = []\n",
    "task_nontask_e_len = []\n",
    "\n",
    "chunk_expert = []\n",
    "chunk_mid_time_post_onset = []\n",
    "#5 \n",
    "mouse_summed_amounts = []\n",
    "ordered_sum = []\n",
    "ordered_misordered_total = []\n",
    "\n",
    "\n",
    "# warps = []\n",
    "\n",
    "\n",
    "# loop across all mouse files\n",
    "for run_index,pp_file in enumerate(os.listdir(dat_path)):\n",
    "    if not 'sleep_time_points' in pp_file:\n",
    "        # current mouse\n",
    "        mouse = '_'.join(pp_file.split('_')[0:3])\n",
    "        \n",
    "        if not mouse in ignore_list:\n",
    "\n",
    "            # if session in one of the groups (and define which)   \n",
    "            if mouse in list(expert_mice) + list(hlesion_mice) + list(learning_mice):\n",
    "                if mouse in expert_mice:\n",
    "                    expert += [1]\n",
    "                    hlesion += [0]\n",
    "                    learning += [0]               \n",
    "                elif mouse in hlesion_mice:                \n",
    "                    expert += [0]\n",
    "                    hlesion += [1]\n",
    "                    learning += [0]\n",
    "                elif mouse in learning_mice:                \n",
    "                    expert += [0]\n",
    "                    hlesion += [0]\n",
    "                    learning += [1]\n",
    "\n",
    "                print(run_index)\n",
    "\n",
    "                print(mouse)\n",
    "\n",
    "\n",
    "\n",
    "                # load in sleep start time \n",
    "                current_sleep_start = sleep_start[mouse]\n",
    "                params_file = dat_path + pp_file + r'\\trainingData\\\\' + 'params_' + mouse + '.json'\n",
    "                with open(params_file, 'r') as file:\n",
    "                    params = json.load(file)\n",
    "                time_spans = params['time_span']\n",
    "\n",
    "                # set path to processed files \n",
    "                current_mouse_path = dat_path + pp_file + '\\\\analysis_output'\n",
    "                mirs += [mouse]\n",
    "\n",
    "                ## set chunk vars \n",
    "                #1\n",
    "                chunk_rpm = []\n",
    "    #             chunk_warps = []\n",
    "                #2\n",
    "                chunk_binned_rate = []\n",
    "                chunk_bins_relative_so = []\n",
    "                #3\n",
    "                chunk_event_lens = []\n",
    "\n",
    "                #4\n",
    "                coactive_freqs_chunk  = {}\n",
    "                chunk_total_nontask_task_related_events = []\n",
    "                total_events = 0\n",
    "                chunk_task_num_spikes = []\n",
    "                chunk_nontask_num_spikes = []\n",
    "                chunk_task_e_len = []\n",
    "                chunk_nontask_e_len = []\n",
    "\n",
    "                #5\n",
    "                chunk_summed_amounts = []\n",
    "                chunk_ordered_sum = 0\n",
    "                chunk_coactive_total = 0\n",
    "                \n",
    "                \n",
    "                task_related = 0\n",
    "                non_task_related = 0\n",
    "\n",
    "                ## lopp across all chunk files\n",
    "                for file in os.listdir(current_mouse_path):\n",
    "                    if 'chunk' in file:\n",
    "                        print(file)\n",
    "                        current_data_path = current_mouse_path + '\\\\' + file + '\\\\'\n",
    "                        chunk_time = np.load(current_data_path + 'chunk_time_interval.npy')\n",
    "                        data = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "\n",
    "                        ## filter this data\n",
    "                        if sequential_filter == True: \n",
    "                            sequential_condition = data.ordering_classification == 'sequential'\n",
    "                        else:\n",
    "                            sequential_condition = np.array([True]*len(data.ordering_classification))\n",
    "\n",
    "                        if sleep_filters_on == True:\n",
    "                            if nrem_filter == True: \n",
    "                                nrem_condition = nrem__condition = data.nrem_events == 1\n",
    "                            else:\n",
    "                                nrem_condition = np.array([False]*len(data.nrem_events))\n",
    "\n",
    "                            if rem_filter == True: \n",
    "                                rem_condition = rem__condition = data.rem_events == 1\n",
    "                            else:\n",
    "                                rem_condition = np.array([False]*len(data.rem_events))\n",
    "\n",
    "                            if background_only == True:\n",
    "                                rem_condition = rem__condition = data.rem_events == 0\n",
    "                                nrem_condition = nrem__condition = data.nrem_events == 1\n",
    "\n",
    "                        else:\n",
    "                            nrem_condition = np.array([True]*len(data))\n",
    "                            rem_condition = np.array([True]*len(data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        # filter is set up so that any true will carry forward \n",
    "                        filter_mask = sequential_condition * (nrem_condition + rem_condition)\n",
    "\n",
    "                        filtered_chunk_data = data[filter_mask].reset_index()\n",
    "\n",
    "\n",
    "                        # save out data\n",
    "                        reactivations_found = len(filtered_chunk_data)\n",
    "\n",
    "\n",
    "\n",
    "                        # this one depends on rem/nrem filter... \n",
    "\n",
    "    #                         # if sleep_filters_on is false, use all chunk time\n",
    "                        if sleep_filters_on == False:\n",
    "                            mins = np.diff(chunk_time)[0]\n",
    "                        else:\n",
    "                            # load in state times\n",
    "                            rem_state_times = np.load(current_data_path + 'rem_state_times.npy')\n",
    "                            nrem_state_times = np.load(current_data_path + 'nrem_state_times.npy')\n",
    "                            if len(rem_state_times) > 0:\n",
    "                                tot_rem = sum(np.diff(rem_state_times))[0]\n",
    "                            else:\n",
    "                                tot_rem = 0\n",
    "                            if len(nrem_state_times) > 0:\n",
    "                                tot_nrem = sum(np.diff(nrem_state_times))[0]\n",
    "                            else:\n",
    "                                tot_nrem = 0\n",
    "\n",
    "                            # if background then use all non rem an dnon nrem times\n",
    "                            if background_only:\n",
    "                                mins = np.diff(chunk_time)[0] - (tot_rem+tot_nrem)\n",
    "                            else:\n",
    "                                # if both, use both \n",
    "                                if nrem_filter == True and rem_filter == True:\n",
    "                                    mins = tot_rem+tot_nrem\n",
    "                                elif nrem_filter == True and rem_filter == False:\n",
    "                                    mins = tot_nrem\n",
    "                                elif nrem_filter == False and rem_filter == True:\n",
    "                                    mins = tot_rem\n",
    "                        # convert to mins            \n",
    "                        mins = mins/60\n",
    "\n",
    "                        if mins > 0:\n",
    "                            chunk_rpm += [reactivations_found/mins]\n",
    "\n",
    "                        #2################################\n",
    "\n",
    "#                             current_sleep_start = sleep_start[mouse] - 400\n",
    "                            chunk_number = int(file.split('_')[0][-1])\n",
    "                            start_offset = ([0]+list(np.cumsum(np.diff(time_spans))))[chunk_number-1]\n",
    "\n",
    "\n",
    "                            # take away cumulative chunk offset - this gives time in terms of chunk\n",
    "                            f_spike_times = filtered_chunk_data.first_spike_time.values - start_offset\n",
    "                            # add on ephys time that chunk started - so its in ephys timestamps \n",
    "                            f_spike_times = f_spike_times + chunk_time[0]\n",
    "\n",
    "                            # now make relative to sleep start time\n",
    "                            f_spike_times_relative_to_so = f_spike_times - current_sleep_start \n",
    "                            # do the same but for rem and nrem start\n",
    "\n",
    "                            # filter out anything that happened before sleep onset\n",
    "                            f_spike_times_relative_to_so = f_spike_times_relative_to_so[f_spike_times_relative_to_so > 0]\n",
    "\n",
    "                            ## calculate rate over time:\n",
    "                            time_data = pd.Series(f_spike_times_relative_to_so)\n",
    "                            if len(time_data) > 0:\n",
    "#                                 # Calculate the number of bins required # 5 minute bins\n",
    "#                                 num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "#                                 # Create bins and count the occurrences in each bin\n",
    "#                                 chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "#                                 #remove extra final bin and convert to mins\n",
    "#                                 chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "                                # Calculate the number of bins required # 20s bins\n",
    "                            #     num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "                                if time_data.max() - time_data.min() > 19:\n",
    "                                    num_bins = int((time_data.max() - time_data.min())//20)\n",
    "                                    # Create bins and count the occurrences in each bin\n",
    "                                    chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "                                    #remove extra final bin and convert to mins\n",
    "                                    chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "\n",
    "                                    chunk_binned_rate += [list((chunk_event_rate*3).astype(float))] # *3 because its per 20s so we want it per minute )\n",
    "                                    chunk_bins_relative_so += [list(chunk_relative_time_bins.astype(float))]\n",
    "\n",
    "                        \n",
    "                        #3########################################################\n",
    "\n",
    "                        chunk_event_lens += list(filtered_chunk_data.event_length.values)\n",
    "\n",
    "                        #4 ################################################# coactive stuff -300ms = coactive\n",
    "                        event_proximity_filter =  0.3 #s (how close events have to be to each other to be clustered together as coacitve \n",
    "\n",
    "                        task_seqs = np.load(current_data_path + 'task_order_seqs.npy')+1\n",
    "            \n",
    "                        for motif_type in filtered_chunk_data.cluster_seq_type:\n",
    "                            if motif_type in task_seqs:\n",
    "                                task_related += 1\n",
    "                            else:\n",
    "                                non_task_related += 1\n",
    "        \n",
    "                        total_events += len(filtered_chunk_data.cluster_seq_type)\n",
    "\n",
    "                        # normalise by number of each type: \n",
    "#                         if (6-len(task_seqs)) == 0:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "#                         else:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]\n",
    "\n",
    "                        chunk_mid_time_post_onset += [((sum(chunk_time)/2)-current_sleep_start)]\n",
    "\n",
    "                        ### ignore the origonal clusterg rosp and remake them: \n",
    "                        start_times = filtered_chunk_data.first_spike_time.values\n",
    "                        end_times = filtered_chunk_data.last_spike_time.values\n",
    "\n",
    "                        clustered_events = cluster_events(start_times, end_times,event_proximity_filter)\n",
    "\n",
    "                        cluster_group = np.zeros(len(filtered_chunk_data))\n",
    "                        for index,cluster in enumerate(clustered_events):\n",
    "                            for item in cluster:\n",
    "                                cluster_group[item] = int(index)\n",
    "                        filtered_chunk_data['coactive_cluster_group'] = cluster_group\n",
    "\n",
    "                        # work out how mnay coacitve in chunk: \n",
    "                        current_coactive_freqs_chunk = {}\n",
    "                        for cluster in filtered_chunk_data.coactive_cluster_group.unique():\n",
    "                            num = list(filtered_chunk_data.coactive_cluster_group.values).count(cluster)\n",
    "                            if num in current_coactive_freqs_chunk:\n",
    "                                current_coactive_freqs_chunk[num] += 1\n",
    "                            else:\n",
    "                                current_coactive_freqs_chunk[num] = 1\n",
    "\n",
    "                        avs =[]\n",
    "                        for item in current_coactive_freqs_chunk:\n",
    "                            avs += current_coactive_freqs_chunk[item] * [item]\n",
    "                        av_coactive_len_per_chunk += [np.mean(avs)]\n",
    "                        if mouse in expert_mice:\n",
    "                            chunk_expert += [1]\n",
    "                        elif mouse in hlesion_mice:\n",
    "                            chunk_expert += [2]\n",
    "                        elif mouse in learning_mice:\n",
    "                            chunk_expert += [3]\n",
    "\n",
    "\n",
    "                        # make it relative:\n",
    "                        current_coactive_freqs_chunk = relative_dict(current_coactive_freqs_chunk)\n",
    "\n",
    "                        coactive_freqs_keys = list(current_coactive_freqs_chunk.keys())\n",
    "                        rel_coactive_freqs = list(current_coactive_freqs_chunk.values())\n",
    "                        for index,item in enumerate(rel_coactive_freqs):\n",
    "                            num = int(coactive_freqs_keys[index])\n",
    "                            if num in coactive_freqs_chunk:\n",
    "                                coactive_freqs_chunk[num] += [item]\n",
    "                            else:\n",
    "                                coactive_freqs_chunk[num] = [item]\n",
    "\n",
    "\n",
    "                        task_events = filtered_chunk_data[filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "                        non_task_events = filtered_chunk_data[~filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "\n",
    "                        chunk_task_num_spikes+=list(task_events.num_spikes)\n",
    "                        chunk_nontask_num_spikes+=list(non_task_events.num_spikes)\n",
    "                        chunk_task_e_len+=list(task_events.event_length)\n",
    "                        chunk_nontask_e_len+=list(non_task_events.event_length)\n",
    "\n",
    "\n",
    "                        # 5 ##############################################################################\n",
    "\n",
    "                        ############################################## split into multi clusters and process\n",
    "\n",
    "                        multi_cluster_df = pd.DataFrame({'cluster_seq_type':[],\n",
    "                         'num_spikes':[],\n",
    "                         'num_neurons':[],\n",
    "                         'first_spike_time':[],\n",
    "                         'event_length':[],\n",
    "                         'last_spike_time':[],\n",
    "                         'cluster_spike_times':[],\n",
    "                         'cluster_neurons':[],\n",
    "                         'spike_plotting_order':[],\n",
    "                         'coactive_cluster_group':[],\n",
    "                         'new_cluster_group':[],\n",
    "                         'cluster_order_first_spike_defined':[],\n",
    "                         'cluster_order_mean_weighted_spikes_defined':[],\n",
    "                         'pairs_mean_ordering':[],\n",
    "                         'catagories_mean_ordering':[],\n",
    "                         'pairs_fs_ordering':[],\n",
    "                         'catagories_fs_ordering':[],\n",
    "                         'real_sequence_order':[]})\n",
    "                        meaned_order = []\n",
    "                        fs_order = []\n",
    "                        event_times = []\n",
    "                        multi_cluster_df\n",
    "                        count = 0\n",
    "                        for i,group in enumerate(filtered_chunk_data.coactive_cluster_group.unique()):\n",
    "                            group_mask = filtered_chunk_data.coactive_cluster_group == group\n",
    "                            current_cluster = filtered_chunk_data[group_mask]\n",
    "                            if len(current_cluster) > 1:\n",
    "                                means = []\n",
    "                                event_types = []\n",
    "                                fs_orders = []\n",
    "                                for index,events in enumerate(current_cluster.cluster_spike_times):\n",
    "                                    event_types += [current_cluster.cluster_seq_type.values[index]]\n",
    "                                    # calculate event order based on spike time weighted mean\n",
    "                                    means += [np.mean(ast.literal_eval(events))]\n",
    "                                    # calculate order based on first spike time:\n",
    "                                    fs_orders += [current_cluster.first_spike_time.values[index]]\n",
    "\n",
    "                                # order by mean time:    \n",
    "                                meaned_order += [list(np.array(event_types)[np.argsort(means)])]\n",
    "                                # order by first spike:\n",
    "                                fs_order += [list(np.array(event_types)[np.argsort(fs_orders)])]\n",
    "\n",
    "                                event_times += [fs_orders]\n",
    "\n",
    "                                current_cluster['new_cluster_group'] =  [count]*len(current_cluster)\n",
    "                                current_cluster['cluster_order_first_spike_defined'] =  list(np.argsort(np.argsort(fs_orders)))\n",
    "                                current_cluster['cluster_order_mean_weighted_spikes_defined'] =  list(np.argsort(np.argsort(means)))\n",
    "\n",
    "                                if count == 0:\n",
    "                                    multi_cluster_df = current_cluster.copy()\n",
    "                                else:\n",
    "                                    # Concatenate the DataFrames vertically (row-wise)\n",
    "                                    multi_cluster_df = pd.concat([multi_cluster_df, current_cluster], axis=0)\n",
    "                                    # Reset the index if needed\n",
    "                                    multi_cluster_df = multi_cluster_df.reset_index(drop=True)\n",
    "\n",
    "                                count += 1\n",
    "\n",
    "                        ############################################## Load in seq order data \n",
    "\n",
    "                        awake_PP_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\awake\\\\\"\n",
    "\n",
    "                        for index_,M_I_R in enumerate(os.listdir(awake_PP_path)):\n",
    "                            if not M_I_R == 'not_suitable':\n",
    "                                mir = '_'.join(M_I_R.split('_')[0:3])\n",
    "                                if mir == mouse:\n",
    "                                    c_path = awake_PP_path + M_I_R + r\"\\analysis_output\\reordered_recolored\\\\\" \n",
    "\n",
    "                        sequence_order_df = pd.read_csv(awake_PP_path+\"sequence_order.csv\")\n",
    "\n",
    "                        import ast\n",
    "                        seq_order= ast.literal_eval(sequence_order_df[sequence_order_df.mir == mouse].seq_order.values[0])\n",
    "                        num_dominant_seqs = int(sequence_order_df[sequence_order_df.mir == mouse].dominant_task_seqs)\n",
    "\n",
    "                        ############################################## calculate catagory breakdown\n",
    "\n",
    "                        if len(multi_cluster_df.coactive_cluster_group.unique()) > 1:\n",
    "\n",
    "                            real_order = list(np.array(seq_order)+1)\n",
    "\n",
    "                            # # mean ordering first : \n",
    "                            if len(real_order) > 3: # 3 will always be ordered so exclude\n",
    "                                relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,meaned_order)\n",
    "                                summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "                            #     labels = ['ordered','reverse','repeat','misordered','other_to_task','task_to_other','other']\n",
    "                            #     fig, ax = plt.subplots()\n",
    "                            #     ax.bar(labels,summed_amounts)\n",
    "                            #     ax.set_title('catagory occurances (seqs ordered by mean spike time)')\n",
    "\n",
    "                            #     SaveFig('catagory occurances_1___chunk'+ str(index_+1) + '.png',chunk_path)\n",
    "\n",
    "                                all_pair_outcomes_todf = []\n",
    "                                all_pairs_todf = []\n",
    "                                for group in multi_cluster_df.new_cluster_group.unique():\n",
    "                                    group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    all_pairs = []\n",
    "                                    all_pair_outcomes = []\n",
    "                                    for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "                                        all_pairs += [pair_]\n",
    "                                        all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "                                    all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "                                    all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "                                multi_cluster_df['pairs_mean_ordering'] = all_pairs_todf\n",
    "                                multi_cluster_df['catagories_mean_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "                                multi_cluster_df['real_sequence_order'] = [real_order]*len(multi_cluster_df)\n",
    "\n",
    "                                chunk_summed_amounts += [list(np.array(summed_amounts)/sum(summed_amounts))]\n",
    "\n",
    "                                chunk_ordered_sum += sum(summed_amounts[0:3])\n",
    "                                chunk_coactive_total += sum(summed_amounts[0:4])\n",
    "                            else:\n",
    "                                print('only 3 seqs')\n",
    "\n",
    "                            \n",
    "                            \n",
    "#                             print(chunk_summed_amounts)\n",
    "                            \n",
    "        \n",
    "                # outside of chunk loop ################################################\n",
    "                \n",
    "                # changed how i do this, now task freq is worke dout by adding up instances across all chunks and lookig at the proportion rather than averageing across chunks \n",
    "                if (6-len(task_seqs)) == 0:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "                else:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]      \n",
    "\n",
    "                ### add to animal vars\n",
    "                #1\n",
    "                reactivations_per_min += [np.mean(chunk_rpm)]\n",
    "                if np.mean(chunk_rpm) < 3:\n",
    "                    print('!!!!!')\n",
    "                #2\n",
    "                event_rate_binned +=[chunk_binned_rate]\n",
    "                er_bins_relative_to_so +=[chunk_bins_relative_so]\n",
    "                #3\n",
    "                event_lens += [chunk_event_lens]\n",
    "\n",
    "\n",
    "                #4 #########    \n",
    "                relative = []\n",
    "                totals = [sum(item) for item in chunk_total_nontask_task_related_events]\n",
    "                for i,item in enumerate(chunk_total_nontask_task_related_events):\n",
    "                    relative += [list(np.array(item)/totals[i])]\n",
    "\n",
    "                all_total_events += [total_events]\n",
    "\n",
    "                num_task_order_seqs = len(np.load(current_data_path+ 'task_order_seqs.npy')+1)\n",
    "\n",
    "                rel_task_nontask += [[np.mean(conactinate_nth_items(relative)[1]),np.mean(conactinate_nth_items(relative)[0])]]\n",
    "\n",
    "                chunks_task_nontask += conactinate_nth_items(relative)[1]\n",
    "\n",
    "                for item in coactive_freqs_chunk:\n",
    "                    if mouse in expert_mice:\n",
    "                        if item in e_coactive_freqs_counts:\n",
    "                            e_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            e_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in hlesion_mice:\n",
    "                        if item in hl_coactive_freqs_counts:\n",
    "                            hl_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            hl_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in learning_mice:\n",
    "                        if item in l_coactive_freqs_counts:\n",
    "                            l_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            l_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "\n",
    "\n",
    "\n",
    "                task_nontask_num_spikes+= [[np.mean(chunk_task_num_spikes),np.mean(chunk_nontask_num_spikes)]]\n",
    "                task_nontask_e_len+= [[np.mean(chunk_task_e_len),np.mean(chunk_nontask_e_len)]]\n",
    "\n",
    "                #5 #############\n",
    "\n",
    "                if len(chunk_summed_amounts) > 0:\n",
    "                    c_summed_amounts = []\n",
    "                    for item in conactinate_nth_items(chunk_summed_amounts):\n",
    "                        c_summed_amounts +=[np.mean(item)]\n",
    "                    mouse_summed_amounts += [c_summed_amounts]\n",
    "                else:\n",
    "                    mouse_summed_amounts += [[]]\n",
    "                    \n",
    "                    \n",
    "                ordered_sum += [chunk_ordered_sum]\n",
    "                ordered_misordered_total += [chunk_coactive_total]\n",
    "\n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load in the shuffled data - extract number of sequenes found\n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\synthetic_data\\shuffled\\ppseq_output\\\\\"\n",
    "# shuffle_events_per_min = []\n",
    "# for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "#     file = os.listdir(PP_PATH)[iteration_]\n",
    "#     data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "#     clust_events_per_min = 0\n",
    "#     all_chunks_len = 0\n",
    "#     current_mir = file.split('run')[0][:-1]\n",
    "#     for file in os.listdir(data_path):\n",
    "#         if 'chunk' in file:\n",
    "#             current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "#             replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "#             if 'ordering_classification' in list(replay_clusts):\n",
    "#                 interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "#                 # only sequential events\n",
    "#                 clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "#                 # clust_events_per_min += len(replay_clusts)\n",
    "#                 all_chunks_len += interval_length/60\n",
    "#             else:\n",
    "#                 print('no ordering classification...')\n",
    "            \n",
    "#     if all_chunks_len > 0:\n",
    "#         shuffle_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "\n",
    "\n",
    "# # load in the non shuffle - extract number of sequuences found \n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\synthetic_data\\non_shuffled\\ppseq_output\\\\\"\n",
    "# non_shuff_events_per_min = []\n",
    "# for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "#     file = os.listdir(PP_PATH)[iteration_]\n",
    "#     data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "#     clust_events_per_min = 0\n",
    "#     all_chunks_len = 0\n",
    "#     current_mir = file.split('run')[0][:-1]\n",
    "#     for file in os.listdir(data_path):\n",
    "#         if 'chunk' in file:\n",
    "#             current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "#             replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "#             if 'ordering_classification' in list(replay_clusts):\n",
    "#                 interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "#                 # only sequential events\n",
    "#                 # clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "#                 clust_events_per_min += len(replay_clusts)\n",
    "#                 all_chunks_len += interval_length/60\n",
    "#             else:\n",
    "#                 print('no ordering classification...')\n",
    "\n",
    "#     if all_chunks_len > 0:\n",
    "#         non_shuff_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "        \n",
    "# outpath = r'Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\\\'\n",
    "# pd.DataFrame({'id':mirs,'c_shuffled_epm':shuffle_events_per_min,'non_shuffled_epm':non_shuff_events_per_min}).to_csv(outpath+ 'circular_shuffle_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the csv:\n",
    "circular_shuffle_df = pd.read_csv(r'Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\circular_shuffle_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle_events_per_min = circular_shuffle_df.c_shuffled_epm.values\n",
    "non_shuff_events_per_min = circular_shuffle_df.non_shuffled_epm.values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 5))\n",
    "\n",
    "ax.plot([0.2]*len(shuffle_events_per_min),shuffle_events_per_min,'o', color = 'blue')\n",
    "ax.plot([0.8]*len(non_shuff_events_per_min),non_shuff_events_per_min,'o', color = 'red')\n",
    "\n",
    "ax.set_ylim(0,40)\n",
    "\n",
    "# for i in range(len(shuffle_events_per_min)):\n",
    "#     ax.plot([0.2,0.8],[shuffle_events_per_min[i],non_shuff_events_per_min[i]], 'o-')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['circular shuffle'] * len(shuffle_events_per_min)) + (['no shuffle'] * len(non_shuff_events_per_min)) , 'replay rate': list(shuffle_events_per_min)+list(non_shuff_events_per_min)})\n",
    "ax = sns.boxplot(y='replay rate', x='group', data=plt_df, color='blue', width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate = np.mean((np.array(shuffle_events_per_min)/np.array(non_shuff_events_per_min))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
