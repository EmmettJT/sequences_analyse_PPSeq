{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import statistics\n",
    "from ast import literal_eval\n",
    "#functions\n",
    "\n",
    "def load_in_paths(pp_file, PP_PATH, DAT_PATH):\n",
    "    mir = '_'.join(pp_file.split('_')[0:3])\n",
    "    print(str(run_index+1) + '/' + str(len(os.listdir(PP_PATH))-1) + '-------------------------------------------------------------------------')\n",
    "    print(pp_file)\n",
    "    mouse_session_recording = pp_file.split('_')[0] + '_' + pp_file.split('_')[1] + '_' + pp_file.split('_')[2] \n",
    "    skip = False\n",
    "    for item in ignore_list:\n",
    "        if item == mouse_session_recording:\n",
    "            skip = True\n",
    "\n",
    "    save_path = PP_PATH + pp_file + '\\\\_final_analysis_output\\\\'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    ## set dat_path:\n",
    "    for file_ in os.listdir(DAT_PATH):\n",
    "        if mouse_session_recording.split('_')[0] in file_:\n",
    "            if mouse_session_recording.split('_')[1] == file_[-1]:\n",
    "                dat_path = os.path.join(DAT_PATH,file_)\n",
    "    for recording in os.listdir(os.path.join(DAT_PATH,dat_path)):\n",
    "        if recording.split('_')[0][9::] == mouse_session_recording.split('_')[-1]:\n",
    "            dat_path = os.path.join(dat_path,recording)\n",
    "\n",
    "    # set tracking path\n",
    "    for file_ in os.listdir(dat_path + r\"\\video\\tracking\\\\\"):\n",
    "        if 'task' in file_:\n",
    "            if not 'clock' in file_:\n",
    "                tracking_path = os.path.join(dat_path + r\"\\video\\tracking\\\\\",file_) + '\\\\'\n",
    "   \n",
    "    return mir,mouse_session_recording,save_path,tracking_path,dat_path\n",
    "\n",
    "def load_PPSEQ_data(PP_PATH,pp_file,dat_path,mouse_session_recording):\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------------------------------------------------------------    \n",
    "    ## LOAD \n",
    "    print(\"LOADING PPSEQ DATA\")\n",
    "    print('\\n')\n",
    "    #The assignment history frame (assigment_hist_frame.csv): Spikes by iterations, how each spike is assigned to a sequence ID (in latent_event_hist) or to background (-1)\n",
    "    assignment_history_df = pd.read_csv(PP_PATH + pp_file + r\"\\assigment_hist_frame.csv\")\n",
    "\n",
    "    # latent_event_hist.csv: history of latent events. All latent events across all iterations have a row\n",
    "    latent_event_history_df = pd.read_csv(PP_PATH + pp_file + r\"\\latent_event_hist.csv\")\n",
    "\n",
    "    # seq_type_log_proportions: log p of each type of sequence at each iteration\n",
    "    seq_type_log_proportions_df = pd.read_csv(PP_PATH + pp_file + r\"\\seq_type_log_proportions.csv\")\n",
    "\n",
    "    # neuron_responses.csv: iterations x neurons by 3(number of sequences). Each neuron has three parameters per sequence to describe how it is influenced by each sequence type. \n",
    "    # Each iteration these are resampled, therefore there are number of neurons by iterations by 3 by number of sequences of these numbers.\n",
    "    neuron_response_df = pd.read_csv(PP_PATH + pp_file + r\"\\neuron_response.csv\")\n",
    "\n",
    "    masking = False\n",
    "    for dat_files in os.listdir(PP_PATH + pp_file):\n",
    "        if 'unmasked_spikes' in dat_files:\n",
    "            masking = True\n",
    "            print('masking was used')\n",
    "\n",
    "    if masking == True:\n",
    "        #log_p_hist.csv: the history of the log_p of the model\n",
    "        log_p_hist_df = pd.read_csv(PP_PATH + pp_file + r\"\\test_log_p_hist.csv\")\n",
    "\n",
    "        unmasked_spikes_df = pd.read_csv(PP_PATH + pp_file + r\"\\unmasked_spikes.csv\")\n",
    "    else:\n",
    "        log_p_hist_df = pd.read_csv(PP_PATH + pp_file + r\"\\log_p_hist.csv\")\n",
    "\n",
    "        spikes_file = os.path.join(PP_PATH + pp_file,'trainingData\\\\') + mouse_session_recording + '.txt'\n",
    "        neuron_ids, spike_times= [], []\n",
    "        with open(spikes_file) as f:\n",
    "            for (i, line) in enumerate(f.readlines()):\n",
    "                neuron_id, spike_time = line.split('\\t')\n",
    "                spike_time = float(spike_time.strip())\n",
    "                neuron_id = float(neuron_id)\n",
    "                spike_times.append(spike_time)\n",
    "                neuron_ids.append(neuron_id)\n",
    "        unmasked_spikes_df = pd.DataFrame({'neuron':neuron_ids,'timestamp':spike_times}) \n",
    "        bkgd_log_proportions_array = pd.read_csv(PP_PATH + pp_file + r\"\\bkgd_log_proportions_array.csv\")\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(PP_PATH + pp_file + r'\\config_file.json')\n",
    "    # returns JSON object as a dictionary\n",
    "    config = eval(json.load(f))\n",
    "    print(f'      done')\n",
    "\n",
    "    ## LOAD behaviour data\n",
    "    print('\\n')\n",
    "    print(\"LOADING BEHAV DATA\")\n",
    "\n",
    "    ## load in the timespan used for pppseq:\n",
    "    input_params_path = os.path.join(PP_PATH + pp_file,'trainingData\\\\') + ('params_' + mouse_session_recording +'.json')\n",
    "    # Opening JSON file\n",
    "    f = open(input_params_path)\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    input_config = json.load(f)\n",
    "    behav_time_interval_start = input_config['time_span']\n",
    "    print(f\"      A corresponding time span has been found. Time span set to {behav_time_interval_start}\")\n",
    "\n",
    "    ### load in data:\n",
    "    for sub_file in os.listdir(dat_path + '\\\\behav_sync\\\\'):\n",
    "        if 'task' in sub_file:\n",
    "            behav_sync_path = dat_path + '\\\\behav_sync\\\\' + sub_file +'\\\\'\n",
    "    behav_sync = pd.read_csv(behav_sync_path + 'Behav_Ephys_Camera_Sync.csv')\n",
    "    transitions = pd.read_csv(behav_sync_path + 'Transition_data_sync.csv')\n",
    "\n",
    "    return assignment_history_df,latent_event_history_df,seq_type_log_proportions_df,neuron_response_df,log_p_hist_df,unmasked_spikes_df,bkgd_log_proportions_array,behav_sync,transitions,behav_time_interval_start\n",
    "\n",
    "def plot_save_log_l_curve(log_p_hist_df,save_path):\n",
    "    # find 95% of growth value and when it crossed this\n",
    "    max_ = max(log_p_hist_df.x1)\n",
    "    min_ = min(log_p_hist_df.x1)\n",
    "    growth = max_ - min_\n",
    "    _prcntile =  max_ - (0.02 * growth)\n",
    "\n",
    "    ## model log likley hood curve\n",
    "    plt.plot(log_p_hist_df.x1)\n",
    "    plt.axhline(y=_prcntile, color='r', linestyle='--')\n",
    "\n",
    "    SaveFig('log_l_curve.png',save_path)\n",
    "\n",
    "# Function to find corresponding number in another column\n",
    "def find_corresponding(nums):\n",
    "    return [df_dict[num] for num in nums]\n",
    "\n",
    "def SaveFig(file_name,figure_dir):\n",
    "    if not os.path.isdir(figure_dir):\n",
    "        os.makedirs(figure_dir)\n",
    "    plt.savefig(figure_dir + file_name, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_data_raster(behav_time_interval_start, spikes_df, neuron_index, colors, save_path):\n",
    "    # calculate interval timings and end points\n",
    "    interval_lengths = []\n",
    "    for interval in behav_time_interval_start:\n",
    "        interval_lengths += [np.diff(interval)[0]]\n",
    "    total_time = sum(interval_lengths)\n",
    "    interval_end_points = np.cumsum(interval_lengths)\n",
    "\n",
    "    # Plot sequences - basic\n",
    "    timeframe = [0, total_time]\n",
    "    mask = (spikes_df.timestamp > timeframe[0]) * (spikes_df.timestamp < timeframe[-1])\n",
    "\n",
    "    # Define neuron order\n",
    "    neuron_permute_loc = np.zeros(len(neuron_index))\n",
    "    for i in range(len(neuron_index)):\n",
    "        neuron_permute_loc[i] = int(list(neuron_index).index(i))\n",
    "    neuron_order = neuron_permute_loc[(spikes_df.neuron - 1).astype(int)]\n",
    "\n",
    "    # Plotting\n",
    "    fig, [ax, ax2] = plt.subplots(2, 1, figsize=(20, 20))\n",
    "\n",
    "    # Plot background in grey\n",
    "    background_keep_mask = (spikes_df[mask].sequence_type_adjusted < 0) | (spikes_df[mask].sequence_type_adjusted >= 7.0)\n",
    "    ax.scatter(spikes_df[mask][background_keep_mask].timestamp, neuron_order[mask][background_keep_mask],\n",
    "               marker='o', s=40, linewidth=0, color='lightgrey', alpha=0.3)\n",
    "    c_ = np.array(colors)[spikes_df[mask][background_keep_mask].sequence_type_adjusted.values.astype(int)]\n",
    "    ax2.scatter(spikes_df[mask][background_keep_mask].timestamp, neuron_order[mask][background_keep_mask],\n",
    "                marker='o', s=40, linewidth=0, color=c_, alpha=0.3)\n",
    "    ax2.set_title('extra sequences and background only')\n",
    "\n",
    "    # Plot spikes without background\n",
    "    background_remove_mask = (spikes_df[mask].sequence_type_adjusted >= 0) * \\\n",
    "                             (spikes_df[mask].sequence_type_adjusted != 7.0) * \\\n",
    "                             (spikes_df[mask].sequence_type_adjusted != 8.0)\n",
    "    c_ = np.array(colors)[spikes_df[mask][background_remove_mask].sequence_type_adjusted.values.astype(int)]\n",
    "    ax.scatter(spikes_df[mask][background_remove_mask].timestamp, neuron_order[mask][background_remove_mask],\n",
    "               marker='o', s=40, linewidth=0, color=c_, alpha=1)\n",
    "    ax.set_title('held sequences in color and extra sequences + background in grey')\n",
    "\n",
    "    for end_p in interval_end_points:\n",
    "        ax.axvline(x=end_p, color='k')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "    return interval_end_points,neuron_order\n",
    "\n",
    "\n",
    "def convolve_movmean(y,N):\n",
    "    y_padded = np.pad(y, (N//2, N-1-N//2), mode='edge')\n",
    "    y_smooth = np.convolve(y_padded, np.ones((N,))/N, mode='valid') \n",
    "    return y_smooth\n",
    "\n",
    "def split_list(numbers):\n",
    "    chunks = []\n",
    "    indices = []\n",
    "    current_chunk = []\n",
    "    current_indices = []\n",
    "    for i, num in enumerate(numbers):\n",
    "        if num == 0:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk)\n",
    "                indices.append(current_indices)\n",
    "                current_chunk = []\n",
    "                current_indices = []\n",
    "        else:\n",
    "            current_chunk.append(num)\n",
    "            current_indices.append(i)\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "        indices.append(current_indices)\n",
    "    return chunks, indices\n",
    "\n",
    "# Function to create directory if it doesn't exist\n",
    "def create_directory(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "# Function to save figure\n",
    "def save_figure(fig, filename, path):\n",
    "    fig.savefig(os.path.join(path, filename))\n",
    "\n",
    "# Function to filter and save replay clusters\n",
    "def filter_and_save_replay_clusters(chunk_df, chunk_path, r_seq_type, r_start_, r_end_, colors, min_spikes_filter, min_neurons_involved_filter):\n",
    "    filtered_data = {\n",
    "        'cluster_seq_type': [],\n",
    "        'num_spikes': [],\n",
    "        'num_neurons': [],\n",
    "        'first_spike_time': [],\n",
    "        'event_length': [],\n",
    "        'last_spike_time': [],\n",
    "        'cluster_spike_times': [],\n",
    "        'cluster_neurons': [],\n",
    "        'spike_plotting_order': []\n",
    "    }\n",
    "\n",
    "    for i in range(len(r_seq_type)):\n",
    "        r_event_df = chunk_df[(chunk_df.timestamp >= r_start_[i]) & (chunk_df.timestamp <= r_end_[i])].copy()\n",
    "        neuron_orders = neuron_order[chunk_mask][(chunk_df.timestamp >= r_start_[i]) & (chunk_df.timestamp <= r_end_[i])]\n",
    "        neuron_orders = neuron_orders[r_event_df.sequence_type_adjusted == r_seq_type[i]]\n",
    "        r_event_df = r_event_df[r_event_df.sequence_type_adjusted == r_seq_type[i]]\n",
    "\n",
    "        if len(r_event_df) > 0:\n",
    "            num_spikes = len(r_event_df.sequence_type_adjusted)\n",
    "            num_neurons = len(r_event_df.neuron.unique())\n",
    "            first_spike = min(r_event_df.timestamp)\n",
    "            last_spike = max(r_event_df.timestamp)\n",
    "\n",
    "            if num_spikes >= min_spikes_filter and num_neurons >= min_neurons_involved_filter:\n",
    "                ax1.axvspan(first_spike, last_spike, color=colors[r_seq_type[i]], alpha=0.5)\n",
    "                filtered_data['cluster_seq_type'].append(r_seq_type[i])\n",
    "                filtered_data['num_spikes'].append(num_spikes)\n",
    "                filtered_data['num_neurons'].append(num_neurons)\n",
    "                filtered_data['first_spike_time'].append(first_spike)\n",
    "                filtered_data['event_length'].append(last_spike - first_spike)\n",
    "                filtered_data['last_spike_time'].append(last_spike)\n",
    "                filtered_data['cluster_spike_times'].append(list(r_event_df.timestamp.values))\n",
    "                filtered_data['cluster_neurons'].append(list(r_event_df.neuron.values))\n",
    "                filtered_data['spike_plotting_order'].append(neuron_orders)\n",
    "\n",
    "    filtered_r_clusters_df = pd.DataFrame(filtered_data)\n",
    "    filtered_r_clusters_df.to_csv(os.path.join(chunk_path, 'filtered_replay_clusters_df.csv'), index=False)\n",
    "    \n",
    "    print('###################################')\n",
    "    print('replay rate is')\n",
    "    print(len(filtered_r_clusters_df) / 10)\n",
    "    print('###################################')\n",
    "    \n",
    "    \n",
    "def SaveFig(file_name,figure_dir):\n",
    "    if not os.path.isdir(figure_dir):\n",
    "        os.makedirs(figure_dir)\n",
    "    plt.savefig(figure_dir + file_name,bbox_inches=0,transparent = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. i need to compare this to how many are found when running awake on awake without the shuffle...\n",
    "2. I think I need to do the linear replay check with the regression...\n",
    "3. i might need to make new data where i have sequences implanted into background - but the background is not shuffled noise but times when there are no sequneces occuring...ie. sythetic data but without the shuffled background noise. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data and filter for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 53] The network path was not found: 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\emmett_revisions\\\\Reveiw_Pre_sleep\\\\\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m      7\u001b[0m DAT_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprojects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msequence_squad\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124morganised_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124manimals\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# PP_PATH = r\"D:\\\\\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m######################################################################################################################################################################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# backgroudn confidence - spike had to be classified as a seq type 75% of the time across the last 50 iterations to be kept.   \u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m######################################################################################################################################################################################################################\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run_index,pp_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPP_PATH\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m::]):\n\u001b[0;32m     19\u001b[0m     \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     pp_file= '262_1_4_run_2106023_2357'\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m pp_file:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# load in paths for that specific mouse and recording\u001b[39;00m\n\u001b[0;32m     24\u001b[0m         mir,mouse_session_recording,save_path,tracking_path,dat_path \u001b[38;5;241m=\u001b[39m load_in_paths(pp_file, PP_PATH, DAT_PATH)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 53] The network path was not found: 'Z:\\\\projects\\\\sequence_squad\\\\revision_data\\\\emmett_revisions\\\\Reveiw_Pre_sleep\\\\\\\\'"
     ]
    }
   ],
   "source": [
    "ignore_list= []\n",
    "\n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\ppseq_output\\\\\"\n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\ppseq_output_not_shuffled\\\\\"#\n",
    "PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\Reveiw_Pre_sleep\\\\\"\n",
    "\n",
    "DAT_PATH = r\"Z:\\projects\\sequence_squad\\organised_data\\animals\\\\\"\n",
    "\n",
    "\n",
    "# PP_PATH = r\"D:\\\\\"\n",
    "\n",
    "######################################################################################################################################################################################################################\n",
    "# load in data, extract, filter PPseq spikes etc.\n",
    "# main filtering here:\n",
    "# backgroudn confidence - spike had to be classified as a seq type 75% of the time across the last 50 iterations to be kept.   \n",
    "######################################################################################################################################################################################################################\n",
    "\n",
    "for run_index,pp_file in enumerate(os.listdir(PP_PATH)[-2::]):\n",
    "    \n",
    "#     pp_file= '262_1_4_run_2106023_2357'\n",
    "    \n",
    "    if run_index >-1 and 'run' in pp_file:\n",
    "        # load in paths for that specific mouse and recording\n",
    "        mir,mouse_session_recording,save_path,tracking_path,dat_path = load_in_paths(pp_file, PP_PATH, DAT_PATH)\n",
    "        \n",
    "        ## load in PPseq output data\n",
    "        assignment_history_df,latent_event_history_df,seq_type_log_proportions_df,neuron_response_df,log_p_hist_df,unmasked_spikes_df,bkgd_log_proportions_array,behav_sync,transitions,behav_time_interval_start = load_PPSEQ_data(PP_PATH,pp_file,dat_path,mouse_session_recording)\n",
    "        # plot out log l curve \n",
    "        plot_save_log_l_curve(log_p_hist_df,save_path)\n",
    "        \n",
    "    # ---filter_across_itterations---------------------------------------------------------------------------------------------------------------------------------------------------------------    \n",
    "        # Initialize an empty df to store the result\n",
    "        seq_types_df = pd.DataFrame()\n",
    "        # Iterate through the range\n",
    "        # for iteration_ in tqdm(range(400, 500)):\n",
    "        for iteration_ in tqdm(range(250, 300)):\n",
    "            # Extract the relevant column from the assignment history dataframe\n",
    "            assignment_history_df_split = assignment_history_df[str(list(assignment_history_df)[iteration_])]\n",
    "            # Get the index of the -1 split markers in the latent event history dataframe\n",
    "            end_markers = latent_event_history_df.loc[latent_event_history_df['seq_type'] == -1.0].index\n",
    "            # Extract the relevant portion of the latent event history dataframe\n",
    "            latent_event_history_df_split =  latent_event_history_df[end_markers[iteration_-1]:end_markers[iteration_]]\n",
    "            # Create a dictionary from the dataframe for faster lookups\n",
    "            df_dict = latent_event_history_df_split.set_index('assignment_id')['seq_type'].to_dict()\n",
    "            # Match the sequence ID to the sequence type\n",
    "            seq_type = find_corresponding(assignment_history_df_split)\n",
    "            # Append the result to the df\n",
    "            seq_types_df[str(iteration_+1)] = seq_type\n",
    "        proportion = []\n",
    "        seq_type = []\n",
    "        for index in tqdm(range(len(seq_types_df))):\n",
    "            row = seq_types_df.loc[index]\n",
    "            seq_type += [statistics.mode(row)] \n",
    "            proportion += [np.count_nonzero(row == statistics.mode(row)) / len(row)]\n",
    "        # add seq type to dataframe\n",
    "        unmasked_spikes_df['sequence_type'] = seq_type\n",
    "        # add seq type to dataframe\n",
    "        unmasked_spikes_df['seq_confidence'] = proportion\n",
    "        \n",
    "        # ## filter for background confidence :-------------------------------------------------------------------------------------------------------------------------------------------------------------------    \n",
    "        thresh = max(proportion) *.75 ### \n",
    "        plt.plot(np.sort(proportion)[::-1])\n",
    "        plt.axhline(y = thresh, color = 'r', linestyle = '-')\n",
    "        unmasked_spikes_df['sequence_type_adjusted'] = seq_type\n",
    "        unmasked_spikes_df.sequence_type_adjusted[np.where(unmasked_spikes_df.seq_confidence < thresh)[0]] = -1\n",
    "        SaveFig('filtering_curve.png',save_path)\n",
    "        \n",
    "        ## load in colors and order from awake data -------------------------------------------------------------------------------------------------------------------------------------------------------------------    \n",
    "        awake_PP_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\awake\\\\\"\n",
    "        for file_ in os.listdir(awake_PP_path):\n",
    "            if mouse_session_recording in file_:\n",
    "                awake_file = file_\n",
    "        ordered_preferred_type = pd.read_pickle(awake_PP_path + awake_file + r\"\\analysis_output\\reordered_recolored\\\\\" + 'ordered_preferred_type')\n",
    "        neuron_index = pd.read_pickle(awake_PP_path + awake_file + r\"\\analysis_output\\reordered_recolored\\\\\" + 'neuron_index')\n",
    "        colors = pd.read_pickle(awake_PP_path + awake_file + r\"\\analysis_output\\reordered_recolored\\\\\" + 'colors')\n",
    "        spikes_df = unmasked_spikes_df\n",
    "        colors += ['pink','lightblue', 'k'] \n",
    "        \n",
    "        ############### plot simple rasters ------------------------------\n",
    "        interval_end_points,neuron_order = plot_data_raster(behav_time_interval_start, spikes_df, neuron_index, colors, 'all_data_raster.png')\n",
    "        \n",
    "        \n",
    "        # Constants\n",
    "        min_spikes_filter = 5\n",
    "        min_neurons_involved_filter = 3\n",
    "        bin_size = 0.02\n",
    "\n",
    "        # Main processing loop\n",
    "        chunk_paths = []\n",
    "        for index_, interval_start in enumerate([0] + list(interval_end_points)[:-1]):\n",
    "            chunk_path = os.path.join(save_path, f'chunk{index_+1}_{behav_time_interval_start[index_][0]}to{behav_time_interval_start[index_][1]}\\\\')\n",
    "            chunk_paths.append(chunk_path)\n",
    "            create_directory(chunk_path)\n",
    "\n",
    "            np.save(os.path.join(chunk_path, 'chunk_time_interval.npy'), np.array(behav_time_interval_start[index_]))\n",
    "\n",
    "            timeframe = [interval_start, interval_end_points[index_] - 1]\n",
    "            total_time = np.diff(timeframe)[0] + 1\n",
    "            mask = (spikes_df.timestamp > timeframe[0]) & (spikes_df.timestamp < timeframe[-1])\n",
    "\n",
    "            fig, [ax1, ax2] = plt.subplots(2, 1, figsize=(35, 15))\n",
    "\n",
    "            background_remove_mask = (spikes_df[mask].sequence_type_adjusted > -1) & (spikes_df[mask].sequence_type_adjusted < 7)\n",
    "            c_ = np.array(colors)[spikes_df[mask][background_remove_mask].sequence_type_adjusted.values.astype(int)]\n",
    "            ax1.scatter(spikes_df[mask][background_remove_mask].timestamp, neuron_order[mask][background_remove_mask], marker='o', s=40, linewidth=0, color=c_, alpha=1)\n",
    "\n",
    "            chunk_mask = (spikes_df.timestamp > interval_start) & (spikes_df.timestamp < interval_end_points[index_])\n",
    "            chunk_df = spikes_df[chunk_mask].copy().reset_index(drop=True)\n",
    "            chunk_df.to_csv(os.path.join(chunk_path, 'unfiltered_spikes_data.csv'), index=False)\n",
    "\n",
    "            seqs = np.unique(chunk_df.sequence_type_adjusted)\n",
    "            seq_spikes = [chunk_df.timestamp[chunk_df.sequence_type_adjusted == seq_type_].values for seq_type_ in seqs]\n",
    "            seq_neurons = [chunk_df.neuron[chunk_df.sequence_type_adjusted == seq_type_].values for seq_type_ in seqs]\n",
    "\n",
    "            binned_seq_r_events = [np.histogram(spikes_, bins=np.arange(interval_start, interval_end_points[index_], bin_size))[0] for spikes_ in seq_spikes]\n",
    "\n",
    "            strt_ = int(timeframe[0] / bin_size)\n",
    "            end_ = int(timeframe[1] / bin_size)\n",
    "\n",
    "            r_start_, r_end_, r_seq_type = [], [], []\n",
    "            for _index_, sequence_type in enumerate(seqs):\n",
    "                sequence_type = int(sequence_type)\n",
    "                if 0 < sequence_type <= 6:\n",
    "                    smoothed_binned_spikes = convolve_movmean(binned_seq_r_events[_index_], 2)\n",
    "                    time_bins = np.arange(timeframe[0], timeframe[0] + np.diff(timeframe) + 1, bin_size)\n",
    "                    ax2.plot(time_bins[:-1], smoothed_binned_spikes, c=colors[sequence_type])\n",
    "                    ax2.sharex(ax1)\n",
    "\n",
    "                    replay_chunks, indices = split_list(list(smoothed_binned_spikes))\n",
    "                    for index, chunk in enumerate(replay_chunks):\n",
    "                        r_seq_type.append(sequence_type)\n",
    "                        r_start_.append(time_bins[indices[index][0]])\n",
    "                        r_end_.append(time_bins[indices[index][-1]])\n",
    "\n",
    "            filter_and_save_replay_clusters(chunk_df, chunk_path, r_seq_type, r_start_, r_end_, colors, min_spikes_filter, min_neurons_involved_filter)\n",
    "\n",
    "            ax1.set_xlim(timeframe[0] + 140, timeframe[0] + 150)\n",
    "            ax2.set_xlim(timeframe[0] + 140, timeframe[0] + 150)\n",
    "\n",
    "            save_figure(fig, f'zoomed_data_filtering_chunk_{index_+1}.png', chunk_path)\n",
    "            plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:47<00:00,  5.97s/it]\n",
      "100%|██████████| 13/13 [01:49<00:00,  8.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# load in the shuffled data - extract number of sequenes found\n",
    "PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\ppseq_output\\\\\"\n",
    "shuffle_events_per_min = []\n",
    "for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "    file = os.listdir(PP_PATH)[iteration_]\n",
    "    data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "    clust_events_per_min = 0\n",
    "    all_chunks_len = 0\n",
    "    for file in os.listdir(data_path):\n",
    "        if 'chunk' in file:\n",
    "            current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "            replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "            if 'ordering_classification' in list(replay_clusts):\n",
    "                interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "                # only sequential events\n",
    "                clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "                all_chunks_len += interval_length/60\n",
    "    if all_chunks_len > 0:\n",
    "        shuffle_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "\n",
    "\n",
    "# load in the non shuffle - extract number of sequuences found \n",
    "PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\circular_shuffle\\ppseq_output_not_shuffled\\\\\"\n",
    "non_shuff_events_per_min = []\n",
    "for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "    file = os.listdir(PP_PATH)[iteration_]\n",
    "    data_path = os.path.join(PP_PATH,file)+ r'//_final_analysis_output//'\n",
    "    clust_events_per_min = 0\n",
    "    all_chunks_len = 0\n",
    "    for file in os.listdir(data_path):\n",
    "        if 'chunk' in file:\n",
    "            current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "            replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "            if 'ordering_classification' in list(replay_clusts):\n",
    "                interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "                # only sequential events\n",
    "                clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "                all_chunks_len += interval_length/60\n",
    "    if all_chunks_len > 0:\n",
    "        non_shuff_events_per_min += [clust_events_per_min/all_chunks_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shuffle_events_per_min\n",
    "\n",
    "non_shuff_events_per_min\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 5))\n",
    "\n",
    "ax.plot([0.2]*len(shuffle_events_per_min),shuffle_events_per_min,'o', color = 'blue')\n",
    "ax.plot([0.8]*len(non_shuff_events_per_min),non_shuff_events_per_min,'o', color = 'red')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['circular shuffle'] * len(shuffle_events_per_min)) + (['no shuffle'] * len(non_shuff_events_per_min)) , 'replay rate': list(shuffle_events_per_min)+list(non_shuff_events_per_min)})\n",
    "ax = sns.boxplot(y='replay rate', x='group', data=plt_df, color='blue', width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESLEEP ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [05:45<00:00, 11.14s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load in the presleep data - extract number of sequenes found\n",
    "PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\Reveiw_Pre_sleep\\\\\"\n",
    "presleep_events_per_min = []\n",
    "mirs = []\n",
    "for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "    file_ = os.listdir(PP_PATH)[iteration_]\n",
    "    data_path = os.path.join(PP_PATH,file_)+ r'//_final_analysis_output//'\n",
    "    clust_events_per_min = 0\n",
    "    all_chunks_len = 0\n",
    "    for file in os.listdir(data_path):\n",
    "        if 'chunk' in file:\n",
    "            current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "            replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "            if 'ordering_classification' in list(replay_clusts):\n",
    "                interval_length = int(file.split('_')[-1].split('to')[-1]) - int(file.split('_')[-1].split('to')[0])\n",
    "                # only sequential events\n",
    "                clust_events_per_min += len(replay_clusts[replay_clusts.ordering_classification == 'sequential'])\n",
    "                all_chunks_len += interval_length/60\n",
    "    if all_chunks_len > 0:\n",
    "        presleep_events_per_min += [clust_events_per_min/all_chunks_len]\n",
    "        mirs += [file_.split('_run')[0]]\n",
    "\n",
    "post_sleep_replay_rates = pd.read_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\replay_rate_old_data\\replay_rates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "\n",
    "for epms in presleep_events_per_min:\n",
    "    ax.plot(0.2,epms,'o', color = 'blue')\n",
    "    \n",
    "ps_rr = post_sleep_replay_rates.reactivations_per_min.values   \n",
    "ax.plot([0.8]*len(ps_rr),ps_rr,'o', color = 'red')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(presleep_events_per_min)) + (['post sleep'] * len(ps_rr)) , 'replay rate': list(presleep_events_per_min)+list(ps_rr)})\n",
    "ax = sns.boxplot(y='replay rate', x='group', data=plt_df, color='blue', width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "\n",
    "SaveFig('pre-post-replay-rate.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-2.6452936873802777, pvalue=0.00816200426767409)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Remove NaN values\n",
    "presleep_events_per_min_clean = np.array(presleep_events_per_min)[~np.isnan(presleep_events_per_min)]\n",
    "ps_rr_clean = np.array(ps_rr)[~np.isnan(ps_rr)]\n",
    "\n",
    "scipy.stats.shapiro(presleep_events_per_min_clean)\n",
    "scipy.stats.shapiro(ps_rr_clean)\n",
    "# non parametric\n",
    "\n",
    "#indipendent, Wilcoxon Rank-Sum test\n",
    "scipy.stats.ranksums(presleep_events_per_min_clean, ps_rr_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "for index, mir in enumerate(mirs):\n",
    "    pre_events = presleep_events_per_min[index]\n",
    "    if mir in post_sleep_replay_rates.mirs.values:\n",
    "        post_events = post_sleep_replay_rates[post_sleep_replay_rates.mirs == mir].reactivations_per_min.values[0]\n",
    "        ax.plot([0.2,0.8],[pre_events,post_events],'o-', color = 'k', alpha = 0.2)\n",
    "        \n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(presleep_events_per_min)) + (['post sleep'] * len(ps_rr)) , 'replay rate': list(presleep_events_per_min)+list(ps_rr)})\n",
    "ax = sns.boxplot(y='replay rate', x='group', data=plt_df, color='blue', width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "\n",
    "SaveFig('pre-post-replay-rate-connected.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "diffs = []\n",
    "for index, mir in enumerate(mirs):\n",
    "    pre_events = presleep_events_per_min[index]\n",
    "    if mir in post_sleep_replay_rates.mirs.values:\n",
    "        post_events = post_sleep_replay_rates[post_sleep_replay_rates.mirs == mir].reactivations_per_min.values[0]\n",
    "        diff = post_events - pre_events\n",
    "        diffs += [diff]\n",
    "        ax.plot([0.2],diff,'o', color = 'k', alpha = 0.2)\n",
    "        \n",
    "plt_df = pd.DataFrame({'group': (['replay rates'] * len(diffs)), 'difference: pre to post': diffs})\n",
    "ax = sns.boxplot(y='difference: pre to post', x='group', data=plt_df, width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "\n",
    "SaveFig('pre-post-replay-rate-diff.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess event details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [05:48<00:00, 11.25s/it]\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "PP_PATH =  r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\Reveiw_Pre_sleep\\\\\"\n",
    "\n",
    "# PP_PATH =  r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\paper_submission\\post_sleep\\\\\"\n",
    "number_of_spikes = []\n",
    "event_lengths = []\n",
    "number_of_neurons = []\n",
    "mirs = []\n",
    "for iteration_ in tqdm(range(len(os.listdir(PP_PATH)))):\n",
    "    file_ = os.listdir(PP_PATH)[iteration_]\n",
    "    data_path = os.path.join(PP_PATH,file_)+ r'//_final_analysis_output//'\n",
    "    chunk_number_of_spikes = []\n",
    "    chunk_event_lengths = []\n",
    "    chunk_number_of_neurons = []\n",
    "    for file in os.listdir(data_path):\n",
    "        if 'chunk' in file:\n",
    "            current_data_path = os.path.join(data_path,file)+ r'//'\n",
    "            replay_clusts = pd.read_csv(current_data_path + 'filtered_replay_clusters_df.csv')\n",
    "            if 'ordering_classification' in list(replay_clusts):\n",
    "                filtered_replay_clusts = replay_clusts[replay_clusts.ordering_classification == 'sequential']\n",
    "                chunk_number_of_spikes += [list(filtered_replay_clusts.num_spikes.values)]\n",
    "                chunk_event_lengths += [list(filtered_replay_clusts.event_length.values)]\n",
    "                n_neurons = []\n",
    "                for clusters in filtered_replay_clusts.cluster_neurons:\n",
    "                    n_neurons += [len(np.unique(literal_eval(clusters)))]\n",
    "                chunk_number_of_neurons += [n_neurons]\n",
    "                \n",
    "    mirs += [file_.split('_run')[0]]\n",
    "    number_of_spikes += [chunk_number_of_spikes]\n",
    "    event_lengths += [chunk_event_lengths]\n",
    "    number_of_neurons += [chunk_number_of_neurons]  \n",
    "    \n",
    "out_df = pd.DataFrame({'mirs':mirs,'number_of_spikes_per_event_per_chunk':number_of_spikes,'event_lengths_per_event_per_chunk':event_lengths,'number_of_neurons_per_event_per_chunk':number_of_neurons}) \n",
    "out_df.to_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\pre_sleep_processed_data\\presleep_event_details.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsleep_event_details = pd.read_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\pre_sleep_processed_data\\postsleep_event_details.csv\")\n",
    "presleep_event_details = pd.read_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\pre_sleep_processed_data\\presleep_event_details.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "mean_neurons = []\n",
    "for item in postsleep_event_details.event_lengths_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "pre_mean_neurons = []\n",
    "for item in presleep_event_details.event_lengths_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    pre_mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "\n",
    "ax.plot([0.8] * len(mean_neurons),mean_neurons,'o')\n",
    "ax.plot([0.2] * len(pre_mean_neurons),pre_mean_neurons,'o')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(pre_mean_neurons))+(['postsleep'] * len(mean_neurons)), 'mean event lengths (s)': pre_mean_neurons+mean_neurons})\n",
    "ax = sns.boxplot(y='mean event lengths (s)', x='group', data=plt_df, width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "\n",
    "SaveFig('pre-post-event-length.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9736347336727063, pvalue=0.6425938122325177)\n",
      "ShapiroResult(statistic=0.9745358066407458, pvalue=0.5444022319207653)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.681469325508937, pvalue=0.009281302676323199, df=65.0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import scipy\n",
    "\n",
    "# Remove NaN values\n",
    "presleep_clean = np.array(pre_mean_neurons)[~np.isnan(pre_mean_neurons)]\n",
    "post_clean = np.array(mean_neurons)[~np.isnan(mean_neurons)]\n",
    "\n",
    "print(scipy.stats.shapiro(presleep_clean))\n",
    "print(scipy.stats.shapiro(post_clean))\n",
    "\n",
    "#parametric\n",
    "\n",
    "# ind t test\n",
    "scipy.stats.ttest_ind(presleep_clean,post_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "mean_neurons = []\n",
    "for item in postsleep_event_details.number_of_neurons_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "pre_mean_neurons = []\n",
    "for item in presleep_event_details.number_of_neurons_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    pre_mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "\n",
    "ax.plot([0.8] * len(mean_neurons),mean_neurons,'o')\n",
    "ax.plot([0.2] * len(pre_mean_neurons),pre_mean_neurons,'o')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(pre_mean_neurons))+(['postsleep'] * len(mean_neurons)), 'neurons per event': pre_mean_neurons+mean_neurons})\n",
    "ax = sns.boxplot(y='neurons per event', x='group', data=plt_df, width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "SaveFig('neurons-per-event.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9426393607836691, pvalue=0.10714487311900522)\n",
      "ShapiroResult(statistic=0.9191407241432415, pvalue=0.010484009387248498)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-1.0339237932144132, pvalue=0.3011717908311138)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Remove NaN values\n",
    "presleep_clean = np.array(pre_mean_neurons)[~np.isnan(pre_mean_neurons)]\n",
    "post_clean = np.array(mean_neurons)[~np.isnan(mean_neurons)]\n",
    "\n",
    "print(scipy.stats.shapiro(presleep_clean))\n",
    "print(scipy.stats.shapiro(post_clean))\n",
    "\n",
    "#non parametric\n",
    "\n",
    "#indipendent, Wilcoxon Rank-Sum test\n",
    "scipy.stats.ranksums(presleep_clean,post_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\miniconda\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "mean_neurons = []\n",
    "for item in postsleep_event_details.number_of_spikes_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "pre_mean_neurons = []\n",
    "for item in presleep_event_details.number_of_spikes_per_event_per_chunk:    \n",
    "    flattened_list = [item for sublist in literal_eval(item) for item in sublist]\n",
    "    pre_mean_neurons += [np.mean(flattened_list)]\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "\n",
    "ax.plot([0.8] * len(mean_neurons),mean_neurons,'o')\n",
    "ax.plot([0.2] * len(pre_mean_neurons),pre_mean_neurons,'o')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(pre_mean_neurons))+(['postsleep'] * len(mean_neurons)), 'mean spikes per event': pre_mean_neurons+mean_neurons})\n",
    "ax = sns.boxplot(y='mean spikes per event', x='group', data=plt_df, width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "SaveFig('pre-post-spikes-per-event.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9736347336727063, pvalue=0.6425938122325177)\n",
      "ShapiroResult(statistic=0.9745358066407458, pvalue=0.5444022319207653)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-2.681469325508937, pvalue=0.009281302676323199, df=65.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "# Remove NaN values\n",
    "presleep_clean = np.array(pre_mean_neurons)[~np.isnan(pre_mean_neurons)]\n",
    "post_clean = np.array(mean_neurons)[~np.isnan(mean_neurons)]\n",
    "\n",
    "print(scipy.stats.shapiro(presleep_clean))\n",
    "print(scipy.stats.shapiro(post_clean))\n",
    "\n",
    "#parametric\n",
    "\n",
    "# ind t test\n",
    "scipy.stats.ttest_ind(presleep_clean,post_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# firing rate control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "presleep_average_firing_rates = pd.read_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\pre_sleep_processed_data\\presleep_average_firing_rates.csv\")\n",
    "postsleep_average_firing_rates = pd.read_csv(r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\replay_rate_old_data\\average_firing_rates.csv\")\n",
    "\n",
    "bool_1 = []\n",
    "for item in presleep_average_firing_rates.mirs:\n",
    "    if item in presleep_event_details.mirs.values:\n",
    "        bool_1 += [True]\n",
    "    else:\n",
    "        bool_1 += [False]\n",
    "        \n",
    "bool_2 = []\n",
    "for item in postsleep_average_firing_rates.mirs:\n",
    "    if item in postsleep_event_details.mirs.values:\n",
    "        bool_2 += [True]\n",
    "    else:\n",
    "        bool_2 += [False]\n",
    "        \n",
    "pre = presleep_average_firing_rates[bool_1].average_firing_rates.values\n",
    "post = postsleep_average_firing_rates[bool_2].average_firing_rates.values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 5))\n",
    "\n",
    "ax.plot([0.8] * len(pre),pre,'o')\n",
    "ax.plot([0.2] * len(post),post,'o')\n",
    "\n",
    "plt_df = pd.DataFrame({'group': (['presleep'] * len(pre))+(['postsleep'] * len(post)), 'mean firing rate (Hz)': list(pre)+list(post)})\n",
    "ax = sns.boxplot(y='mean firing rate (Hz)', x='group', data=plt_df, width=.2, zorder=10,\n",
    "                    showcaps=True, boxprops={'facecolor': 'none', \"zorder\": 10},\n",
    "                    showfliers=False, whiskerprops={'linewidth': 2, \"zorder\": 10},\n",
    "                    saturation=1, orient='v')\n",
    "\n",
    "SaveFig('pre-post-firing-rate-control.pdf',r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\phase1_plots\\presleep\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.951025621714755, pvalue=0.19460186435686694)\n",
      "ShapiroResult(statistic=0.9355716482703269, pvalue=0.037045802969689845)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RanksumsResult(statistic=-0.10557434432865279, pvalue=0.9159200812258538)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "print(scipy.stats.shapiro(pre))\n",
    "print(scipy.stats.shapiro(post))\n",
    "\n",
    "#non parametric\n",
    "\n",
    "#indipendent, Wilcoxon Rank-Sum test\n",
    "scipy.stats.ranksums(pre,post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
