{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJThompson 02/12/24\n",
    "\n",
    "## import functions from .py utils file: \n",
    "from Utilities.preprocessing import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set paths and params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_out = r'Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\sleep_wake_link_data\\raw_bpod_to_process\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\sleep_wake_link_data\\raw_bpod_to_process\\\\AP5_2_R_Sequence_Automated_20241117_101411.mat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m InputPathCurrent \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.DS_Store\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;66;03m#if file is not the weird hidden file \u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(InputPathCurrent)\n\u001b[1;32m---> 16\u001b[0m     Current_file \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mInputPathCurrent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     Behav_Data \u001b[38;5;241m=\u001b[39m Current_file\n\u001b[0;32m     18\u001b[0m     Sessions \u001b[38;5;241m=\u001b[39m Sessions \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Emmett Thompson\\Documents\\sequences_analyse_PPseq\\revision_analysis\\prioritisation_analysis\\sleep_behaviour_link\\Utilities\\preprocessing.py:47\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadmat\u001b[39m(filename):\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    this function should be called instead of direct spio.loadmat\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    as it cures the problem of not properly recovering python dictionaries\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    from mat files. It calls the function check keys to cure all entries\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    which are still mat-objects\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_as_record\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_keys(data)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_mio5_utils.pyx:665\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:965\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:965\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:965\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:734\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:11\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:18\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\miniconda\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1487\u001b[0m, in \u001b[0;36m_squeeze_dispatcher\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     a \u001b[38;5;241m=\u001b[39m concatenate((a,) \u001b[38;5;241m*\u001b[39m repeats)[:new_size]\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[1;32m-> 1487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_squeeze_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msqueeze\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# reloads imports (utils) if something changes\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#### MAIN ####\n",
    "for InputPath in os.listdir(in_out):\n",
    "    if 'fig' in InputPath:\n",
    "        continue\n",
    "    \n",
    "    InputPathCurrent = os.path.join(in_out, InputPath)\n",
    "    \n",
    "    if InputPathCurrent[-2] == 'a': #if its a .mat and not a fig\n",
    "        if os.stat(InputPathCurrent).st_size > 200000: #more thann 200kb \n",
    "            if InputPathCurrent != '.DS_Store': #if file is not the weird hidden file \n",
    "                print(InputPathCurrent)\n",
    "                Current_file = loadmat(InputPathCurrent)\n",
    "                Behav_Data = Current_file\n",
    "                Sessions = Sessions + 1\n",
    "                File_dates = File_dates + [InputPathCurrent[-19:-4]]\n",
    "    \n",
    "    display(HTML(f\"<b>Processing data for: {InputPath}</b>\"))\n",
    "    # InputPathCurrent = (InputPath + CurrentAnimal + r'\\Sequence_Automated\\Session Data\\\\')\n",
    "    \n",
    "    Save_path = os.path.join(in_out,InputPath.split('Sequence')[0] + InputPath.split('_')[-2])\n",
    "\n",
    "    #Convert to python friendly format:\n",
    "    convert_nested_structs(Behav_data)\n",
    "    # Extract GUI info\n",
    "    Trial_settings = todict(Behav_data['SessionData']['TrialSettings'][0])\n",
    "    FinalRewardAmount = []\n",
    "    for item in Behav_data['SessionData']['SessionVariables']['TLevel']:\n",
    "        TLevel = item\n",
    "        FinalRewardAmount = FinalRewardAmount + [Behav_data['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][4]]\n",
    "\n",
    "    # save out training levels on their own\n",
    "    filename = 'Preprocessed_TrainingLevels' \n",
    "    with open(Save_path + '\\\\'+ filename, 'wb') as fp:\n",
    "        pickle.dump(Behav_data['SessionData']['SessionVariables']['TLevel'], fp)\n",
    "\n",
    "    # save out led intensites and reward amounts on their own:\n",
    "    LED_Intensities = pd.DataFrame({'Port2':Behav_data['SessionData']['SessionVariables']['LEDIntensitys']['port2'],\n",
    "                            'Port3':Behav_data['SessionData']['SessionVariables']['LEDIntensitys']['port3'],\n",
    "                            'Port4':Behav_data['SessionData']['SessionVariables']['LEDIntensitys']['port4'],\n",
    "                            'Port5':Behav_data['SessionData']['SessionVariables']['LEDIntensitys']['port5']})\n",
    "    LED_Intensities.to_csv(Save_path + '/Preprocessed_LED_Intensities.csv')\n",
    "    RewardAmounts = pd.DataFrame({'Port1':Behav_data['SessionData']['SessionVariables']['RewardAmount']['port1'],\n",
    "                                    'Port2':Behav_data['SessionData']['SessionVariables']['RewardAmount']['port2'],\n",
    "                                    'Port3':Behav_data['SessionData']['SessionVariables']['RewardAmount']['port3'],\n",
    "                                    'Port4':Behav_data['SessionData']['SessionVariables']['RewardAmount']['port4']})\n",
    "    RewardAmounts.to_csv(Save_path + '/Preprocessed_RewardAmounts.csv')\n",
    "\n",
    "\n",
    "\n",
    "    #Extract PortIn times for each port and check for errors (inside this function):\n",
    "    All_PortIn_Times,All_PortOut_Times,All_Port_references = extract_poke_times(Behav_data)\n",
    "\n",
    "    \n",
    "    #remove nans (times when part [in or out poke] of the event was dropped for some reason by bpod)\n",
    "    All_PortIn_Times_fixed,All_PortOut_Times_fixed ,All_Port_references_fixed = remove_dropped_in_events(All_PortIn_Times,All_PortOut_Times,All_Port_references)\n",
    "    \n",
    "    # Resort these in time:\n",
    "    All_PortIn_Times_sorted,All_PortOut_Times_sorted,All_Port_references_sorted = time_sort(All_PortIn_Times,All_PortOut_Times,All_Port_references)\n",
    "    \n",
    "    #fix stupid error that suddently appeared\n",
    "    if len(All_Port_references_sorted) == 1:\n",
    "        All_Port_references_sorted = All_Port_references_sorted[0]\n",
    "        All_PortIn_Times_sorted = All_PortIn_Times_sorted[0]\n",
    "        All_PortOut_Times_sorted = All_PortOut_Times_sorted[0]\n",
    "    #extract reward times:\n",
    "    Reward_ts = extract_reward_times(Behav_data)\n",
    "\n",
    "    # find reward inds and align rewarded ts to poke events:\n",
    "    Rewarded_event_inds = find_reward_inds(All_PortIn_Times_sorted,All_Port_references_sorted,Reward_ts)\n",
    "    Reward_ts = np.asarray(Reward_ts)\n",
    "    Reward_ts = Reward_ts[np.logical_not(np.isnan(Reward_ts))]\n",
    "    Reward_ts = list(Reward_ts)\n",
    "    Reward_ts_aligned = align_trigger_to_index(Reward_ts,Rewarded_event_inds,All_Port_references_sorted)\n",
    "\n",
    "    #extract trial start time stamps\n",
    "    Trial_start_ts = extract_trial_timestamps(Behav_data)\n",
    "\n",
    "    #extract trial end times:\n",
    "    Trial_end_ts = extract_trial_end_times(Behav_data)\n",
    "\n",
    "    #determine trial IDs\n",
    "    trial_id = determine_trial_id(All_PortIn_Times_sorted,Trial_end_ts)\n",
    "\n",
    "    # align trial start and end times to poke events\n",
    "    trialstart_index = find_trialstart_index(trial_id)\n",
    "    trial_start_ts_aligned = align_trial_start_end_timestamps(trial_id,trialstart_index,Trial_start_ts)\n",
    "    trial_end_ts_aligned = align_trial_start_end_timestamps(trial_id,trialstart_index,Trial_end_ts)\n",
    "\n",
    "    # optostim data:\n",
    "    if Trial_settings['GUI']['OptoStim'] == 1: \n",
    "        ## save out opto settings as a dataframe\n",
    "        Opto_StimPoke = Trial_settings['GUI']['StimPoke']\n",
    "        Opto_PulsePower = Trial_settings['GUI']['PulsePower']\n",
    "        Opto_OptoChance = Trial_settings['GUI']['OptoChance']\n",
    "        Opto_PulseDuration = Trial_settings['GUI']['PulseDuration']\n",
    "        Opto_PulseInterval = Trial_settings['GUI']['PulseInterval']\n",
    "        Opto_TrainDuration = Trial_settings['GUI']['TrainDuration']\n",
    "        #create opto dataframe\n",
    "        Opto_settings = pd.DataFrame(\n",
    "        {'StimPoke' : [Opto_StimPoke],\n",
    "            'PulsePower':[Opto_PulsePower],\n",
    "            'OptoChance':[Opto_OptoChance],\n",
    "            'PulseDuration' : [Opto_PulseDuration],\n",
    "            'PulseInterval':[Opto_PulseInterval],\n",
    "            'TrainDuration':[Opto_TrainDuration]})\n",
    "        #save\n",
    "        Opto_settings.to_csv(Save_path + '/Opto_settings.csv')\n",
    "\n",
    "        #pull out optotrials from data\n",
    "        optotrials = Behav_data['SessionData']['SessionVariables']['OptoStim']\n",
    "        #align these to dataframe:\n",
    "        executed_optotrials = optotrials[0:trial_id[-1]]\n",
    "        optotrials_aligned = align_opto_trials_to_dataframe(trial_id,executed_optotrials)\n",
    "    else:\n",
    "        #no optostim so fill this column with NaNs\n",
    "        optotrials_aligned = ['NaN'] * len(trial_id)\n",
    "\n",
    "    #determine LED and reward states for each trial and align them to trials:\n",
    "    IntermediateRewards = []\n",
    "    LED_intensities = []\n",
    "    for item in Behav_data['SessionData']['SessionVariables']['TLevel']:\n",
    "        TLevel = item\n",
    "        IntermediateRewards = IntermediateRewards + [list(Behav_data['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][0:4])]\n",
    "        LED_intensities = LED_intensities + [list(Behav_data['SessionData']['SessionVariables']['TrainingLevels'][TLevel-1][6:10])]\n",
    "    aligned_LED_intensities = align_trial_start_end_timestamps(trial_id,trialstart_index,LED_intensities)\n",
    "    aligned_IntermediateRewards = align_trial_start_end_timestamps(trial_id,trialstart_index,IntermediateRewards)\n",
    "\n",
    "    # #Search for timestamps for given animal and session \n",
    "    # TimeStampsExist, TimeStampPath = FindTimestamps(filedate,CameraPath,CurrentAnimal)\n",
    "\n",
    "    # if TimeStampsExist:\n",
    "    #     print('Timestamps Found')\n",
    "    #     #Load camera timestamps:\n",
    "    #     Camera_ts_raw = load_camera_timestamps(TimeStampPath)\n",
    "    #     #Convert to seconds and uncycle:\n",
    "    #     Camera_ts = convert_uncycle_Timestamps(Camera_ts_raw)\n",
    "    #     #check for dropped frames:\n",
    "    #     check_timestamps(Camera_ts, Frame_rate = 40)\n",
    "    #     # Find triggers:\n",
    "    #     Camera_trig_states = find_trigger_states(Camera_ts_raw)\n",
    "    #     #check if triggers are working:\n",
    "    #     result = np.max(Camera_trig_states) == np.min(Camera_trig_states)\n",
    "    #     if not result:\n",
    "    #         # make camera dataframe:\n",
    "    #         Camera_dataframe = pd.DataFrame(\n",
    "    #             {'Time Stamps': Camera_ts,\n",
    "    #             'Trigger State': Camera_trig_states,\n",
    "    #             'DataPath': ([TimeStampPath] * len(Camera_ts))})\n",
    "\n",
    "    #         #Save Data\n",
    "    #         Camera_dataframe.to_csv(Save_path + '/PreProcessed_CameraData.csv')\n",
    "\n",
    "    #         #find camera inds that align with trigger start and stop events (trial start and first poke):\n",
    "    #         Trial_start_camera_inds,Poke1_camera_inds = Find_TrialStart_and_Poke1_camera_inds(Camera_trig_states)\n",
    "    #         #align behavioural data (trial starts) with camera timestamps \n",
    "    #         Trial_start_Camera_Ts_aligned = align_trial_start_end_timestamps(trial_id,trialstart_index,Camera_ts[Trial_start_camera_inds])\n",
    "            \n",
    "            \n",
    "\n",
    "    #         #align behavioural data (trial ends) with camera timestamps \n",
    "    #         Trial_end_Camera_Ts_aligned = generate_aligned_trial_end_camera_ts(Trial_start_camera_inds,trial_id,trialstart_index,Camera_ts)\n",
    "    #         #align behavioural data (first poke in port1) with camera timestamps \n",
    "    #         First_poke_Camera_Ts_aligned = align_firstpoke_camera_timestamps(trial_id,trialstart_index,Camera_ts[Poke1_camera_inds],All_Port_references_sorted)\n",
    "        \n",
    "    #     else:\n",
    "    #         print('Triggers Broken')\n",
    "    #         TimeStampsExist = False\n",
    "    #         Trial_start_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "    #         Trial_end_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "    #         First_poke_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "    # else:\n",
    "    Trial_start_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "    Trial_end_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "    First_poke_Camera_Ts_aligned = ['NaN'] * len(trial_id)\n",
    "\n",
    "    ## align Training level for each trial:\n",
    "    Training_Levels = align_opto_trials_to_dataframe(trial_id,Behav_data['SessionData']['SessionVariables']['TLevel'])\n",
    "\n",
    "    # make portin dataframe:\n",
    "    PortIn_df = pd.DataFrame(\n",
    "        {'Trial_id' : trial_id,\n",
    "            'Trial_Start' : trial_start_ts_aligned,\n",
    "            'Port': All_Port_references_sorted,\n",
    "            'PokeIn_Time': All_PortIn_Times_sorted,\n",
    "            'PokeOut_Time': All_PortOut_Times_sorted,\n",
    "            'Reward_Times': Reward_ts_aligned,\n",
    "            'Trial_End' : trial_end_ts_aligned,\n",
    "            'Trial_Start_Camera_Time':Trial_start_Camera_Ts_aligned,\n",
    "            'Trial_End_Camera_Time':Trial_end_Camera_Ts_aligned,\n",
    "            'First_poke_camera_timestamp': First_poke_Camera_Ts_aligned,\n",
    "            'Port 2,3,4,5 LED intensities': aligned_LED_intensities,\n",
    "            'Port 1,2,3,4 RewardAmount':aligned_IntermediateRewards,\n",
    "            'OptoCondition':optotrials_aligned,\n",
    "        'TrainingLevel': Training_Levels})\n",
    "    \n",
    "    #Save Data\n",
    "    PortIn_df.to_csv(Save_path +'/PreProcessed_RawPokeData.csv')\n",
    "\n",
    "    #PART2##########################Transitions:\n",
    "\n",
    "    #Determine Transition times and types for all events \n",
    "    ##old way:\n",
    "#             Transition_times, Transition_types,transition_reference_time = Determine_Transition_Times_and_Types(All_PortIn_Times_sorted , All_Port_references_sorted)\n",
    "    out_in_Transition_times, in_in_Transition_times, Transition_types, out_in_transition_reference,in_in_transition_reference = Determine_Transition_Times_and_Types(All_PortIn_Times_sorted ,All_PortOut_Times_sorted, All_Port_references_sorted)\n",
    "    \n",
    "    \n",
    "    #Split transtion types into first and last ports: \n",
    "    start_port_ids = Start_End_port_id(Transition_types,0)\n",
    "    end_port_ids = Start_End_port_id(Transition_types,1)\n",
    "    #Align start and end port times\n",
    "    End_Port_in_time = All_PortIn_Times_sorted[1::]\n",
    "    Start_Port_in_time = All_PortIn_Times_sorted[0:-1]\n",
    "    End_Port_out_time = All_PortOut_Times_sorted[1::]\n",
    "    Start_Port_out_time = All_PortOut_Times_sorted[0:-1]\n",
    "    #Find Port repeat events (double pokes)\n",
    "    Non_Port_repeat = determine_RepeatPort_events(start_port_ids,end_port_ids)\n",
    "    #Determine which transitions are good: less than 1.5s\n",
    "    out_in_Filtered_transitions = filter_transitons_by_latency(out_in_Transition_times, 2)\n",
    "    in_in_Filtered_transitions = filter_transitons_by_latency(in_in_Transition_times, 2)\n",
    "\n",
    "    # if TimeStampsExist:\n",
    "    #     # Align camera ts to each transition event \n",
    "    #     ## calculate from each time stamp\n",
    "    #     first_port_camera_ts = port_events_in_camera_time(trial_start_ts_aligned,Start_Port_in_time,Trial_start_Camera_Ts_aligned)\n",
    "    #     second_port_camera_ts = first_port_camera_ts + in_in_Transition_times\n",
    "    # else:\n",
    "    first_port_camera_ts = ['NaN'] * len(Transition_types)\n",
    "    second_port_camera_ts = ['NaN'] * len(Transition_types)\n",
    "\n",
    "    # make dataframe:\n",
    "    Transition_df = pd.DataFrame(\n",
    "        {'Trial_id' : trial_id[0:-1],\n",
    "        'Transition_type' : Transition_types,\n",
    "            'Start_Port':start_port_ids, \n",
    "            'End_Port':end_port_ids,\n",
    "            'Start_Poke_in_time': Start_Port_in_time,\n",
    "            'Start_Poke_out_time': Start_Port_out_time,\n",
    "            'End_Poke_in_time': End_Port_in_time,\n",
    "            'End_Poke_out_time': End_Port_out_time,\n",
    "            'out_in_Latency' : out_in_Transition_times,\n",
    "            'in_in_Latency': in_in_Transition_times,\n",
    "            'First_port_in_camera_time':first_port_camera_ts,\n",
    "            'Second_port_in_camera_time':second_port_camera_ts,\n",
    "            'Repeat_Filter':Non_Port_repeat,\n",
    "            '2s_Time_Filter_out_in': out_in_Filtered_transitions,\n",
    "            '2s_Time_Filter_in_in': in_in_Filtered_transitions,\n",
    "            'OptoCondition':optotrials_aligned[0:-1],\n",
    "            'TrainingLevel': Training_Levels[0:-1],\n",
    "            'Port 2,3,4,5 LED intensities': aligned_LED_intensities[0:-1],\n",
    "            'Port 1,2,3,4 RewardAmount':aligned_IntermediateRewards[0:-1]})\n",
    "    #Save Data\n",
    "    Transition_df.to_csv(Save_path + '/PreProcessed_TransitionData.csv')\n",
    "\n",
    "    #PART3#########################Sequences:\n",
    "\n",
    "    # Define useful port/seq related information\n",
    "    port1 = Behav_data['SessionData']['TrialSequence'][0][0]\n",
    "    port2 = Behav_data['SessionData']['TrialSequence'][0][1]\n",
    "    port3 = Behav_data['SessionData']['TrialSequence'][0][2]\n",
    "    port4 = Behav_data['SessionData']['TrialSequence'][0][3]\n",
    "    port5 = Behav_data['SessionData']['TrialSequence'][0][4]\n",
    "    sequence1 = int(str(port1) + str(port2))\n",
    "    sequence2 = int(str(port2) + str(port3))\n",
    "    sequence3 = int(str(port3) + str(port4))\n",
    "    sequence4 = int(str(port4) + str(port5))\n",
    "\n",
    "    #Filter transitons into sequences for each port by finding port and then transitions that happen after that port which are in a string that satisfies the transition filter time\n",
    "    # there is now a lower filter - ie. any sequences that are shorter than 0.05 are discounted:\n",
    "    ## these are from in to in as we dont care about transiton times, just poke in times for eahc port \n",
    "    Port1_Time_Filtered_seq_ids,Port1_Time_Filtered_seq_times,Port1_Reference_times = CreateSequences_TimeandPort(Transition_types,in_in_Transition_times,port1,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "    Port2_Time_Filtered_seq_ids,Port2_Time_Filtered_seq_times,Port2_Reference_times = CreateSequences_TimeandPort(Transition_types,in_in_Transition_times,port2,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "    Port3_Time_Filtered_seq_ids,Port3_Time_Filtered_seq_times,Port3_Reference_times = CreateSequences_TimeandPort(Transition_types,in_in_Transition_times,port3,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "    Port4_Time_Filtered_seq_ids,Port4_Time_Filtered_seq_times,Port4_Reference_times = CreateSequences_TimeandPort(Transition_types,in_in_Transition_times,port4,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "    Port5_Time_Filtered_seq_ids,Port5_Time_Filtered_seq_times,Port5_Reference_times = CreateSequences_TimeandPort(Transition_types,in_in_Transition_times,port5,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "\n",
    "    #Filter transitons into sequences that are within the transition filter time (not filtered to start at first poke):\n",
    "    Time_Filtered_seq_ids,Time_Filtered_seq_times,Reference_times = CreateSequences_Time(Transition_types,out_in_Transition_times,port1,in_in_transition_reference,Transition_filter_time = 2.0)\n",
    "\n",
    "    # make dataframes:\n",
    "    Sequence_df_timefiltered_port1aligned = pd.DataFrame(\n",
    "        {'Sequence_ids' : Port1_Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Port1_Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Port1_Reference_times})\n",
    "    Sequence_df_timefiltered_port2aligned = pd.DataFrame({\n",
    "            'Sequence_ids' : Port2_Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Port2_Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Port2_Reference_times})\n",
    "    Sequence_df_timefiltered_port3aligned = pd.DataFrame({    \n",
    "            'Sequence_ids' : Port3_Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Port3_Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Port3_Reference_times})\n",
    "    Sequence_df_timefiltered_port4aligned = pd.DataFrame({     \n",
    "            'Sequence_ids' : Port4_Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Port4_Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Port4_Reference_times})\n",
    "    Sequence_df_timefiltered_port5aligned = pd.DataFrame({\n",
    "            'Sequence_ids' : Port5_Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Port5_Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Port5_Reference_times})\n",
    "\n",
    "    Sequence_timefilteredonly_df = pd.DataFrame(\n",
    "        {'Sequence_ids' : Time_Filtered_seq_ids,\n",
    "            'Sequence_times':Time_Filtered_seq_times,\n",
    "            'SessionTime_Reference':Reference_times})\n",
    "\n",
    "    #Save Data\n",
    "    Sequence_df_timefiltered_port1aligned.to_csv(Save_path + '/PreProcessed_Sequence_df_timefiltered_port1aligned.csv')\n",
    "    Sequence_df_timefiltered_port2aligned.to_csv(Save_path + '/PreProcessed_Sequence_df_timefiltered_port2aligned.csv')\n",
    "    Sequence_df_timefiltered_port3aligned.to_csv(Save_path + '/PreProcessed_Sequence_df_timefiltered_port3aligned.csv')\n",
    "    Sequence_df_timefiltered_port4aligned.to_csv(Save_path + '/PreProcessed_Sequence_df_timefiltered_port4aligned.csv')\n",
    "    Sequence_df_timefiltered_port5aligned.to_csv(Save_path + '/PreProcessed_Sequence_df_timefiltered_port5aligned.csv')\n",
    "\n",
    "    Sequence_timefilteredonly_df.to_csv(Save_path + '/PreProcessed_Sequence_timefilteredonly_df.csv')\n",
    "\n",
    "    #Make final session information dataframe\n",
    "    TrainingLevels = list(Trial_settings['GUIMeta']['TrainingLevel']['String'])\n",
    "    SessionLevel = Trial_settings['GUI']['TrainingLevel']\n",
    "    no_rewarded_events = number_of_rewarded_events(Reward_ts_aligned)\n",
    "    \n",
    "    #experiment or training session:\n",
    "    if Trial_settings['GUI']['ExperimentType'] == 2:\n",
    "        Experiment = 1\n",
    "    else:\n",
    "        Experiment = 0\n",
    "\n",
    "    Session_information = pd.DataFrame(\n",
    "        {'Port1' : [port1],\n",
    "            'Port2':[port2],\n",
    "            'Port3':[port3],\n",
    "            'Port4':[port4],\n",
    "            'Port5':[port5],\n",
    "        'Transition1':sequence1,\n",
    "        'Transition2':sequence2,\n",
    "        'Transition3':sequence3,\n",
    "        'Transition4':sequence4,\n",
    "        'n_Trials': trial_id[-1],\n",
    "        'n_rewards': no_rewarded_events,\n",
    "        'FinalRewardAmount': [FinalRewardAmount],\n",
    "        'SessionLevel':[TLevel],\n",
    "        'Experiment':Experiment,\n",
    "        'CameraData': TimeStampsExist,})\n",
    "\n",
    "    #Save Data\n",
    "    Session_information.to_csv(Save_path + '/PreProcessed_SessionInfo.csv')\n",
    "    Processed = (Processed + str(Session) +',')\n",
    "else:\n",
    "    Skipped = (Skipped + str(Session) +',')\n",
    "    if len(Skipped) == 0:\n",
    "        Skipped == 'None'\n",
    "    if len(Processed) == 0:\n",
    "        Processed == 'None'\n",
    "    print('Already Processed so skipped: ' + Skipped)\n",
    "    print('Processed: ' + Processed)\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
