{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "\n",
    "def assign_to_group(mouse,expert_mice,hlesion_mice,learning_mice,var_dict):\n",
    "    # if session in one of the groups (and define which)   \n",
    "    if mouse in list(expert_mice) + list(hlesion_mice) + list(learning_mice):\n",
    "        if mouse in expert_mice:\n",
    "            var_dict['expert'] += [1]\n",
    "            var_dict['hlesion'] += [0]\n",
    "            var_dict['learning'] += [0]               \n",
    "        elif mouse in hlesion_mice:                \n",
    "            var_dict['expert'] += [0]\n",
    "            var_dict['hlesion'] += [1]\n",
    "            var_dict['learning'] += [0]   \n",
    "        elif mouse in learning_mice:                \n",
    "            var_dict['expert'] += [0]\n",
    "            var_dict['hlesion'] += [0]\n",
    "            var_dict['learning'] += [1]   \n",
    "    return var_dict\n",
    "\n",
    "def get_time_span(dat_path,pp_file,mouse):\n",
    "    with open(dat_path + pp_file + r'\\trainingData\\\\' + 'params_' + mouse + '.json', 'r') as file:\n",
    "        params = json.load(file)\n",
    "    time_spans = params['time_span']\n",
    "    return time_spans\n",
    "\n",
    "def find_useable_mouse_paths(sleep_ppseq_path,useable_mirs,expert_mice,hlesion_mice,learning_mice,var_dict,sleep_start):\n",
    "    current_mouse_path = []\n",
    "    for run_index,pp_file in enumerate(os.listdir(sleep_ppseq_path)):\n",
    "        if not 'sleep_time_points' in pp_file:\n",
    "            # current mouse\n",
    "            mouse = '_'.join(pp_file.split('_')[0:3])    \n",
    "\n",
    "            if mouse in useable_mirs:\n",
    "                    #print out progress\n",
    "                    print(f\"run index: {run_index}, processing {mouse}\")\n",
    "                    \n",
    "                    # asign to experimental group in var_dict\n",
    "                    var_dict = assign_to_group(mouse,expert_mice,hlesion_mice,learning_mice,var_dict)\n",
    "\n",
    "                    # load in sleep start time and time span\n",
    "                    var_dict['current_sleep_start'] += sleep_start[mouse]\n",
    "                    var_dict['time_spans'] += get_time_span(sleep_ppseq_path,pp_file,mouse)\n",
    "\n",
    "                    # set path to processed files \n",
    "                    current_mouse_path += [sleep_ppseq_path + pp_file + '\\\\analysis_output\\\\']\n",
    "                    var_dict['mirs'] += [mouse]\n",
    "    return current_mouse_path,var_dict\n",
    "\n",
    "\n",
    "def make_filter_masks(data,sequential_filter,nrem_filter,rem_filter,sleep_filters_on,background_only):\n",
    "    ## filter this data\n",
    "    if sequential_filter == True: \n",
    "        sequential_condition = data.ordering_classification == 'sequential'\n",
    "    else:\n",
    "        sequential_condition = np.array([True]*len(data.ordering_classification))\n",
    "\n",
    "    if sleep_filters_on == True:\n",
    "        if nrem_filter == True: \n",
    "            nrem_condition = data.nrem_events == 1\n",
    "        else:\n",
    "            nrem_condition = np.array([False]*len(data.nrem_events))\n",
    "\n",
    "        if rem_filter == True: \n",
    "            rem_condition = data.rem_events == 1\n",
    "        else:\n",
    "            rem_condition = np.array([False]*len(data.rem_events))\n",
    "\n",
    "        if background_only == True:\n",
    "            rem_condition = data.rem_events == 0\n",
    "            nrem_condition = data.nrem_events == 0\n",
    "\n",
    "    else:\n",
    "        nrem_condition = np.array([True]*len(data))\n",
    "        rem_condition = np.array([True]*len(data))\n",
    "        \n",
    "    # filter is set up so that any true will carry forward \n",
    "    filter_mask = sequential_condition * (nrem_condition + rem_condition)\n",
    "        \n",
    "    return filter_mask\n",
    "\n",
    "def determine_chunk_mins(chunk_time,sleep_filters_on,nrem_filter,rem_filter,background_only,path):\n",
    "    # if sleep_filters_on is false, use all chunk time\n",
    "    if sleep_filters_on == False:\n",
    "        mins = np.diff(chunk_time)[0]\n",
    "    else:\n",
    "        # load in state times\n",
    "        rem_state_times = np.load(path + 'rem_state_times.npy')\n",
    "        nrem_state_times = np.load(path + 'nrem_state_times.npy')\n",
    "        if len(rem_state_times) > 0:\n",
    "            tot_rem = sum(np.diff(rem_state_times))[0]\n",
    "        else:\n",
    "            tot_rem = 0\n",
    "        if len(nrem_state_times) > 0:\n",
    "            tot_nrem = sum(np.diff(nrem_state_times))[0]\n",
    "        else:\n",
    "            tot_nrem = 0\n",
    "\n",
    "        # if background then use all non rem and non nrem times\n",
    "        if background_only:\n",
    "            mins = np.diff(chunk_time)[0] - (tot_rem+tot_nrem)\n",
    "        else:\n",
    "            # if both, use both \n",
    "            if nrem_filter == True and rem_filter == True:\n",
    "                mins = tot_rem+tot_nrem\n",
    "            elif nrem_filter == True and rem_filter == False:\n",
    "                mins = tot_nrem\n",
    "            elif nrem_filter == False and rem_filter == True:\n",
    "                mins = tot_rem\n",
    "    # convert to mins            \n",
    "    mins = mins/60\n",
    "    \n",
    "    return mins\n",
    "\n",
    "def cluster_events(start_times, end_times, threshold):\n",
    "    clusters = []\n",
    "    for i in range(len(start_times)):\n",
    "        event_added = False\n",
    "        for cluster in clusters:\n",
    "            for index in cluster:\n",
    "                if (start_times[i] <= end_times[index] + threshold and end_times[i] >= start_times[index] - threshold):\n",
    "                    cluster.append(i)\n",
    "                    event_added = True\n",
    "                    break\n",
    "            if event_added:\n",
    "                break\n",
    "        if not event_added:\n",
    "            clusters.append([i])\n",
    "    return clusters\n",
    "\n",
    "def relative_dict(input_dict):\n",
    "    total_sum = sum(input_dict.values())\n",
    "    relative_dict = {key: value / total_sum for key, value in input_dict.items()}\n",
    "    return relative_dict\n",
    "\n",
    "def refind_cluster_events(filtered_chunk_data,event_proximity_filter):\n",
    "    \n",
    "    ### ignore the origonal clusterg rosp and remake them: \n",
    "    start_times = filtered_chunk_data.first_spike_time.values\n",
    "    end_times = filtered_chunk_data.last_spike_time.values\n",
    "\n",
    "    clustered_events = cluster_events(start_times, end_times,event_proximity_filter)\n",
    "\n",
    "    cluster_group = np.zeros(len(filtered_chunk_data))\n",
    "    for index,cluster in enumerate(clustered_events):\n",
    "        for item in cluster:\n",
    "            cluster_group[item] = int(index)\n",
    "    filtered_chunk_data['coactive_cluster_group'] = cluster_group\n",
    "    \n",
    "    return filtered_chunk_data\n",
    "\n",
    "def coactive_rate(filtered_chunk_data):\n",
    "    # work out how mnay coacitve in chunk: \n",
    "    current_coactive_freqs_chunk = {}\n",
    "    for cluster in filtered_chunk_data.coactive_cluster_group.unique():\n",
    "        num = list(filtered_chunk_data.coactive_cluster_group.values).count(cluster)\n",
    "        if num in current_coactive_freqs_chunk:\n",
    "            current_coactive_freqs_chunk[num] += 1\n",
    "        else:\n",
    "            current_coactive_freqs_chunk[num] = 1\n",
    "            \n",
    "    # proportion of all single events that are cocaitve with at least one other\n",
    "    cocative_total = 0\n",
    "    for item in list(current_coactive_freqs_chunk):\n",
    "        if item > 1:\n",
    "            cocative_total += current_coactive_freqs_chunk[item] * item \n",
    "    proportion_single_events_coacitvely_paired = cocative_total/(cocative_total + current_coactive_freqs_chunk[1])\n",
    "\n",
    "    # av_coactive_length (only coactive, ignore single events)\n",
    "    avs =[]\n",
    "    for item in current_coactive_freqs_chunk:\n",
    "        if item > 1:\n",
    "            avs += current_coactive_freqs_chunk[item] * [item]\n",
    "    av_coactive_len_per_chunk = np.mean(avs)\n",
    "\n",
    "    # proportion of events that are coactive (counting coative evetns as one)\n",
    "    proporiton_of_events_coactive = len(avs) / (len(avs) + current_coactive_freqs_chunk[1])\n",
    "\n",
    "    return proportion_single_events_coacitvely_paired,av_coactive_len_per_chunk,proporiton_of_events_coactive\n",
    "\n",
    "def create_multicluster_dataframe(filtered_chunk_data):\n",
    "    meaned_order = []\n",
    "    fs_order = []\n",
    "    event_times = []\n",
    "    count = 0\n",
    "    for i,group in enumerate(filtered_chunk_data.coactive_cluster_group.unique()):\n",
    "        group_mask = filtered_chunk_data.coactive_cluster_group == group\n",
    "        current_cluster = filtered_chunk_data[group_mask].copy()\n",
    "        if len(current_cluster) > 1:\n",
    "            means = []\n",
    "            event_types = []\n",
    "            fs_orders = []\n",
    "            for index,events in enumerate(current_cluster.cluster_spike_times):\n",
    "                event_types += [current_cluster.cluster_seq_type.values[index]]\n",
    "                # calculate event order based on spike time weighted mean\n",
    "                means += [np.mean(ast.literal_eval(events))]\n",
    "                # calculate order based on first spike time:\n",
    "                fs_orders += [current_cluster.first_spike_time.values[index]]\n",
    "\n",
    "            # order by mean time:    \n",
    "            meaned_order += [list(np.array(event_types)[np.argsort(means)])]\n",
    "            # order by first spike:\n",
    "            fs_order += [list(np.array(event_types)[np.argsort(fs_orders)])]\n",
    "\n",
    "            event_times += [fs_orders]\n",
    "\n",
    "            current_cluster['new_cluster_group'] =  [count]*len(current_cluster)\n",
    "            current_cluster['cluster_order_first_spike_defined'] =  list(np.argsort(np.argsort(fs_orders)))\n",
    "            current_cluster['cluster_order_mean_weighted_spikes_defined'] =  list(np.argsort(np.argsort(means)))\n",
    "\n",
    "            if count == 0:\n",
    "                multi_cluster_df = current_cluster.copy()\n",
    "            else:\n",
    "                # Concatenate the DataFrames vertically (row-wise)\n",
    "                multi_cluster_df = pd.concat([multi_cluster_df, current_cluster], axis=0)\n",
    "                # Reset the index if needed\n",
    "                multi_cluster_df = multi_cluster_df.reset_index(drop=True)\n",
    "\n",
    "            count += 1\n",
    "    return multi_cluster_df,meaned_order,fs_order\n",
    "\n",
    "def logic_machine_for_pair_catagorisation(pair,dominant,other):\n",
    "    # if first one in dominant check for ordering:\n",
    "    if pair[0] in dominant and pair[-1] in dominant:\n",
    "        if pair_in_sequence(pair,dominant):\n",
    "            return('ordered')\n",
    "        elif pair_in_sequence(pair,dominant[::-1]):\n",
    "            return('reverse')\n",
    "        elif pair[-1] == pair[0]:\n",
    "            return('repeat')\n",
    "        elif pair[-1] in dominant:\n",
    "            return('misordered') \n",
    "    # if its not these  options then check if it could be in the extra task seqs\n",
    "    elif pair[0] in  (dominant + other) and pair[-1] in  (dominant + other):\n",
    "        for item in other:\n",
    "            if pair[0] in  (dominant + [item]):\n",
    "                if pair_in_sequence(pair,(dominant + [item])):\n",
    "                    return('ordered')\n",
    "                elif pair_in_sequence(pair,(dominant + [item])[::-1]):\n",
    "                    return('reverse')\n",
    "                elif pair[-1] == pair[0]:\n",
    "                    return('repeat')\n",
    "                elif pair[-1] in (dominant + [item]):\n",
    "                    return('misordered')  \n",
    "        # if not this then check if both are in the extra seqs (and are not a repeat):\n",
    "        if pair[0] in other and pair[-1] in other:\n",
    "            if not pair[-1] == pair[0]: \n",
    "                return('ordered')\n",
    "    else:\n",
    "        # if item 1 is in but item 2 isnt then task to other \n",
    "        if pair[0] in  (dominant + other):\n",
    "            if not pair[-1] in  (dominant + other):\n",
    "                return('task to other')\n",
    "        # if item 2 is in but item 1 isnt then other to task \n",
    "        elif not pair[0] in  (dominant + other):\n",
    "            if pair[-1] in  (dominant + other):\n",
    "                return('other to task')\n",
    "            else:\n",
    "                return('other')\n",
    "    return print('ERROR!')\n",
    "\n",
    "def pair_in_sequence(pair, sequence):\n",
    "    for i in range(len(sequence) - 1):\n",
    "        if sequence[i] == pair[0] and sequence[i + 1] == pair[1]:\n",
    "            return True\n",
    "        # because its ciruclar:\n",
    "        elif sequence[-1] == pair[0] and sequence[0] == pair[1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def calculate_ordering_amounts(meaned_order,dominant,other_):\n",
    "    ordered = 0\n",
    "    misordered = 0\n",
    "    other = 0\n",
    "    for cluster in meaned_order:\n",
    "        for ind,item in enumerate(cluster):\n",
    "            if not ind == len(cluster)-1:\n",
    "                pair = [item,cluster[ind+1]]\n",
    "                outcome = logic_machine_for_pair_catagorisation(pair,dominant,other_)\n",
    "                if outcome in ['ordered', 'repeat', 'reverse']:\n",
    "                    ordered += 1\n",
    "                elif outcome == 'misordered':\n",
    "                    misordered += 1\n",
    "                else:\n",
    "                    other +=1\n",
    "    return ordered,misordered,other\n",
    "\n",
    "def all_motifs_proportion_coactive(multi_cluster_df,all_motif_type_reactivations):\n",
    "    motif_prop_coative = []\n",
    "    for seq_type in range(1,7):\n",
    "        motif_cluster_groups = multi_cluster_df[multi_cluster_df['cluster_seq_type'] == seq_type].new_cluster_group\n",
    "        if not len(motif_cluster_groups) == 0:\n",
    "            coative_motif_events = len(motif_cluster_groups)\n",
    "            all_motif_events = all_motif_type_reactivations[seq_type-1]\n",
    "            motif_prop_coative += [coative_motif_events/all_motif_events]\n",
    "        else:\n",
    "            motif_prop_coative += [0]\n",
    "    return motif_prop_coative\n",
    "\n",
    "def motif_by_motif_ordering(meaned_order,real_order,dominant,other_):\n",
    "\n",
    "    all_motifs_fs_task_related_ordered_prop = []\n",
    "    all_motifs_fs_ordered_proportion_all = []\n",
    "    all_motifs_fs_other_proportion = []\n",
    "\n",
    "    for motif_type in range(1,7):\n",
    "        ordered = 0\n",
    "        misordered = 0\n",
    "        other = 0\n",
    "        \n",
    "        if motif_type in real_order:\n",
    "            for cluster in meaned_order:\n",
    "                for ind,item in enumerate(cluster):\n",
    "                    if not ind == len(cluster)-1:\n",
    "                        pair = [item,cluster[ind+1]]\n",
    "                        if motif_type in pair:\n",
    "                            outcome = logic_machine_for_pair_catagorisation(pair,dominant,other_)\n",
    "                            if outcome in ['ordered', 'repeat', 'reverse']:\n",
    "                                ordered += 1\n",
    "                            elif outcome == 'misordered':\n",
    "                                misordered += 1\n",
    "                            else:\n",
    "                                other +=1  \n",
    "                                \n",
    "            if not (ordered+misordered) == 0:\n",
    "                task_related_ordered_prop = ordered/(ordered+misordered)\n",
    "            else:\n",
    "                task_related_ordered_prop = 0\n",
    "            if not (ordered+misordered+other) == 0:\n",
    "                ordered_proportion_all = ordered/(ordered+misordered+other)\n",
    "                other_proportion = other/(ordered+misordered+other)\n",
    "            else:\n",
    "                ordered_proportion_all = 0\n",
    "                other_proportion = 0\n",
    "        else:\n",
    "            task_related_ordered_prop = 'nan'\n",
    "            ordered_proportion_all = 'nan'\n",
    "            other_proportion = 'nan'\n",
    "        \n",
    "        all_motifs_fs_task_related_ordered_prop += [task_related_ordered_prop]\n",
    "        all_motifs_fs_ordered_proportion_all += [ordered_proportion_all]\n",
    "        all_motifs_fs_other_proportion += [other_proportion]\n",
    "        \n",
    "    return all_motifs_fs_task_related_ordered_prop,all_motifs_fs_ordered_proportion_all,all_motifs_fs_other_proportion\n",
    "\n",
    "def empty_chunk_vars():\n",
    "    ## set chunk vars \n",
    "    chunk_vars = {\"chunk_rpm\": [],           \n",
    "    \"chunk_motif_type_reactivations\" :[],\n",
    "    \"chunk_motif_type_reactivations_min\" :[],\n",
    "    \"chunk_motif_type_relative_proportion\" :[],\n",
    "    \"chunk_event_lengths\":[],\n",
    "    \"motif_event_lenghts\":[],\n",
    "    \"mean_spikes_per_event\":[],\n",
    "    \"motif_by_motif_mean_spikes_per_event\":[],\n",
    "    \"proportion_single_events_coacitvely_paired\":[],\n",
    "    \"av_coactive_len_per_chunk\":[],\n",
    "    \"proporiton_of_events_coactive\":[],\n",
    "    \"meaned_order_task_related_ordered_prop\":[],\n",
    "    \"meaned_order_ordered_proportion_all\":[],\n",
    "    \"meaned_order_other_proportion\":[],\n",
    "    \"fs_order_task_related_ordered_prop\":[],\n",
    "    \"fs_order_ordered_proportion_all\":[],\n",
    "    \"fs_order_other_proportion\":[],\n",
    "    \"all_motifs_proportion_coactive\":[],\n",
    "    \"meaned_ordering_all_motifs_task_related_ordered_prop\":[],\n",
    "    \"meaned_ordering_all_motifs_ordered_proportion_all\":[],\n",
    "    \"meaned_ordering_all_motifs_other_proportion\":[],\n",
    "    \"fs_ordering_all_motifs_task_related_ordered_prop\":[],\n",
    "    \"fs_ordering_all_motifs_ordered_proportion_all\":[],\n",
    "    \"fs_ordering_all_motifs_other_proportion\":[],\n",
    "    \"ratio_task_to_nontask\":[],\n",
    "    \"proportion_coacitve_event_that_are_task_related\":[],\n",
    "    \"mean_units_per_event\":[],\n",
    "    \"mean_units_per_motif_event\":[],\n",
    "    \"motif_by_motif_mean_units_per_event\":[]\n",
    "    }\n",
    "    return chunk_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replay processing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this filtering gives...\n",
      " - only sequential events\n",
      "and only those which are in\n",
      " - nrem\n",
      " - rem\n"
     ]
    }
   ],
   "source": [
    "# seq filter takes presedence, if its on: only sequential events, if it is off: all events \n",
    "sequential_filter = True\n",
    "## master switch - turns all sleep filters on/off (if you want all evets turn this off)\n",
    "sleep_filters_on = True\n",
    "# these filters refer to seq one above, and both can be true at the same time. \n",
    "nrem_filter = True\n",
    "rem_filter = True\n",
    "# set this as true (along with the sleep filter one) to override the other two an djust take the background \n",
    "background_only = False\n",
    "\n",
    "\n",
    "## sanity checker / set save path:\n",
    "print('this filtering gives...')\n",
    "if sequential_filter == True:\n",
    "    print(' - only sequential events')\n",
    "    save_var = 'sequential_no_sleep_selected'\n",
    "    type_var = 'sequential'\n",
    "else:\n",
    "    print('- all events')\n",
    "    save_var = 'all_events_no_sleep_selected'\n",
    "    type_var = 'all_events'\n",
    "if sleep_filters_on == True:\n",
    "    if not background_only:\n",
    "        print('and only those which are in')\n",
    "        if nrem_filter == True:\n",
    "            print(' - nrem')\n",
    "            save_var = type_var+'_NREM_sleep'\n",
    "        if rem_filter == True:\n",
    "            print(' - rem')\n",
    "            save_var = type_var+'_REM_sleep'\n",
    "        if nrem_filter == True and rem_filter == True:\n",
    "            save_var = type_var+'_NREM_and_REM_sleep'\n",
    "        \n",
    "    else:\n",
    "        print('and only those which are not in rem/nrem')\n",
    "        save_var = type_var + '_OTHER_nonsleep'\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run index: 3, processing 149_1_1\n",
      "run index: 7, processing 178_1_7\n"
     ]
    }
   ],
   "source": [
    "sleep_ppseq_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\paper_submission\\post_sleep\\\\\"\n",
    "out_path = r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\sleep_wake_link_data\\behaviour_to_replay\\processed_data\\\\\" + save_var + '\\\\'\n",
    "\n",
    "useable_mirs = ['178_1_7','149_1_1']\n",
    "\n",
    "# load in sleep time points\n",
    "sleep_time_point_df = pd.read_csv(sleep_ppseq_path + 'sleep_time_points.csv')\n",
    "# decide when sleep started\n",
    "sleep_start = {}\n",
    "for index,value in enumerate(sleep_time_point_df.approx_sleep_start.values):\n",
    "    mouse = sleep_time_point_df.mir.values[index]\n",
    "    sleep_start[mouse] = value\n",
    "# define mice/sessions in each group    \n",
    "expert_mice = sleep_time_point_df[sleep_time_point_df.group == 'expert'].mir.values\n",
    "hlesion_mice = sleep_time_point_df[sleep_time_point_df.group == 'h_lesion'].mir.values\n",
    "learning_mice = sleep_time_point_df[sleep_time_point_df.group == 'learning'].mir.values\n",
    "\n",
    "\n",
    "var_dict = {'expert':[],'hlesion':[],'learning' :[],'mirs':[],'current_sleep_start':[], 'time_spans':[]}\n",
    "\n",
    "#Load in seq order data \n",
    "sequence_order_df = pd.read_csv(sleep_ppseq_path+\"sequence_order.csv\")\n",
    "# get all the relevant path name and some other data \n",
    "current_mouse_path,var_dict = find_useable_mouse_paths(sleep_ppseq_path,useable_mirs,expert_mice,hlesion_mice,learning_mice,var_dict,sleep_start)\n",
    "# loop across each mouse path:\n",
    "for loop_index, path in enumerate(current_mouse_path):\n",
    "    # create empty chunk vars dict\n",
    "    chunk_vars = empty_chunk_vars()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk1_8300to9300\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## loop across all chunk files\n",
    "for file in os.listdir(path):\n",
    "    if 'chunk' in file:\n",
    "        print(file)\n",
    "        path_ = path + '\\\\' + file + '\\\\'\n",
    "        chunk_time = np.load(path_ + 'chunk_time_interval.npy')\n",
    "        data = pd.read_csv(path_ + 'filtered_replay_clusters_df.csv')\n",
    "        \n",
    "        # filter based on the sequential/rem-nrem conditions set above\n",
    "        filter_mask = make_filter_masks(data,sequential_filter,nrem_filter,rem_filter,sleep_filters_on,background_only)\n",
    "        filtered_chunk_data = data[filter_mask].reset_index()\n",
    "        \n",
    "        # how many reactivations found\n",
    "        reactivations_found = len(filtered_chunk_data)\n",
    "        print(reactivations_found)\n",
    "        \n",
    "        ####################################### chunk rate per minute: (# this one depends on rem/nrem filter... )\n",
    "        mins = determine_chunk_mins(chunk_time,sleep_filters_on,nrem_filter,rem_filter,background_only,path_)\n",
    "        if mins > 0:\n",
    "            chunk_vars['chunk_rpm'] += [reactivations_found/mins]    \n",
    "            \n",
    "        ####################################### replay rate per motif type\n",
    "        all_motif_type_reactivations = []\n",
    "        all_motif_type_reactivations_min = []\n",
    "        all_motif_type_relative_proportion = []\n",
    "        for seq_type in range(1,7):\n",
    "            motif_type_reactivations = [len(np.where(filtered_chunk_data.cluster_seq_type.values == seq_type)[0])][0]\n",
    "            motif_type_reactivations_min = (motif_type_reactivations / mins)\n",
    "            relative_motif_proportion = motif_type_reactivations / len(filtered_chunk_data.cluster_seq_type.values)\n",
    "            all_motif_type_reactivations += [motif_type_reactivations]\n",
    "            all_motif_type_reactivations_min += [motif_type_reactivations_min]\n",
    "            all_motif_type_relative_proportion += [motif_type_reactivations]\n",
    "        chunk_vars['chunk_motif_type_reactivations'] += [all_motif_type_reactivations]\n",
    "        chunk_vars['chunk_motif_type_reactivations_min'] += [all_motif_type_reactivations_min]\n",
    "        chunk_vars['chunk_motif_type_relative_proportion'] += [all_motif_type_relative_proportion]\n",
    "        \n",
    "        \n",
    "        ##################################### av. spikes involved\n",
    "        chunk_vars['mean_spikes_per_event'] += [[len(item) for item in filtered_chunk_data.cluster_spike_times]]\n",
    "        # per motif\n",
    "        motif_by_motif_mean_spikes_per_event = []\n",
    "        for motif_number in range(1,7):\n",
    "            motif_data = filtered_chunk_data[filtered_chunk_data['cluster_seq_type'] == motif_number]\n",
    "            motif_by_motif_mean_spikes_per_event += [len(item) for item in motif_data.cluster_spike_times]\n",
    "        chunk_vars['motif_by_motif_mean_spikes_per_event'] += [motif_by_motif_mean_spikes_per_event]  \n",
    "                \n",
    "        ########################################## average units involved \n",
    "        chunk_vars['mean_units_per_event'] += [[len(np.unique(ast.literal_eval(item))) for item in filtered_chunk_data.cluster_neurons]]\n",
    "        motif_by_motif_mean_units_per_event = []\n",
    "        for motif_number in range(1,7):\n",
    "            motif_data = filtered_chunk_data[filtered_chunk_data['cluster_seq_type'] == motif_number]\n",
    "            motif_by_motif_mean_units_per_event += [len(np.unique(ast.literal_eval(item))) for item in motif_data.cluster_neurons]\n",
    "        chunk_vars['motif_by_motif_mean_units_per_event'] += [motif_by_motif_mean_units_per_event]\n",
    "        \n",
    "        ########################################### replay length overall \n",
    "        chunk_vars['chunk_event_lengths'] += [filtered_chunk_data.event_length.values]\n",
    "        \n",
    "        ########################################### replay length per motif \n",
    "        motif_event_lenghts = []\n",
    "        for i in range(1,7):\n",
    "            motif_event_lenghts += [filtered_chunk_data[filtered_chunk_data.cluster_seq_type == i].event_length.values]\n",
    "        chunk_vars['motif_event_lenghts'] += [motif_event_lenghts]\n",
    "        \n",
    "        ########################################### coactive rate overall\n",
    "        event_proximity_filter =  0.3 #s (how close events have to be to each other to be clustered together as coacitve \n",
    "        # refind the clusters\n",
    "        filtered_chunk_data  = refind_cluster_events(filtered_chunk_data,event_proximity_filter)\n",
    "        # how many single evtns coactivly paired? average coactive rate? proportion of global events coactive? \n",
    "        proportion_single_events_coacitvely_paired,av_coactive_len_per_chunk,proporiton_of_events_coactive = coactive_rate(filtered_chunk_data)\n",
    "        chunk_vars['proportion_single_events_coacitvely_paired'] += [proportion_single_events_coacitvely_paired]\n",
    "        chunk_vars['av_coactive_len_per_chunk'] += [av_coactive_len_per_chunk]\n",
    "        chunk_vars['proporiton_of_events_coactive'] += [proporiton_of_events_coactive]\n",
    "        \n",
    "        # ordering of coactive?\n",
    "        multi_cluster_df,meaned_order,fs_order = create_multicluster_dataframe(filtered_chunk_data)\n",
    "\n",
    "        # pull out sequence order for current mouse\n",
    "        seq_order= ast.literal_eval(sequence_order_df[sequence_order_df.mir == var_dict['mirs'][loop_index]].seq_order.values[0])\n",
    "        num_dominant_seqs = int(sequence_order_df[sequence_order_df.mir == var_dict['mirs'][loop_index]].dominant_task_seqs)\n",
    "        real_order = np.array(seq_order)+1\n",
    "\n",
    "        #deal wih the fact that the way I order the sequence messes up the order a bit\n",
    "        if not len(real_order) == num_dominant_seqs:\n",
    "            dominant = list(real_order[0:num_dominant_seqs])\n",
    "            other_ = list(real_order[num_dominant_seqs::])\n",
    "        else:\n",
    "            dominant = list(real_order)\n",
    "            other_ = []\n",
    "            \n",
    "        # orderng amounts for mean ordering\n",
    "        ordered,misordered,other = calculate_ordering_amounts(meaned_order,dominant,other_)\n",
    "\n",
    "        meaned_order_task_related_ordered_prop = ordered/(ordered+misordered)\n",
    "        meaned_order_ordered_proportion_all = ordered/(ordered+misordered+other)\n",
    "        meaned_order_other_proportion = other/(ordered+misordered+other)\n",
    "        chunk_vars['meaned_order_task_related_ordered_prop'] += [meaned_order_task_related_ordered_prop]\n",
    "        chunk_vars['meaned_order_ordered_proportion_all'] += [meaned_order_ordered_proportion_all]\n",
    "        chunk_vars['meaned_order_other_proportion'] += [meaned_order_other_proportion]\n",
    "        \n",
    "        # orderng amounts for first spike ordering\n",
    "        ordered,misordered,other = calculate_ordering_amounts(fs_order,dominant,other_)\n",
    "\n",
    "        fs_order_task_related_ordered_prop = ordered/(ordered+misordered)\n",
    "        fs_order_ordered_proportion_all = ordered/(ordered+misordered+other)\n",
    "        fs_order_other_proportion = other/(ordered+misordered+other)\n",
    "        chunk_vars['fs_order_task_related_ordered_prop'] += [fs_order_task_related_ordered_prop]\n",
    "        chunk_vars['fs_order_ordered_proportion_all'] += [fs_order_ordered_proportion_all]\n",
    "        chunk_vars['fs_order_other_proportion'] += [fs_order_other_proportion]\n",
    "        \n",
    "        ### motif by motif:\n",
    "        # does one motif appear more in coactive?\n",
    "        all_motifs_prop_coactive = all_motifs_proportion_coactive(multi_cluster_df,all_motif_type_reactivations)\n",
    "        chunk_vars['all_motifs_proportion_coactive'] += [all_motifs_prop_coactive]\n",
    "        \n",
    "        # does one motif appeaer more ordered? \n",
    "        # # this is only calculated for the task related motifs as the non task dont have an order - thought other catagory still exists for times it was task to non task or other way around \n",
    "        # meaned ordering \n",
    "        all_motifs_task_related_ordered_prop,all_motifs_ordered_proportion_all,all_motifs_ordered_proportion_all = motif_by_motif_ordering(meaned_order,real_order,dominant,other_)\n",
    "        chunk_vars['meaned_ordering_all_motifs_task_related_ordered_prop'] += [all_motifs_task_related_ordered_prop]\n",
    "        chunk_vars['meaned_ordering_all_motifs_ordered_proportion_all'] += [all_motifs_ordered_proportion_all]\n",
    "        chunk_vars['meaned_ordering_all_motifs_other_proportion'] += [all_motifs_ordered_proportion_all]\n",
    "        \n",
    "        # first spike ordering \n",
    "        all_motifs_task_related_ordered_prop,all_motifs_ordered_proportion_all,all_motifs_other_proportion = motif_by_motif_ordering(fs_order,real_order,dominant,other_)\n",
    "        chunk_vars['fs_ordering_all_motifs_task_related_ordered_prop'] += [all_motifs_task_related_ordered_prop]\n",
    "        chunk_vars['fs_ordering_all_motifs_ordered_proportion_all'] += [all_motifs_ordered_proportion_all]\n",
    "        chunk_vars['fs_ordering_all_motifs_other_proportion'] += [all_motifs_other_proportion]\n",
    "\n",
    "        ########################################### task related vs other rate\n",
    "        task_seqs = np.array(seq_order)+1\n",
    "        # mask each condition\n",
    "        mask = np.isin(filtered_chunk_data.cluster_seq_type.values, task_seqs)\n",
    "        opposite_mask = ~mask\n",
    "        task_related = filtered_chunk_data[mask]\n",
    "        non_task_related = filtered_chunk_data[opposite_mask]\n",
    "\n",
    "        #  task v nontask overallrate\n",
    "        ratio_task_to_nontask = (len(task_related)/len(task_seqs))/(len(non_task_related)/(6-len(task_seqs)))\n",
    "        chunk_vars['ratio_task_to_nontask'] += [ratio_task_to_nontask]\n",
    "        \n",
    "        ### extra stuff to add in:\n",
    "        \n",
    "        # same but motif by motif\n",
    "        \n",
    "        # number of spikes task related \n",
    "        # number of units task related\n",
    "        \n",
    "        # # coative rate \n",
    "        # task_related_number = 0\n",
    "        # non_task_related_number = 0\n",
    "        # for coactive_ in meaned_order:\n",
    "        #     for motif_item in coactive_:\n",
    "        #         if motif_item in task_seqs:\n",
    "        #             task_related_number += 1\n",
    "        #         else:\n",
    "        #             non_task_related_number += 1\n",
    "        # # make it relative:\n",
    "        # task_related_number = task_related_number/len(task_seqs) \n",
    "        # non_task_related_number = non_task_related_number/(6-len(task_seqs))\n",
    "        # proportion_coacitve_event_that_are_task_related = task_related_number/(task_related_number+non_task_related_number)\n",
    "        # chunk_vars['proportion_coacitve_event_that_are_task_related'] = proportion_coacitve_event_that_are_task_related\n",
    "        \n",
    "        # # motif coactive rate for task and non task \n",
    "        # # task\n",
    "        # task_events = filtered_chunk_data[filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "        # task_proportion_single_events_coacitvely_paired,task_av_coactive_len_per_chunk,task_proporiton_of_events_coactive = coactive_rate(task_related)\n",
    "        # # non task:\n",
    "        # non_task_events = filtered_chunk_data[~filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "        # nontask_proportion_single_events_coacitvely_paired,nontask_av_coactive_len_per_chunk,nontask_proporiton_of_events_coactive = coactive_rate(non_task_related)\n",
    "\n",
    "        # replay length\n",
    "        #task v non task\n",
    "        # motif by motif  \n",
    "        # spikes involved\n",
    "        \n",
    "        # save out to newly made place\n",
    "\n",
    "            \n",
    "\n",
    "##\n",
    "#now do averages for each chunk and save out to a new file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65,\n",
       " 141,\n",
       " 98,\n",
       " 55,\n",
       " 86,\n",
       " 55,\n",
       " 120,\n",
       " 121,\n",
       " 54,\n",
       " 121,\n",
       " 88,\n",
       " 76,\n",
       " 132,\n",
       " 55,\n",
       " 65,\n",
       " 65,\n",
       " 121,\n",
       " 161,\n",
       " 154,\n",
       " 54,\n",
       " 77,\n",
       " 55,\n",
       " 153,\n",
       " 153,\n",
       " 98,\n",
       " 108,\n",
       " 109,\n",
       " 227,\n",
       " 217,\n",
       " 53,\n",
       " 76,\n",
       " 283,\n",
       " 99,\n",
       " 161,\n",
       " 152,\n",
       " 55,\n",
       " 66,\n",
       " 261,\n",
       " 424,\n",
       " 77,\n",
       " 54,\n",
       " 55,\n",
       " 358,\n",
       " 374,\n",
       " 195,\n",
       " 65,\n",
       " 151,\n",
       " 65,\n",
       " 88,\n",
       " 107,\n",
       " 296,\n",
       " 76,\n",
       " 196,\n",
       " 118,\n",
       " 108,\n",
       " 152,\n",
       " 184,\n",
       " 207,\n",
       " 99,\n",
       " 55,\n",
       " 66,\n",
       " 98,\n",
       " 174,\n",
       " 184,\n",
       " 77,\n",
       " 99,\n",
       " 97,\n",
       " 380,\n",
       " 162,\n",
       " 294,\n",
       " 229,\n",
       " 54,\n",
       " 180,\n",
       " 77,\n",
       " 283,\n",
       " 98,\n",
       " 55,\n",
       " 109,\n",
       " 77,\n",
       " 132,\n",
       " 196,\n",
       " 88,\n",
       " 54,\n",
       " 224,\n",
       " 895,\n",
       " 132,\n",
       " 154,\n",
       " 143,\n",
       " 108,\n",
       " 142,\n",
       " 250,\n",
       " 87,\n",
       " 66,\n",
       " 280,\n",
       " 121,\n",
       " 185,\n",
       " 296,\n",
       " 184,\n",
       " 87,\n",
       " 74,\n",
       " 120,\n",
       " 217,\n",
       " 170,\n",
       " 77,\n",
       " 52,\n",
       " 88,\n",
       " 195,\n",
       " 153,\n",
       " 306,\n",
       " 175,\n",
       " 98,\n",
       " 141,\n",
       " 153,\n",
       " 87,\n",
       " 105,\n",
       " 259,\n",
       " 64,\n",
       " 119,\n",
       " 132,\n",
       " 259,\n",
       " 306,\n",
       " 152,\n",
       " 109,\n",
       " 76,\n",
       " 228,\n",
       " 86,\n",
       " 77,\n",
       " 260,\n",
       " 219,\n",
       " 154,\n",
       " 131,\n",
       " 141,\n",
       " 187,\n",
       " 162,\n",
       " 317,\n",
       " 252,\n",
       " 384,\n",
       " 284,\n",
       " 99,\n",
       " 185,\n",
       " 185,\n",
       " 110,\n",
       " 65,\n",
       " 77,\n",
       " 129,\n",
       " 54,\n",
       " 204,\n",
       " 110,\n",
       " 109,\n",
       " 153,\n",
       " 98,\n",
       " 120,\n",
       " 131,\n",
       " 109,\n",
       " 140,\n",
       " 109,\n",
       " 99,\n",
       " 87,\n",
       " 66,\n",
       " 251,\n",
       " 271,\n",
       " 250,\n",
       " 88,\n",
       " 87,\n",
       " 131,\n",
       " 251,\n",
       " 121,\n",
       " 175,\n",
       " 76,\n",
       " 172,\n",
       " 55,\n",
       " 152,\n",
       " 55,\n",
       " 208,\n",
       " 129,\n",
       " 132,\n",
       " 143,\n",
       " 240,\n",
       " 143,\n",
       " 390,\n",
       " 88,\n",
       " 87,\n",
       " 241,\n",
       " 110,\n",
       " 88,\n",
       " 64,\n",
       " 75,\n",
       " 197,\n",
       " 65,\n",
       " 328,\n",
       " 55,\n",
       " 131,\n",
       " 230,\n",
       " 142,\n",
       " 141,\n",
       " 110,\n",
       " 141,\n",
       " 54]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(item) for item in filtered_chunk_data.cluster_spike_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_out_vars():\n",
    "    ## set chunk vars \n",
    "    out_vars = {\"mean_rpm\": [], \n",
    "                \n",
    "                \"motif_type_reactivations\" :[],\n",
    "                \"motif_type_reactivations_min\":[],\n",
    "                \"motif_type_relative_proportion\":[],   \n",
    "                \n",
    "                \"mean_spikes_per_event\" : [],\n",
    "                \"motif_by_motif_mean_spikes_per_event\" : [],\n",
    "                \"mean_units_per_event\" : [],\n",
    "                \n",
    "                \"motif_by_motif_mean_units_per_event\" : [],\n",
    "                \"mean_event_lengths\" : [],\n",
    "                \n",
    "                \"motif_event_lenghts\" : [],\n",
    "                \"proportion_single_events_coacitvely_paired\" : [],\n",
    "                \"av_coactive_len_per_chunk\" : [],\n",
    "                \"proporiton_of_events_coactive\" : [],\n",
    "                \"meaned_order_task_related_ordered_prop\" : [],\n",
    "                \"meaned_order_ordered_proportion_all\" : [],\n",
    "                \"meaned_order_other_proportion\" : [],\n",
    "                \"fs_order_task_related_ordered_prop\" : [],\n",
    "                \"fs_order_ordered_proportion_all\" : [],\n",
    "                \"fs_order_other_proportion\" : [],\n",
    "                \"all_motifs_proportion_coactive\" : [],\n",
    "                \"meaned_ordering_all_motifs_task_related_ordered_prop\" : [],\n",
    "                \"meaned_ordering_all_motifs_ordered_proportion_all\" : [],\n",
    "                \"meaned_ordering_all_motifs_other_proportion\" : [],\n",
    "                \"fs_ordering_all_motifs_task_related_ordered_prop\" : [],\n",
    "                \"fs_ordering_all_motifs_ordered_proportion_all\" : [],\n",
    "                \"fs_ordering_all_motifs_other_proportion\" : [],\n",
    "                \"ratio_task_to_nontask\" : []\n",
    "    }\n",
    "    return out_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1430542542100364"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.mean(list_) for list_ in chunk_vars['chunk_event_lengths']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40.66666667,  51.33333333, 112.33333333,   2.33333333,\n",
       "        37.        ,  86.        ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(chunk_vars[\"chunk_motif_type_reactivations\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vars= empty_out_vars()\n",
    "\n",
    "out_vars['mean_rpm'] = np.mean(chunk_vars['chunk_rpm'])\n",
    "\n",
    "#fix \n",
    "# chunk_vars[\"chunk_motif_type_reactivations\"]\n",
    "# chunk_vars['chunk_motif_type_reactivations_min']\n",
    "# chunk_vars['chunk_motif_type_relative_proportion']\n",
    "\n",
    "out_vars[\"mean_spikes_per_event\"] = np.mean(chunk_vars['mean_spikes_per_event'])\n",
    "out_vars[\"motif_by_motif_mean_spikes_per_event\"] = np.mean(chunk_vars['motif_by_motif_mean_spikes_per_event'],axis =0)\n",
    "out_vars[\"mean_units_per_event\"] = np.mean(chunk_vars['mean_units_per_event'])\n",
    "\n",
    "#chunk_vars['motif_by_motif_mean_units_per_event']\n",
    "\n",
    "out_vars[\"mean_event_lengths\"] = np.mean([np.mean(list_) for list_ in chunk_vars['chunk_event_lengths']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chunk_event_lengths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchunk_event_lengths\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chunk_event_lengths' is not defined"
     ]
    }
   ],
   "source": [
    "chunk_event_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk_rpm': [42.00537186833754, 18.233966492411298, 15.14957720270838],\n",
       " 'chunk_motif_type_reactivations': [25, 31, 29, 1, 27, 85],\n",
       " 'chunk_motif_type_reactivations_min': [1.9128254043823711,\n",
       "  2.3719035014341405,\n",
       "  2.2188774690835507,\n",
       "  0.07651301617529485,\n",
       "  2.065851436732961,\n",
       "  6.5036063749000625],\n",
       " 'chunk_motif_type_relative_proportion': [25, 31, 29, 1, 27, 85],\n",
       " 'chunk_event_lengths': [array([0.015 , 0.0956, 0.055 , 0.0374, 0.0094, 0.002 , 0.01  , 0.0121,\n",
       "         0.0467, 0.0082, 0.026 , 0.0949, 0.0331, 0.0803, 0.0184, 0.0017,\n",
       "         0.0533, 0.0419, 0.0108, 0.0225, 0.0089, 0.0213, 0.0214, 0.0019,\n",
       "         0.0412, 0.0132, 0.0006, 0.0088, 0.0019, 0.0105, 0.0165, 0.0184,\n",
       "         0.0165, 0.003 , 0.0121, 0.0278, 0.0116, 0.0106, 0.0436, 0.0142,\n",
       "         0.0051, 0.0208, 0.0147, 0.0321, 0.0124, 0.0246, 0.0197, 0.0211,\n",
       "         0.0217, 0.0759, 0.0249, 0.2645, 0.0005, 0.0419, 0.0158, 0.037 ,\n",
       "         0.0051, 0.0128, 0.0452, 0.0248, 0.0543, 0.0058, 0.1449, 0.0137,\n",
       "         0.0807, 0.0052, 0.0931, 0.1091, 0.1192, 0.0725, 0.0504, 0.022 ,\n",
       "         0.0858, 0.0534, 0.0821, 0.0156, 0.014 , 0.0138, 0.0079, 0.0211,\n",
       "         0.0034, 0.0887, 0.0753, 0.0689, 0.0311, 0.0041, 0.0211, 0.0672,\n",
       "         0.1101, 0.1004, 0.1082, 0.0183, 0.0841, 0.0936, 0.0832, 0.0025,\n",
       "         0.0765, 0.0747, 0.0641, 0.0148, 0.0086, 0.0188, 0.0566, 0.0983,\n",
       "         0.0049, 0.088 , 0.0093, 0.0506, 0.0063, 0.0583, 0.0688, 0.1177,\n",
       "         0.1684, 0.0739, 0.0801, 0.1039, 0.0019, 0.0323, 0.0374, 0.078 ,\n",
       "         0.078 , 0.0022, 0.0778, 0.0172, 0.0948, 0.0498, 0.0794, 0.0107,\n",
       "         0.0118, 0.0399, 0.0375, 0.0498, 0.0383, 0.0738, 0.0367, 0.0294,\n",
       "         0.013 , 0.0745, 0.0201, 0.0292, 0.0974, 0.0833, 0.1282, 0.1305,\n",
       "         0.1671, 0.0449, 0.0865, 0.0584, 0.0346, 0.0707, 0.0626, 0.0473,\n",
       "         0.0552, 0.1369, 0.1146, 0.0526, 0.203 , 0.0277, 0.0864, 0.0901,\n",
       "         0.0176, 0.016 , 0.0374, 0.0355, 0.0341, 0.0624, 0.036 , 0.0176,\n",
       "         0.0977, 0.1381, 0.1105, 0.1656, 0.0073, 0.0211, 0.0057, 0.0153,\n",
       "         0.025 , 0.0706, 0.0934, 0.1319, 0.0281, 0.0645, 0.0211, 0.033 ,\n",
       "         0.0084, 0.0722, 0.0183, 0.0659, 0.0075, 0.0209, 0.0477, 0.022 ,\n",
       "         0.0537, 0.0127, 0.0294, 0.0651, 0.0197, 0.0128, 0.3195, 0.0927,\n",
       "         0.058 , 0.0109, 0.0958, 0.0977, 0.0006, 0.2051, 0.0189, 0.131 ,\n",
       "         0.0121, 0.117 , 0.081 , 0.0943, 0.0963, 0.0147, 0.0286, 0.0239,\n",
       "         0.0128, 0.0287, 0.2597, 0.0451, 0.0191, 0.0348, 0.0142, 0.1117,\n",
       "         0.0156, 0.014 , 0.0643, 0.0424, 0.0191, 0.0274, 0.0205, 0.0374,\n",
       "         0.0148, 0.2362, 0.1054, 0.0768, 0.0246, 0.0602, 0.0114, 0.0264,\n",
       "         0.1692, 0.0429, 0.0264, 0.1238, 0.1016, 0.0779, 0.0173, 0.0218,\n",
       "         0.0556, 0.0762, 0.1865, 0.0853, 0.0287, 0.0762, 0.04  , 0.0313,\n",
       "         0.1458, 0.1274, 0.0048, 0.0601, 0.2089, 0.0327, 0.0301, 0.1166,\n",
       "         0.0411, 0.0201, 0.012 , 0.0141, 0.0212, 0.0642, 0.0903, 0.0164,\n",
       "         0.024 , 0.0218, 0.101 , 0.071 , 0.0995, 0.047 , 0.0388, 0.0183,\n",
       "         0.0248, 0.0279, 0.0198, 0.0078, 0.0162, 0.111 , 0.0226, 0.0394,\n",
       "         0.1061, 0.0094, 0.0151, 0.0205, 0.0246, 0.0561, 0.0377, 0.0295,\n",
       "         0.0133, 0.2022, 0.0496, 0.1399, 0.0149, 0.3089, 0.1286, 0.1236,\n",
       "         0.2659, 0.0189, 0.1678, 0.0332, 0.0275, 0.0197, 0.0608, 0.1117,\n",
       "         0.1921, 0.1192, 0.0357, 0.033 , 0.0215, 0.0129, 0.0712, 0.0726,\n",
       "         0.0038, 0.0041, 0.1287, 0.0883, 0.1073, 0.052 , 0.0398, 0.0524,\n",
       "         0.0322, 0.0496, 0.0479, 0.0036, 0.0177, 0.1598, 0.0548, 0.1377,\n",
       "         0.1726, 0.0301, 0.1706, 0.1599, 0.0419, 0.2035, 0.0365, 0.1261,\n",
       "         0.0729, 0.2535, 0.011 , 0.0509, 0.0717, 0.0397, 0.0055, 0.0359,\n",
       "         0.0362, 0.0126, 0.0079, 0.0291, 0.0266, 0.0088, 0.0716, 0.0194,\n",
       "         0.0516, 0.066 , 0.0902, 0.0184, 0.0286, 0.029 , 0.0046, 0.0326,\n",
       "         0.0176, 0.0374, 0.1927, 0.1536, 0.0159, 0.0057, 0.0738, 0.0885,\n",
       "         0.0346, 0.0198, 0.1609, 0.1731, 0.0136, 0.0873, 0.0964, 0.037 ,\n",
       "         0.0322, 0.0425, 0.0808, 0.0314, 0.0601, 0.0325, 0.0392, 0.0182,\n",
       "         0.058 , 0.0308, 0.0273, 0.1074, 0.059 , 0.0288, 0.3059, 0.0507,\n",
       "         0.0575, 0.0234, 0.0208, 0.0077, 0.2181, 0.0613, 0.1058, 0.0051,\n",
       "         0.0315, 0.0127, 0.0564, 0.029 , 0.0407, 0.0056, 0.02  , 0.0219,\n",
       "         0.0705, 0.1513, 0.1132, 0.0679, 0.0975, 0.0271, 0.0374, 0.0339,\n",
       "         0.1423, 0.0335, 0.0351, 0.0826, 0.119 , 0.1418, 0.183 , 0.0536,\n",
       "         0.0394, 0.094 , 0.1176, 0.1282, 0.1308, 0.085 , 0.076 , 0.0106,\n",
       "         0.0228, 0.0113, 0.0382, 0.0768, 0.076 , 0.1078, 0.0941, 0.0757,\n",
       "         0.0548, 0.0629, 0.002 , 0.1501, 0.1407, 0.0242, 0.0339, 0.0221,\n",
       "         0.0762, 0.1828, 0.0343, 0.0999, 0.1293, 0.0896, 0.1151, 0.091 ,\n",
       "         0.1   , 0.0064, 0.0988, 0.0343, 0.1455, 0.1234, 0.1734, 0.029 ,\n",
       "         0.0487, 0.2125, 0.1492, 0.0904, 0.0403, 0.0208, 0.0257, 0.2187,\n",
       "         0.1723, 0.0261, 0.0268, 0.0347, 0.161 , 0.0212, 0.0356, 0.019 ,\n",
       "         0.0188, 0.1067, 0.0686, 0.0219, 0.005 , 0.1901, 0.0365, 0.0526,\n",
       "         0.036 , 0.2462, 0.0773, 0.0038, 0.0241, 0.018 , 0.0188, 0.0197,\n",
       "         0.0281, 0.1162, 0.0789, 0.0447, 0.117 , 0.1238, 0.066 , 0.209 ,\n",
       "         0.0115, 0.0393, 0.0707, 0.0349, 0.0459, 0.0479, 0.0812, 0.0177,\n",
       "         0.0251, 0.0052, 0.03  , 0.0817, 0.0278, 0.0485, 0.024 , 0.1647,\n",
       "         0.0127, 0.1048, 0.0411, 0.0107, 0.067 , 0.0426, 0.1102, 0.0094,\n",
       "         0.0253, 0.0084, 0.1533, 0.0861, 0.0204, 0.0826, 0.0346, 0.0327,\n",
       "         0.1788, 0.0443, 0.0308, 0.0196, 0.0143, 0.0736, 0.0109, 0.0266,\n",
       "         0.093 , 0.1583, 0.09  , 0.0373, 0.0583, 0.007 , 0.2079, 0.0924,\n",
       "         0.0255, 0.0528, 0.0758, 0.1967, 0.0087, 0.082 , 0.0364, 0.0365,\n",
       "         0.0352, 0.0201, 0.1203, 0.174 , 0.011 , 0.1015, 0.0219, 0.0731,\n",
       "         0.0165]),\n",
       "  array([0.1102, 0.5812, 0.014 , 0.0477, 0.0393, 0.0017, 0.0253, 0.0361,\n",
       "         0.0164, 0.2975, 0.5889, 0.4121, 0.0067, 0.0889, 0.03  , 0.1487,\n",
       "         0.112 , 0.2559, 0.0271, 0.1526, 0.0308, 0.006 , 0.1632, 0.0221,\n",
       "         0.9509, 0.0439, 0.0238, 0.1247, 0.1328, 0.0338, 0.1599, 0.3911,\n",
       "         0.0244, 0.0275, 0.0253, 0.1877, 0.0851, 0.2058, 0.0922, 0.0573,\n",
       "         0.0192, 0.0181, 0.1709, 0.227 , 0.3019, 0.1731, 0.0137, 0.3902,\n",
       "         0.0698, 0.2613, 0.6606, 0.0069, 0.1218, 0.0918, 0.0102, 0.0101,\n",
       "         0.0483, 0.0585, 0.0775, 0.0764, 0.0427, 0.1498, 0.0025, 0.125 ,\n",
       "         0.28  , 0.1191, 0.0838, 0.2442, 0.0671, 0.0796, 0.1622, 0.0174,\n",
       "         0.0554, 0.6804, 0.0206, 0.0727, 0.0078, 0.1101, 0.0958, 0.0704,\n",
       "         0.1137, 0.0369, 0.1576, 0.2497, 0.0019, 0.1175, 0.108 , 0.2084,\n",
       "         0.0122, 0.003 , 0.158 , 0.1534, 0.012 , 0.2812, 0.021 , 0.1426,\n",
       "         0.3227, 0.0292, 0.1345, 0.0252, 0.017 , 0.1294, 0.5497, 0.1888,\n",
       "         0.4486, 0.2459, 0.4563, 0.0416, 0.0112, 0.0708, 0.0625, 0.1242,\n",
       "         0.3125, 0.0625, 0.1539, 0.0736, 0.0752, 0.0684, 0.4743, 0.0269,\n",
       "         0.5658, 0.0275, 0.7195, 0.0424, 0.1156, 0.0593, 0.834 , 0.1245,\n",
       "         0.3206, 0.0773, 0.3807, 0.032 , 1.0298, 0.273 , 0.0499, 0.1036,\n",
       "         0.0053, 0.0372, 0.0978, 0.0297, 0.1077, 0.0186, 0.0643, 0.9003,\n",
       "         0.0033, 0.0188, 0.3063, 0.0404, 0.0308, 0.7037, 0.0732, 0.1951,\n",
       "         0.4405, 0.4966, 0.2299, 0.0786, 0.7356, 0.0137, 0.014 , 0.1264,\n",
       "         0.0238, 0.0202, 0.1735, 0.2065, 0.0556, 0.2515, 0.2354, 0.539 ,\n",
       "         0.0825, 0.1836, 0.0872, 0.3033, 0.1057, 0.0633, 0.2591, 0.131 ,\n",
       "         0.152 , 0.5666, 0.0212, 0.0907, 0.6817, 0.0068, 0.1405, 0.0721,\n",
       "         0.0037, 0.6317, 0.0074, 0.0019, 0.0752, 0.1922, 0.1321, 0.2416,\n",
       "         0.1826, 0.2163, 0.1139, 0.1933, 0.0747, 0.1904, 0.1931, 0.0209,\n",
       "         0.0254, 0.6806, 0.1042, 0.0501, 0.0923, 0.1371, 0.1493, 0.0365,\n",
       "         0.1401, 0.9384, 0.0271, 0.2454, 0.6095, 0.3212]),\n",
       "  array([4.6540e-01, 2.1730e-01, 2.3200e-02, 2.9000e-03, 1.3260e-01,\n",
       "         2.5900e-02, 2.1300e-01, 7.8700e-02, 2.0600e-02, 1.6640e-01,\n",
       "         4.1500e-02, 2.2600e-02, 3.1590e-01, 5.0000e-04, 2.3400e-02,\n",
       "         1.9300e-02, 8.5000e-02, 2.0640e-01, 1.0070e-01, 8.0000e-04,\n",
       "         1.1760e-01, 2.2800e-02, 3.2440e-01, 1.8150e-01, 1.2470e-01,\n",
       "         7.2900e-02, 3.7100e-02, 1.6800e-01, 3.0940e-01, 4.5000e-03,\n",
       "         2.4000e-03, 2.1150e-01, 7.5300e-02, 8.0100e-02, 4.4300e-02,\n",
       "         4.4000e-03, 1.3300e-02, 3.1030e-01, 1.0080e-01, 7.6800e-02,\n",
       "         1.2100e-02, 1.7600e-02, 7.8200e-02, 1.4830e-01, 9.3100e-02,\n",
       "         1.3600e-02, 1.1140e-01, 2.5300e-02, 9.3000e-02, 9.9300e-02,\n",
       "         3.5670e-01, 1.1700e-02, 2.1820e-01, 2.9000e-02, 4.8700e-02,\n",
       "         2.2930e-01, 3.6480e-01, 1.3100e-01, 1.5600e-02, 6.3500e-02,\n",
       "         2.6800e-02, 2.3700e-02, 5.6670e-01, 7.7100e-02, 4.7200e-02,\n",
       "         3.2900e-02, 5.8000e-03, 1.8100e-01, 4.0200e-02, 2.9480e-01,\n",
       "         2.3010e-01, 3.3000e-03, 1.8420e-01, 3.1800e-02, 2.0210e-01,\n",
       "         3.4600e-02, 1.9000e-03, 3.0300e-02, 1.5000e-02, 1.0700e-01,\n",
       "         9.2600e-02, 3.8350e-01, 2.0800e-02, 1.0600e-01, 8.7270e-01,\n",
       "         4.4900e-02, 1.7620e-01, 2.9110e-01, 1.2540e-01, 1.2430e-01,\n",
       "         1.1005e+00, 9.3600e-02, 2.8440e-01, 9.1700e-02, 3.1840e-01,\n",
       "         5.4900e-02, 3.3420e-01, 1.2750e-01, 5.5900e-02, 6.0000e-02,\n",
       "         3.1600e-02, 1.2200e-01, 2.2000e-02, 5.5400e-02, 2.2800e-02,\n",
       "         3.1200e-02, 1.5150e-01, 5.0630e-01, 2.2140e-01, 1.6380e-01,\n",
       "         5.1440e-01, 3.3760e-01, 8.1900e-02, 9.8000e-03, 7.1930e-01,\n",
       "         7.8020e-01, 1.9100e-02, 1.3870e-01, 7.6700e-02, 2.3790e-01,\n",
       "         9.7510e-01, 2.0330e-01, 4.7200e-01, 1.4980e-01, 4.9770e-01,\n",
       "         5.7000e-03, 1.6700e-02, 1.4664e+00, 2.2280e-01, 5.0490e-01,\n",
       "         9.1570e-01, 3.4900e-02, 2.8800e-02, 8.8800e-02, 3.6790e-01,\n",
       "         4.3830e-01, 7.2480e-01, 3.6720e-01, 1.0144e+00, 4.5430e-01,\n",
       "         9.2500e-02, 5.6900e-01, 1.1900e-02, 7.0000e-03, 1.4500e-02,\n",
       "         4.6000e-03, 1.7110e-01, 1.1060e-01, 9.9300e-02, 5.9900e-02,\n",
       "         2.6000e-02, 9.4200e-02, 2.7300e-02, 2.9800e-02, 4.5350e-01,\n",
       "         8.5440e-01, 1.5210e-01, 3.4700e-02, 1.6300e-02, 1.6530e-01,\n",
       "         2.4110e-01, 2.9080e-01, 9.1100e-02, 1.5900e-02, 5.1730e-01,\n",
       "         8.6550e-01, 1.4770e-01, 1.1700e-01, 1.3000e-02, 1.2580e-01,\n",
       "         6.6000e-03, 2.4600e-02, 2.8000e-03, 2.0190e-01, 1.8060e-01,\n",
       "         1.5420e-01, 1.8500e-02, 3.9460e-01, 1.0731e+00, 7.1400e-01,\n",
       "         3.2680e-01, 9.2230e-01, 1.7870e-01, 6.9100e-02, 1.5600e-01,\n",
       "         2.5590e-01, 9.3400e-02, 2.8300e-02, 2.8500e-02, 1.2510e-01,\n",
       "         2.0100e-02, 1.0300e-01, 7.2220e-01, 3.2200e-02, 3.7100e-02,\n",
       "         9.2900e-02, 6.4030e-01, 1.7200e-02])],\n",
       " 'motif_event_lenghts': [[array([0.015 , 0.0956, 0.055 , 0.0374, 0.0094, 0.002 , 0.01  , 0.0121,\n",
       "          0.0467, 0.0082, 0.026 , 0.0949, 0.0331, 0.0803, 0.0184, 0.0017,\n",
       "          0.0533, 0.0419, 0.0108, 0.0225, 0.0089, 0.0213, 0.0214, 0.0019,\n",
       "          0.0412, 0.0132, 0.0006, 0.0088, 0.0019, 0.0105, 0.0165, 0.0184,\n",
       "          0.0165, 0.003 , 0.0121, 0.0278, 0.0116, 0.0106, 0.0436, 0.0142,\n",
       "          0.0051, 0.0208, 0.0147, 0.0321, 0.0124, 0.0246, 0.0197, 0.0211,\n",
       "          0.0217, 0.0759, 0.0249, 0.2645, 0.0005, 0.0419, 0.0158, 0.037 ,\n",
       "          0.0051, 0.0128, 0.0452]),\n",
       "   array([0.0248, 0.0543, 0.0058, 0.1449, 0.0137, 0.0807, 0.0052, 0.0931,\n",
       "          0.1091, 0.1192, 0.0725, 0.0504, 0.022 , 0.0858, 0.0534, 0.0821,\n",
       "          0.0156, 0.014 , 0.0138, 0.0079, 0.0211, 0.0034, 0.0887, 0.0753,\n",
       "          0.0689, 0.0311, 0.0041, 0.0211, 0.0672, 0.1101, 0.1004, 0.1082,\n",
       "          0.0183, 0.0841, 0.0936, 0.0832, 0.0025, 0.0765, 0.0747, 0.0641,\n",
       "          0.0148, 0.0086, 0.0188, 0.0566, 0.0983, 0.0049, 0.088 , 0.0093,\n",
       "          0.0506, 0.0063, 0.0583, 0.0688, 0.1177, 0.1684, 0.0739, 0.0801,\n",
       "          0.1039, 0.0019, 0.0323, 0.0374, 0.078 , 0.078 , 0.0022, 0.0778,\n",
       "          0.0172, 0.0948, 0.0498, 0.0794, 0.0107, 0.0118, 0.0399, 0.0375,\n",
       "          0.0498, 0.0383, 0.0738, 0.0367]),\n",
       "   array([0.0294, 0.013 , 0.0745, 0.0201, 0.0292, 0.0974, 0.0833, 0.1282,\n",
       "          0.1305, 0.1671, 0.0449, 0.0865, 0.0584, 0.0346, 0.0707, 0.0626,\n",
       "          0.0473, 0.0552, 0.1369, 0.1146, 0.0526, 0.203 , 0.0277, 0.0864,\n",
       "          0.0901, 0.0176, 0.016 , 0.0374, 0.0355, 0.0341, 0.0624, 0.036 ,\n",
       "          0.0176, 0.0977, 0.1381, 0.1105, 0.1656, 0.0073, 0.0211, 0.0057,\n",
       "          0.0153, 0.025 , 0.0706, 0.0934, 0.1319, 0.0281, 0.0645, 0.0211,\n",
       "          0.033 , 0.0084, 0.0722, 0.0183, 0.0659, 0.0075, 0.0209, 0.0477,\n",
       "          0.022 , 0.0537, 0.0127, 0.0294, 0.0651, 0.0197, 0.0128, 0.3195,\n",
       "          0.0927, 0.058 , 0.0109, 0.0958, 0.0977, 0.0006, 0.2051, 0.0189,\n",
       "          0.131 , 0.0121, 0.117 , 0.081 , 0.0943, 0.0963, 0.0147, 0.0286,\n",
       "          0.0239, 0.0128, 0.0287, 0.2597, 0.0451, 0.0191, 0.0348, 0.0142,\n",
       "          0.1117, 0.0156, 0.014 , 0.0643, 0.0424, 0.0191, 0.0274, 0.0205,\n",
       "          0.0374, 0.0148, 0.2362, 0.1054, 0.0768, 0.0246, 0.0602, 0.0114,\n",
       "          0.0264, 0.1692, 0.0429, 0.0264, 0.1238, 0.1016, 0.0779, 0.0173,\n",
       "          0.0218, 0.0556, 0.0762, 0.1865, 0.0853, 0.0287, 0.0762, 0.04  ,\n",
       "          0.0313, 0.1458, 0.1274, 0.0048, 0.0601, 0.2089, 0.0327, 0.0301,\n",
       "          0.1166, 0.0411, 0.0201, 0.012 , 0.0141, 0.0212, 0.0642, 0.0903,\n",
       "          0.0164, 0.024 , 0.0218, 0.101 , 0.071 , 0.0995, 0.047 , 0.0388,\n",
       "          0.0183, 0.0248, 0.0279, 0.0198, 0.0078, 0.0162, 0.111 , 0.0226,\n",
       "          0.0394, 0.1061, 0.0094, 0.0151, 0.0205, 0.0246, 0.0561, 0.0377,\n",
       "          0.0295, 0.0133, 0.2022, 0.0496, 0.1399, 0.0149, 0.3089, 0.1286,\n",
       "          0.1236, 0.2659, 0.0189, 0.1678, 0.0332, 0.0275, 0.0197, 0.0608,\n",
       "          0.1117, 0.1921, 0.1192, 0.0357, 0.033 , 0.0215, 0.0129, 0.0712,\n",
       "          0.0726, 0.0038, 0.0041, 0.1287, 0.0883, 0.1073, 0.052 , 0.0398,\n",
       "          0.0524, 0.0322, 0.0496, 0.0479, 0.0036, 0.0177, 0.1598, 0.0548,\n",
       "          0.1377, 0.1726, 0.0301, 0.1706, 0.1599, 0.0419, 0.2035, 0.0365,\n",
       "          0.1261, 0.0729, 0.2535, 0.011 , 0.0509, 0.0717, 0.0397, 0.0055,\n",
       "          0.0359, 0.0362, 0.0126, 0.0079, 0.0291, 0.0266, 0.0088, 0.0716,\n",
       "          0.0194, 0.0516, 0.066 , 0.0902, 0.0184, 0.0286, 0.029 , 0.0046,\n",
       "          0.0326, 0.0176, 0.0374, 0.1927, 0.1536, 0.0159, 0.0057, 0.0738,\n",
       "          0.0885, 0.0346, 0.0198, 0.1609, 0.1731, 0.0136, 0.0873, 0.0964,\n",
       "          0.037 , 0.0322, 0.0425, 0.0808, 0.0314, 0.0601, 0.0325, 0.0392,\n",
       "          0.0182, 0.058 , 0.0308, 0.0273, 0.1074, 0.059 , 0.0288, 0.3059,\n",
       "          0.0507, 0.0575, 0.0234, 0.0208, 0.0077, 0.2181, 0.0613, 0.1058,\n",
       "          0.0051, 0.0315, 0.0127, 0.0564, 0.029 ]),\n",
       "   array([0.0407, 0.0056, 0.02  , 0.0219]),\n",
       "   array([0.0705, 0.1513, 0.1132, 0.0679, 0.0975, 0.0271, 0.0374, 0.0339,\n",
       "          0.1423, 0.0335, 0.0351, 0.0826, 0.119 , 0.1418, 0.183 , 0.0536,\n",
       "          0.0394, 0.094 , 0.1176, 0.1282, 0.1308, 0.085 , 0.076 , 0.0106,\n",
       "          0.0228, 0.0113, 0.0382, 0.0768, 0.076 , 0.1078, 0.0941, 0.0757,\n",
       "          0.0548, 0.0629, 0.002 , 0.1501, 0.1407, 0.0242, 0.0339, 0.0221,\n",
       "          0.0762, 0.1828, 0.0343, 0.0999, 0.1293, 0.0896, 0.1151, 0.091 ,\n",
       "          0.1   , 0.0064, 0.0988, 0.0343, 0.1455, 0.1234, 0.1734, 0.029 ,\n",
       "          0.0487, 0.2125]),\n",
       "   array([0.1492, 0.0904, 0.0403, 0.0208, 0.0257, 0.2187, 0.1723, 0.0261,\n",
       "          0.0268, 0.0347, 0.161 , 0.0212, 0.0356, 0.019 , 0.0188, 0.1067,\n",
       "          0.0686, 0.0219, 0.005 , 0.1901, 0.0365, 0.0526, 0.036 , 0.2462,\n",
       "          0.0773, 0.0038, 0.0241, 0.018 , 0.0188, 0.0197, 0.0281, 0.1162,\n",
       "          0.0789, 0.0447, 0.117 , 0.1238, 0.066 , 0.209 , 0.0115, 0.0393,\n",
       "          0.0707, 0.0349, 0.0459, 0.0479, 0.0812, 0.0177, 0.0251, 0.0052,\n",
       "          0.03  , 0.0817, 0.0278, 0.0485, 0.024 , 0.1647, 0.0127, 0.1048,\n",
       "          0.0411, 0.0107, 0.067 , 0.0426, 0.1102, 0.0094, 0.0253, 0.0084,\n",
       "          0.1533, 0.0861, 0.0204, 0.0826, 0.0346, 0.0327, 0.1788, 0.0443,\n",
       "          0.0308, 0.0196, 0.0143, 0.0736, 0.0109, 0.0266, 0.093 , 0.1583,\n",
       "          0.09  , 0.0373, 0.0583, 0.007 , 0.2079, 0.0924, 0.0255, 0.0528,\n",
       "          0.0758, 0.1967, 0.0087, 0.082 , 0.0364, 0.0365, 0.0352, 0.0201,\n",
       "          0.1203, 0.174 , 0.011 , 0.1015, 0.0219, 0.0731, 0.0165])],\n",
       "  [array([0.1102, 0.5812, 0.014 , 0.0477, 0.0393, 0.0017, 0.0253, 0.0361,\n",
       "          0.0164, 0.2975, 0.5889, 0.4121, 0.0067, 0.0889, 0.03  , 0.1487,\n",
       "          0.112 , 0.2559, 0.0271, 0.1526, 0.0308, 0.006 , 0.1632, 0.0221,\n",
       "          0.9509, 0.0439, 0.0238, 0.1247, 0.1328, 0.0338, 0.1599, 0.3911,\n",
       "          0.0244, 0.0275, 0.0253, 0.1877, 0.0851, 0.2058]),\n",
       "   array([0.0922, 0.0573, 0.0192, 0.0181, 0.1709, 0.227 , 0.3019, 0.1731,\n",
       "          0.0137, 0.3902, 0.0698, 0.2613, 0.6606, 0.0069, 0.1218, 0.0918,\n",
       "          0.0102, 0.0101, 0.0483, 0.0585, 0.0775, 0.0764, 0.0427, 0.1498,\n",
       "          0.0025, 0.125 , 0.28  , 0.1191, 0.0838, 0.2442, 0.0671, 0.0796,\n",
       "          0.1622, 0.0174, 0.0554, 0.6804, 0.0206, 0.0727, 0.0078, 0.1101,\n",
       "          0.0958, 0.0704, 0.1137, 0.0369, 0.1576, 0.2497, 0.0019]),\n",
       "   array([0.1175, 0.108 , 0.2084, 0.0122, 0.003 , 0.158 , 0.1534, 0.012 ,\n",
       "          0.2812, 0.021 , 0.1426, 0.3227, 0.0292, 0.1345, 0.0252, 0.017 ,\n",
       "          0.1294, 0.5497, 0.1888, 0.4486, 0.2459, 0.4563, 0.0416, 0.0112,\n",
       "          0.0708, 0.0625, 0.1242, 0.3125, 0.0625, 0.1539, 0.0736]),\n",
       "   array([0.0752, 0.0684]),\n",
       "   array([0.4743, 0.0269, 0.5658, 0.0275, 0.7195, 0.0424, 0.1156, 0.0593,\n",
       "          0.834 , 0.1245, 0.3206, 0.0773, 0.3807, 0.032 , 1.0298, 0.273 ,\n",
       "          0.0499, 0.1036, 0.0053, 0.0372, 0.0978, 0.0297, 0.1077, 0.0186,\n",
       "          0.0643, 0.9003]),\n",
       "   array([0.0033, 0.0188, 0.3063, 0.0404, 0.0308, 0.7037, 0.0732, 0.1951,\n",
       "          0.4405, 0.4966, 0.2299, 0.0786, 0.7356, 0.0137, 0.014 , 0.1264,\n",
       "          0.0238, 0.0202, 0.1735, 0.2065, 0.0556, 0.2515, 0.2354, 0.539 ,\n",
       "          0.0825, 0.1836, 0.0872, 0.3033, 0.1057, 0.0633, 0.2591, 0.131 ,\n",
       "          0.152 , 0.5666, 0.0212, 0.0907, 0.6817, 0.0068, 0.1405, 0.0721,\n",
       "          0.0037, 0.6317, 0.0074, 0.0019, 0.0752, 0.1922, 0.1321, 0.2416,\n",
       "          0.1826, 0.2163, 0.1139, 0.1933, 0.0747, 0.1904, 0.1931, 0.0209,\n",
       "          0.0254, 0.6806, 0.1042, 0.0501, 0.0923, 0.1371, 0.1493, 0.0365,\n",
       "          0.1401, 0.9384, 0.0271, 0.2454, 0.6095, 0.3212])],\n",
       "  [array([0.4654, 0.2173, 0.0232, 0.0029, 0.1326, 0.0259, 0.213 , 0.0787,\n",
       "          0.0206, 0.1664, 0.0415, 0.0226, 0.3159, 0.0005, 0.0234, 0.0193,\n",
       "          0.085 , 0.2064, 0.1007, 0.0008, 0.1176, 0.0228, 0.3244, 0.1815,\n",
       "          0.1247]),\n",
       "   array([0.0729, 0.0371, 0.168 , 0.3094, 0.0045, 0.0024, 0.2115, 0.0753,\n",
       "          0.0801, 0.0443, 0.0044, 0.0133, 0.3103, 0.1008, 0.0768, 0.0121,\n",
       "          0.0176, 0.0782, 0.1483, 0.0931, 0.0136, 0.1114, 0.0253, 0.093 ,\n",
       "          0.0993, 0.3567, 0.0117, 0.2182, 0.029 , 0.0487, 0.2293]),\n",
       "   array([0.3648, 0.131 , 0.0156, 0.0635, 0.0268, 0.0237, 0.5667, 0.0771,\n",
       "          0.0472, 0.0329, 0.0058, 0.181 , 0.0402, 0.2948, 0.2301, 0.0033,\n",
       "          0.1842, 0.0318, 0.2021, 0.0346, 0.0019, 0.0303, 0.015 , 0.107 ,\n",
       "          0.0926, 0.3835, 0.0208, 0.106 , 0.8727]),\n",
       "   array([0.0449]),\n",
       "   array([0.1762, 0.2911, 0.1254, 0.1243, 1.1005, 0.0936, 0.2844, 0.0917,\n",
       "          0.3184, 0.0549, 0.3342, 0.1275, 0.0559, 0.06  , 0.0316, 0.122 ,\n",
       "          0.022 , 0.0554, 0.0228, 0.0312, 0.1515, 0.5063, 0.2214, 0.1638,\n",
       "          0.5144, 0.3376, 0.0819]),\n",
       "   array([0.0098, 0.7193, 0.7802, 0.0191, 0.1387, 0.0767, 0.2379, 0.9751,\n",
       "          0.2033, 0.472 , 0.1498, 0.4977, 0.0057, 0.0167, 1.4664, 0.2228,\n",
       "          0.5049, 0.9157, 0.0349, 0.0288, 0.0888, 0.3679, 0.4383, 0.7248,\n",
       "          0.3672, 1.0144, 0.4543, 0.0925, 0.569 , 0.0119, 0.007 , 0.0145,\n",
       "          0.0046, 0.1711, 0.1106, 0.0993, 0.0599, 0.026 , 0.0942, 0.0273,\n",
       "          0.0298, 0.4535, 0.8544, 0.1521, 0.0347, 0.0163, 0.1653, 0.2411,\n",
       "          0.2908, 0.0911, 0.0159, 0.5173, 0.8655, 0.1477, 0.117 , 0.013 ,\n",
       "          0.1258, 0.0066, 0.0246, 0.0028, 0.2019, 0.1806, 0.1542, 0.0185,\n",
       "          0.3946, 1.0731, 0.714 , 0.3268, 0.9223, 0.1787, 0.0691, 0.156 ,\n",
       "          0.2559, 0.0934, 0.0283, 0.0285, 0.1251, 0.0201, 0.103 , 0.7222,\n",
       "          0.0322, 0.0371, 0.0929, 0.6403, 0.0172])]],\n",
       " 'mean_spikes_per_event': [130.10918544194107,\n",
       "  154.3785046728972,\n",
       "  147.9090909090909],\n",
       " 'motif_by_motif_mean_spikes_per_event': [[92.23728813559322,\n",
       "   109.53947368421052,\n",
       "   144.57761732851986,\n",
       "   101.75,\n",
       "   139.82758620689654,\n",
       "   123.69902912621359],\n",
       "  [136.31578947368422,\n",
       "   173.87234042553192,\n",
       "   173.83870967741936,\n",
       "   148.5,\n",
       "   113.11538461538461,\n",
       "   157.97142857142856],\n",
       "  [96.92,\n",
       "   155.67741935483872,\n",
       "   169.89655172413794,\n",
       "   132.0,\n",
       "   152.66666666666666,\n",
       "   151.24705882352941]],\n",
       " 'proportion_single_events_coacitvely_paired': [0.48700173310225303,\n",
       "  0.22897196261682243,\n",
       "  0.22727272727272727],\n",
       " 'av_coactive_len_per_chunk': [2.322314049586777,\n",
       "  2.130434782608696,\n",
       "  2.142857142857143],\n",
       " 'proporiton_of_events_coactive': [0.290167865707434,\n",
       "  0.12234042553191489,\n",
       "  0.1206896551724138],\n",
       " 'meaned_order_task_related_ordered_prop': [0.8, 0.6842105263157895, 0.75],\n",
       " 'meaned_order_ordered_proportion_all': [0.225, 0.5, 0.625],\n",
       " 'meaned_order_other_proportion': [0.71875,\n",
       "  0.2692307692307692,\n",
       "  0.16666666666666666],\n",
       " 'fs_order_task_related_ordered_prop': [0.8181818181818182,\n",
       "  0.631578947368421,\n",
       "  0.75],\n",
       " 'fs_order_ordered_proportion_all': [0.225, 0.46153846153846156, 0.625],\n",
       " 'fs_order_other_proportion': [0.725, 0.2692307692307692, 0.16666666666666666],\n",
       " 'all_motifs_proportion_coactive': [[0.3220338983050847,\n",
       "   0.4868421052631579,\n",
       "   0.48736462093862815,\n",
       "   0.5,\n",
       "   0.603448275862069,\n",
       "   0.5145631067961165],\n",
       "  [0.3157894736842105,\n",
       "   0.19148936170212766,\n",
       "   0.16129032258064516,\n",
       "   0.5,\n",
       "   0.34615384615384615,\n",
       "   0.18571428571428572],\n",
       "  [0.32,\n",
       "   0.2903225806451613,\n",
       "   0.13793103448275862,\n",
       "   0,\n",
       "   0.4074074074074074,\n",
       "   0.15294117647058825]],\n",
       " 'meaned_ordering_all_motifs_task_related_ordered_prop': [[0.9230769230769231,\n",
       "   0.9565217391304348,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.6363636363636364,\n",
       "   0.6666666666666666],\n",
       "  [0.7272727272727273, 0.625, 'nan', 'nan', 0.625, 0.7272727272727273],\n",
       "  [0.7777777777777778, 0.8, 'nan', 'nan', 0.7, 0.7272727272727273]],\n",
       " 'meaned_ordering_all_motifs_ordered_proportion_all': [[0.43478260869565216,\n",
       "   0.3783783783783784,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.45,\n",
       "   0.5932203389830508],\n",
       "  [0.15384615384615385,\n",
       "   0.2,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.1111111111111111,\n",
       "   0.15384615384615385],\n",
       "  [0.0, 0.0, 'nan', 'nan', 0.16666666666666666, 0.15384615384615385]],\n",
       " 'meaned_ordering_all_motifs_other_proportion': [[0.43478260869565216,\n",
       "   0.3783783783783784,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.45,\n",
       "   0.5932203389830508],\n",
       "  [0.15384615384615385,\n",
       "   0.2,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.1111111111111111,\n",
       "   0.15384615384615385],\n",
       "  [0.0, 0.0, 'nan', 'nan', 0.16666666666666666, 0.15384615384615385]],\n",
       " 'fs_ordering_all_motifs_task_related_ordered_prop': [[0.9230769230769231,\n",
       "   0.9565217391304348,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.65,\n",
       "   0.7083333333333334],\n",
       "  [0.7272727272727273,\n",
       "   0.5714285714285714,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.5555555555555556,\n",
       "   0.6363636363636364],\n",
       "  [0.7777777777777778, 0.8, 'nan', 'nan', 0.7, 0.7272727272727273]],\n",
       " 'fs_ordering_all_motifs_ordered_proportion_all': [[0.5217391304347826,\n",
       "   0.5789473684210527,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.3333333333333333,\n",
       "   0.29310344827586204],\n",
       "  [0.6153846153846154,\n",
       "   0.4444444444444444,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.5,\n",
       "   0.5384615384615384],\n",
       "  [0.7777777777777778,\n",
       "   0.8,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.5833333333333334,\n",
       "   0.6153846153846154]],\n",
       " 'fs_ordering_all_motifs_other_proportion': [[0.43478260869565216,\n",
       "   0.39473684210526316,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.48717948717948717,\n",
       "   0.5862068965517241],\n",
       "  [0.15384615384615385,\n",
       "   0.2222222222222222,\n",
       "   'nan',\n",
       "   'nan',\n",
       "   0.1,\n",
       "   0.15384615384615385],\n",
       "  [0.0, 0.0, 'nan', 'nan', 0.16666666666666666, 0.15384615384615385]],\n",
       " 'ratio_task_to_nontask': [0.5266903914590747, 2.742424242424242, 2.8],\n",
       " 'proportion_coacitve_event_that_are_task_related': [],\n",
       " 'mean_units_per_event': [6.601386481802426,\n",
       "  6.794392523364486,\n",
       "  6.904040404040404],\n",
       " 'mean_units_per_motif_event': [],\n",
       " 'motif_by_motif_mean_units_per_event': [[5,\n",
       "   7,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   9,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   3,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   3,\n",
       "   7,\n",
       "   4,\n",
       "   3,\n",
       "   8,\n",
       "   3,\n",
       "   7,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   5,\n",
       "   6,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   9,\n",
       "   4,\n",
       "   18,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   7,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   5,\n",
       "   13,\n",
       "   3,\n",
       "   16,\n",
       "   11,\n",
       "   12,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   7,\n",
       "   5,\n",
       "   5,\n",
       "   3,\n",
       "   3,\n",
       "   6,\n",
       "   6,\n",
       "   9,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   9,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   3,\n",
       "   5,\n",
       "   3,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   7,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   6,\n",
       "   5,\n",
       "   7,\n",
       "   14,\n",
       "   7,\n",
       "   7,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   9,\n",
       "   9,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   8,\n",
       "   10,\n",
       "   4,\n",
       "   4,\n",
       "   7,\n",
       "   5,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   10,\n",
       "   9,\n",
       "   7,\n",
       "   10,\n",
       "   9,\n",
       "   7,\n",
       "   7,\n",
       "   4,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   12,\n",
       "   5,\n",
       "   9,\n",
       "   8,\n",
       "   12,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   6,\n",
       "   6,\n",
       "   5,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   7,\n",
       "   5,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   3,\n",
       "   6,\n",
       "   13,\n",
       "   4,\n",
       "   13,\n",
       "   10,\n",
       "   14,\n",
       "   9,\n",
       "   10,\n",
       "   4,\n",
       "   11,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   6,\n",
       "   7,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   5,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   20,\n",
       "   10,\n",
       "   5,\n",
       "   5,\n",
       "   9,\n",
       "   10,\n",
       "   3,\n",
       "   24,\n",
       "   3,\n",
       "   11,\n",
       "   3,\n",
       "   8,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   5,\n",
       "   7,\n",
       "   19,\n",
       "   5,\n",
       "   7,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   7,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   4,\n",
       "   7,\n",
       "   5,\n",
       "   7,\n",
       "   12,\n",
       "   17,\n",
       "   7,\n",
       "   6,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   16,\n",
       "   5,\n",
       "   7,\n",
       "   6,\n",
       "   6,\n",
       "   6,\n",
       "   5,\n",
       "   8,\n",
       "   5,\n",
       "   3,\n",
       "   17,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   9,\n",
       "   10,\n",
       "   6,\n",
       "   21,\n",
       "   4,\n",
       "   5,\n",
       "   13,\n",
       "   4,\n",
       "   5,\n",
       "   7,\n",
       "   5,\n",
       "   7,\n",
       "   12,\n",
       "   10,\n",
       "   5,\n",
       "   3,\n",
       "   9,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   4,\n",
       "   6,\n",
       "   6,\n",
       "   7,\n",
       "   3,\n",
       "   5,\n",
       "   3,\n",
       "   7,\n",
       "   4,\n",
       "   3,\n",
       "   12,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   7,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   4,\n",
       "   13,\n",
       "   9,\n",
       "   4,\n",
       "   3,\n",
       "   17,\n",
       "   6,\n",
       "   7,\n",
       "   15,\n",
       "   7,\n",
       "   12,\n",
       "   7,\n",
       "   13,\n",
       "   3,\n",
       "   5,\n",
       "   6,\n",
       "   12,\n",
       "   11,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   7,\n",
       "   3,\n",
       "   11,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   3,\n",
       "   7,\n",
       "   6,\n",
       "   11,\n",
       "   21,\n",
       "   6,\n",
       "   4,\n",
       "   15,\n",
       "   3,\n",
       "   8,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   7,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   8,\n",
       "   4,\n",
       "   9,\n",
       "   5,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   7,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   10,\n",
       "   3,\n",
       "   6,\n",
       "   10,\n",
       "   4,\n",
       "   9,\n",
       "   3,\n",
       "   3,\n",
       "   5,\n",
       "   11,\n",
       "   6,\n",
       "   11,\n",
       "   9,\n",
       "   3,\n",
       "   11,\n",
       "   14,\n",
       "   4,\n",
       "   8,\n",
       "   21,\n",
       "   7,\n",
       "   3,\n",
       "   4,\n",
       "   7,\n",
       "   6,\n",
       "   6,\n",
       "   8,\n",
       "   11,\n",
       "   3,\n",
       "   8,\n",
       "   5,\n",
       "   3,\n",
       "   9,\n",
       "   5,\n",
       "   3,\n",
       "   7,\n",
       "   9,\n",
       "   4,\n",
       "   21,\n",
       "   6,\n",
       "   17,\n",
       "   9,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   7,\n",
       "   4,\n",
       "   3,\n",
       "   7,\n",
       "   10,\n",
       "   12,\n",
       "   6,\n",
       "   8,\n",
       "   9,\n",
       "   6,\n",
       "   8,\n",
       "   13,\n",
       "   5,\n",
       "   3,\n",
       "   14,\n",
       "   16,\n",
       "   6,\n",
       "   15,\n",
       "   3,\n",
       "   4,\n",
       "   6,\n",
       "   14,\n",
       "   12,\n",
       "   8,\n",
       "   8,\n",
       "   6,\n",
       "   5,\n",
       "   5,\n",
       "   7,\n",
       "   8,\n",
       "   6,\n",
       "   12,\n",
       "   10,\n",
       "   7,\n",
       "   9,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   12,\n",
       "   16,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   7,\n",
       "   3,\n",
       "   12,\n",
       "   12,\n",
       "   19,\n",
       "   6,\n",
       "   10,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   10,\n",
       "   4,\n",
       "   11,\n",
       "   5,\n",
       "   19,\n",
       "   4,\n",
       "   4,\n",
       "   11,\n",
       "   4,\n",
       "   7,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   19,\n",
       "   6,\n",
       "   6,\n",
       "   5,\n",
       "   6,\n",
       "   6,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   7,\n",
       "   10,\n",
       "   3,\n",
       "   8,\n",
       "   5,\n",
       "   11,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   23,\n",
       "   6,\n",
       "   4,\n",
       "   10,\n",
       "   5,\n",
       "   9,\n",
       "   6,\n",
       "   8,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   10,\n",
       "   5,\n",
       "   11,\n",
       "   3,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   3,\n",
       "   8,\n",
       "   7,\n",
       "   9,\n",
       "   3,\n",
       "   7,\n",
       "   8,\n",
       "   10,\n",
       "   5,\n",
       "   6,\n",
       "   10,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   10,\n",
       "   3,\n",
       "   8,\n",
       "   4,\n",
       "   7,\n",
       "   9,\n",
       "   7,\n",
       "   4,\n",
       "   9,\n",
       "   4,\n",
       "   13,\n",
       "   3,\n",
       "   7,\n",
       "   6,\n",
       "   5,\n",
       "   8,\n",
       "   7,\n",
       "   8,\n",
       "   8,\n",
       "   14,\n",
       "   6,\n",
       "   10,\n",
       "   5,\n",
       "   3,\n",
       "   7,\n",
       "   9,\n",
       "   8,\n",
       "   3,\n",
       "   9,\n",
       "   13,\n",
       "   5,\n",
       "   6,\n",
       "   8,\n",
       "   10,\n",
       "   9,\n",
       "   7,\n",
       "   11,\n",
       "   7,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   14,\n",
       "   12],\n",
       "  [9,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   3,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   3,\n",
       "   8,\n",
       "   9,\n",
       "   5,\n",
       "   4,\n",
       "   8,\n",
       "   5,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   5,\n",
       "   5,\n",
       "   8,\n",
       "   3,\n",
       "   5,\n",
       "   9,\n",
       "   8,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   7,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   7,\n",
       "   6,\n",
       "   8,\n",
       "   10,\n",
       "   4,\n",
       "   6,\n",
       "   3,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   7,\n",
       "   18,\n",
       "   4,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   7,\n",
       "   3,\n",
       "   8,\n",
       "   3,\n",
       "   11,\n",
       "   6,\n",
       "   16,\n",
       "   4,\n",
       "   7,\n",
       "   9,\n",
       "   11,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   5,\n",
       "   3,\n",
       "   5,\n",
       "   3,\n",
       "   12,\n",
       "   5,\n",
       "   6,\n",
       "   4,\n",
       "   9,\n",
       "   3,\n",
       "   8,\n",
       "   9,\n",
       "   3,\n",
       "   6,\n",
       "   26,\n",
       "   3,\n",
       "   4,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   12,\n",
       "   7,\n",
       "   5,\n",
       "   8,\n",
       "   7,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   6,\n",
       "   8,\n",
       "   12,\n",
       "   10,\n",
       "   11,\n",
       "   27,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   5,\n",
       "   7,\n",
       "   12,\n",
       "   6,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   8,\n",
       "   6,\n",
       "   8,\n",
       "   4,\n",
       "   7,\n",
       "   9,\n",
       "   5,\n",
       "   13,\n",
       "   9,\n",
       "   11,\n",
       "   5,\n",
       "   9,\n",
       "   3,\n",
       "   8,\n",
       "   5,\n",
       "   5,\n",
       "   12,\n",
       "   5,\n",
       "   4,\n",
       "   8,\n",
       "   8,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   8,\n",
       "   4,\n",
       "   16,\n",
       "   4,\n",
       "   10,\n",
       "   3,\n",
       "   7,\n",
       "   20,\n",
       "   7,\n",
       "   8,\n",
       "   5,\n",
       "   8,\n",
       "   7,\n",
       "   6,\n",
       "   9,\n",
       "   10,\n",
       "   6,\n",
       "   8,\n",
       "   11,\n",
       "   8,\n",
       "   10,\n",
       "   13,\n",
       "   6,\n",
       "   4,\n",
       "   8,\n",
       "   6,\n",
       "   8,\n",
       "   6,\n",
       "   5,\n",
       "   5,\n",
       "   9,\n",
       "   9,\n",
       "   8,\n",
       "   7,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   7,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   5,\n",
       "   3,\n",
       "   8,\n",
       "   5,\n",
       "   5,\n",
       "   15,\n",
       "   7,\n",
       "   10,\n",
       "   6,\n",
       "   11,\n",
       "   6,\n",
       "   10,\n",
       "   10,\n",
       "   9,\n",
       "   6,\n",
       "   7,\n",
       "   4,\n",
       "   6,\n",
       "   8,\n",
       "   11,\n",
       "   9,\n",
       "   6,\n",
       "   8,\n",
       "   13,\n",
       "   6,\n",
       "   14,\n",
       "   7,\n",
       "   4],\n",
       "  [4,\n",
       "   8,\n",
       "   4,\n",
       "   4,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   4,\n",
       "   5,\n",
       "   3,\n",
       "   5,\n",
       "   8,\n",
       "   6,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   7,\n",
       "   5,\n",
       "   6,\n",
       "   3,\n",
       "   11,\n",
       "   12,\n",
       "   3,\n",
       "   4,\n",
       "   9,\n",
       "   4,\n",
       "   9,\n",
       "   6,\n",
       "   3,\n",
       "   4,\n",
       "   4,\n",
       "   14,\n",
       "   6,\n",
       "   3,\n",
       "   3,\n",
       "   14,\n",
       "   15,\n",
       "   8,\n",
       "   5,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   9,\n",
       "   10,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   14,\n",
       "   8,\n",
       "   5,\n",
       "   3,\n",
       "   5,\n",
       "   4,\n",
       "   7,\n",
       "   10,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   13,\n",
       "   6,\n",
       "   11,\n",
       "   8,\n",
       "   4,\n",
       "   6,\n",
       "   4,\n",
       "   9,\n",
       "   6,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   8,\n",
       "   5,\n",
       "   4,\n",
       "   4,\n",
       "   8,\n",
       "   25,\n",
       "   9,\n",
       "   5,\n",
       "   5,\n",
       "   6,\n",
       "   10,\n",
       "   9,\n",
       "   6,\n",
       "   3,\n",
       "   16,\n",
       "   3,\n",
       "   11,\n",
       "   20,\n",
       "   13,\n",
       "   3,\n",
       "   3,\n",
       "   7,\n",
       "   10,\n",
       "   6,\n",
       "   4,\n",
       "   3,\n",
       "   8,\n",
       "   10,\n",
       "   8,\n",
       "   9,\n",
       "   8,\n",
       "   6,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   6,\n",
       "   5,\n",
       "   5,\n",
       "   7,\n",
       "   5,\n",
       "   8,\n",
       "   10,\n",
       "   7,\n",
       "   3,\n",
       "   5,\n",
       "   15,\n",
       "   7,\n",
       "   3,\n",
       "   13,\n",
       "   11,\n",
       "   10,\n",
       "   6,\n",
       "   10,\n",
       "   9,\n",
       "   8,\n",
       "   15,\n",
       "   9,\n",
       "   12,\n",
       "   14,\n",
       "   5,\n",
       "   10,\n",
       "   9,\n",
       "   3,\n",
       "   6,\n",
       "   6,\n",
       "   9,\n",
       "   3,\n",
       "   10,\n",
       "   4,\n",
       "   3,\n",
       "   4,\n",
       "   9,\n",
       "   5,\n",
       "   10,\n",
       "   6,\n",
       "   5,\n",
       "   4,\n",
       "   8,\n",
       "   8,\n",
       "   5,\n",
       "   12,\n",
       "   7,\n",
       "   10,\n",
       "   7,\n",
       "   8,\n",
       "   7,\n",
       "   8,\n",
       "   8,\n",
       "   11,\n",
       "   6,\n",
       "   9,\n",
       "   4,\n",
       "   9,\n",
       "   4,\n",
       "   11,\n",
       "   5,\n",
       "   5,\n",
       "   11,\n",
       "   7,\n",
       "   6,\n",
       "   16,\n",
       "   3,\n",
       "   5,\n",
       "   10,\n",
       "   7,\n",
       "   5,\n",
       "   3,\n",
       "   5,\n",
       "   12,\n",
       "   4,\n",
       "   12,\n",
       "   3,\n",
       "   6,\n",
       "   5,\n",
       "   8,\n",
       "   7,\n",
       "   4,\n",
       "   9,\n",
       "   4]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 1 (3017412048.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[363], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    task_related[task_related['cluster_seq_type'] == motif_number]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 1\n"
     ]
    }
   ],
   "source": [
    "for motif_number in range(1,7):\n",
    "task_related[task_related['cluster_seq_type'] == motif_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "474    [79.8994, 79.9064, 79.9189, 79.7697, 79.8038, ...\n",
       "475    [87.0442, 87.0612, 87.0612, 87.0681, 87.0444, ...\n",
       "476    [104.1823, 104.1824, 104.2019, 104.2224, 104.2...\n",
       "477    [114.9235, 114.9317, 114.9361, 114.9237, 114.9...\n",
       "478    [115.2708, 115.2872, 115.2708, 115.2709, 115.2...\n",
       "                             ...                        \n",
       "572    [962.7655, 962.7667, 962.7715, 962.7764, 962.7...\n",
       "573    [968.8868, 968.8956, 968.8036, 968.8827, 968.8...\n",
       "574    [969.7686, 969.7686, 969.7583, 969.7526, 969.7...\n",
       "575    [982.2066, 982.2067, 982.2069, 982.1887, 982.1...\n",
       "576    [994.5198, 994.52, 994.5202, 994.511, 994.5173...\n",
       "Name: cluster_spike_times, Length: 103, dtype: object"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_related[task_related['cluster_seq_type'] == motif_number].cluster_spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_related\n",
    "non_task_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.572953736654805"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### av. spikes involved\n",
    "chunk_vars['mean_spikes_per_event'] = np.mean(task_related.num_spikes.values)\n",
    "# per motif\n",
    "motif_by_motif_mean_spikes_per_event = []\n",
    "for motif_number in range(1,7):\n",
    "    motif_by_motif_mean_spikes_per_event +=[np.mean(filtered_chunk_data[filtered_chunk_data['cluster_seq_type'] == motif_number].num_spikes)]\n",
    "chunk_vars['motif_by_motif_mean_spikes_per_event'] = motif_by_motif_mean_spikes_per_event        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.372881355932204,\n",
       " 11.078947368421053,\n",
       " 14.635379061371841,\n",
       " 10.25,\n",
       " 14.206896551724139,\n",
       " 12.524271844660195]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_by_motif_mean_spikes_per_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[343], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mall_motifs_proportion_coactive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_cluster_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mall_motif_type_reactivations\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3220338983050847,\n",
       " 0.4868421052631579,\n",
       " 0.48736462093862815,\n",
       " 0.5,\n",
       " 0.603448275862069,\n",
       " 0.5145631067961165]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_motifs_proportion_coactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        ########################################### replay length overall \n",
    "        chunk_vars['chunk_event_lengths'] = filtered_chunk_data.event_length.values\n",
    "        \n",
    "        ########################################### replay length per motif \n",
    "        motif_event_lenghts = []\n",
    "        for i in range(1,7):\n",
    "            motif_event_lenghts += [filtered_chunk_data[filtered_chunk_data.cluster_seq_type == i].event_length.values]\n",
    "        chunk_vars['motif_event_lenghts'] = motif_event_lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_coacitve_event_that_are_task_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32432432432432434"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_proportion_single_events_coacitvely_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1, 5, 2])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5124555160142349"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many single evtns coactivly paired? average coactive rate? proportion of global events coactive? \n",
    "proportion_single_events_coacitvely_paired,av_coactive_len_per_chunk,proporiton_of_events_coactive = coactive_rate(task_related)\n",
    "nt_proportion_single_events_coacitvely_paired,nt_av_coactive_len_per_chunk,nt_proporiton_of_events_coactive = coactive_rate(non_task_related)\n",
    "# chunk_vars['proportion_single_events_coacitvely_paired'] = proportion_single_events_coacitvely_paired\n",
    "# chunk_vars['av_coactive_len_per_chunk'] = av_coactive_len_per_chunk\n",
    "# chunk_vars['proporiton_of_events_coactive'] = proporiton_of_events_coactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2704626334519573"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt_proportion_single_events_coacitvely_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26013513513513514"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_single_events_coacitvely_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26013513513513514"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion_single_events_coacitvely_paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.548682968852532"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many reactivations found\n",
    "reactivations_found = len(task_related)\n",
    "print(reactivations_found)\n",
    "\n",
    "\n",
    "reactivations_found/mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_group in motif_cluster_groups:\n",
    "    if len(np.where(multi_cluster_df.new_cluster_group.values == c_group)[0]) == 1:\n",
    "        print('clust')\n",
    "    else:\n",
    "        print('no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([279, 280], dtype=int64)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(multi_cluster_df.new_cluster_group.values == c_group)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmett Thompson\\AppData\\Local\\Temp\\ipykernel_32904\\2690245044.py:13: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  num_dominant_seqs = int(sequence_order_df[sequence_order_df.mir == var_dict['mirs'][loop_index]].dominant_task_seqs)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_related_ordered_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_misrtodered_ratio\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.225"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_proportion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_machine_for_pair_catagorisation(pair,dominant,other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic_machine_for_pair_catagorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5, 3],\n",
       " [6, 1, 6],\n",
       " [1, 5, 3],\n",
       " [1, 5, 3],\n",
       " [3, 1],\n",
       " [1, 3, 3],\n",
       " [3, 1, 3],\n",
       " [1, 3],\n",
       " [1, 3],\n",
       " [1, 2, 3],\n",
       " [5, 1, 3, 3],\n",
       " [5, 1],\n",
       " [3, 1],\n",
       " [6, 1],\n",
       " [1, 1, 6],\n",
       " [1, 6],\n",
       " [3, 1, 6],\n",
       " [3, 1],\n",
       " [3, 2, 6],\n",
       " [2, 6],\n",
       " [5, 2],\n",
       " [3, 2],\n",
       " [2, 3],\n",
       " [2, 6, 3, 5],\n",
       " [6, 5, 2],\n",
       " [5, 2],\n",
       " [2, 6],\n",
       " [2, 6],\n",
       " [3, 2],\n",
       " [3, 3, 2],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [5, 2],\n",
       " [6, 2],\n",
       " [3, 2],\n",
       " [2, 5],\n",
       " [2, 6],\n",
       " [2, 2],\n",
       " [5, 2, 3, 6, 5, 5],\n",
       " [3, 2, 2, 5, 3],\n",
       " [2, 2],\n",
       " [2, 3, 6],\n",
       " [5, 2],\n",
       " [3, 2],\n",
       " [2, 6, 3],\n",
       " [3, 2],\n",
       " [2, 6],\n",
       " [3, 2],\n",
       " [2, 2],\n",
       " [3, 6],\n",
       " [5, 3, 5],\n",
       " [3, 3],\n",
       " [3, 3, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 6, 3],\n",
       " [3, 5],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [6, 3],\n",
       " [3, 3, 6, 6],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 5],\n",
       " [6, 3, 5],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " [3, 3],\n",
       " [6, 3, 3],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [3, 5],\n",
       " [6, 3, 5],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [6, 3],\n",
       " [3, 3],\n",
       " [6, 3],\n",
       " [5, 3],\n",
       " [3, 3],\n",
       " [6, 3],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " [3, 3],\n",
       " [3, 5],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [5, 3, 5],\n",
       " [3, 6],\n",
       " [3, 6],\n",
       " [3, 3, 6],\n",
       " [3, 6, 3],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " [3, 3, 6],\n",
       " [3, 3],\n",
       " [3, 6, 5],\n",
       " [6, 3],\n",
       " [3, 3, 3],\n",
       " [3, 3],\n",
       " [4, 4],\n",
       " [5, 6],\n",
       " [5, 6],\n",
       " [6, 5],\n",
       " [6, 5],\n",
       " [5, 6]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cluster in meaned_order:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion ordered (mean)\n",
    "# proportion ordered (first spike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len( multi_cluster_df.coactive_cluster_group.unique()) > 1:\n",
    "    real_order = list(np.array(seq_order)+1)\n",
    "    # # mean ordering first : \n",
    "    relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,meaned_order)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [6, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 2],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [5, 1],\n",
       " [1, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [5, 1],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [6, 1],\n",
       " ['None'],\n",
       " [1, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [6, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 5],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " [2, 3],\n",
       " [3, 6],\n",
       " [6, 5],\n",
       " [5, 5],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " [2, 2],\n",
       " [2, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [6, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [4, 4],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None']]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0],\n",
       " [0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0],\n",
       " [0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0],\n",
       " [0.0,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.3333333333333333],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.3333333333333333,\n",
       "  0.0],\n",
       " [0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.2, 0.0, 0.2, 0.2, 0.2, 0.2, 0.0],\n",
       " [0.0, 0.25, 0.25, 0.0, 0.25, 0.25, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.3333333333333333],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "    all_pair_outcomes_todf = []\n",
    "    all_pairs_todf = []\n",
    "    for group in multi_cluster_df.new_cluster_group.unique():\n",
    "        group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "        group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "        all_pairs = []\n",
    "        all_pair_outcomes = []\n",
    "        for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "            all_pairs += [pair_]\n",
    "            all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "        all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "        all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "    multi_cluster_df['pairs_mean_ordering'] = all_pairs_todf\n",
    "    multi_cluster_df['catagories_mean_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "    # # first spike ordering second : \n",
    "    relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,fs_order)\n",
    "    summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "    labels = ['ordered','reverse','repeat','misordered','other_to_task','task_to_other','other']\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(labels,summed_amounts)\n",
    "    ax.set_title('catagory occurances (seqs ordered by first spike times)')\n",
    "\n",
    "    SaveFig('catagory occurances_2___chunk'+ str(index_+1) + '.png',chunk_path)\n",
    "\n",
    "    all_pair_outcomes_todf = []\n",
    "    all_pairs_todf = []\n",
    "    for group in multi_cluster_df.new_cluster_group.unique():\n",
    "        group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "        group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "        all_pairs = []\n",
    "        all_pair_outcomes = []\n",
    "        for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "            all_pairs += [pair_]\n",
    "            all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "        all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "        all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "    multi_cluster_df['pairs_fs_ordering'] = all_pairs_todf\n",
    "    multi_cluster_df['catagories_fs_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "\n",
    "    multi_cluster_df['real_sequence_order'] = [real_order]*len(multi_cluster_df)\n",
    "\n",
    "    multi_cluster_df.to_csv(chunk_path + 'multi_event_clusters_df.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (281,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m all_pairs_todf \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m multi_cluster_df\u001b[38;5;241m.\u001b[39mnew_cluster_group\u001b[38;5;241m.\u001b[39munique():\n\u001b[1;32m---> 21\u001b[0m     group_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m[multi_cluster_df[multi_cluster_df\u001b[38;5;241m.\u001b[39mnew_cluster_group \u001b[38;5;241m==\u001b[39m group]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m     22\u001b[0m     group_pair_outcomes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pair_outcomes)[multi_cluster_df[multi_cluster_df\u001b[38;5;241m.\u001b[39mnew_cluster_group \u001b[38;5;241m==\u001b[39m group]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m     23\u001b[0m     all_pairs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (281,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "############################################## calculate catagory breakdown\n",
    "\n",
    "if len(multi_cluster_df.coactive_cluster_group.unique()) > 1:\n",
    "\n",
    "    real_order = list(np.array(seq_order)+1)\n",
    "\n",
    "    # # mean ordering first : \n",
    "    if len(real_order) > 3: # 3 will always be ordered so exclude\n",
    "        relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,meaned_order)\n",
    "        summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "    #     labels = ['ordered','reverse','repeat','misordered','other_to_task','task_to_other','other']\n",
    "    #     fig, ax = plt.subplots()\n",
    "    #     ax.bar(labels,summed_amounts)\n",
    "    #     ax.set_title('catagory occurances (seqs ordered by mean spike time)')\n",
    "\n",
    "    #     SaveFig('catagory occurances_1___chunk'+ str(index_+1) + '.png',chunk_path)\n",
    "\n",
    "        all_pair_outcomes_todf = []\n",
    "        all_pairs_todf = []\n",
    "        for group in multi_cluster_df.new_cluster_group.unique():\n",
    "            group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "            group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "            all_pairs = []\n",
    "            all_pair_outcomes = []\n",
    "            for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "                all_pairs += [pair_]\n",
    "                all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "            all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "            all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "        multi_cluster_df['pairs_mean_ordering'] = all_pairs_todf\n",
    "        multi_cluster_df['catagories_mean_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "        multi_cluster_df['real_sequence_order'] = [real_order]*len(multi_cluster_df)\n",
    "\n",
    "        # chunk_summed_amounts += [list(np.array(summed_amounts)/sum(summed_amounts))]\n",
    "\n",
    "        # chunk_ordered_sum += sum(summed_amounts[0:3])\n",
    "        # chunk_coactive_total += sum(summed_amounts[0:4])\n",
    "    else:\n",
    "        print('only 3 seqs')\n",
    "\n",
    "    \n",
    "    \n",
    "#                             print(chunk_summed_amounts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (281,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (281,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [6, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [1, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 3],\n",
       " ['None'],\n",
       " [1, 2],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [5, 1],\n",
       " [1, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [5, 1],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [6, 1],\n",
       " ['None'],\n",
       " [1, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " [1, 6],\n",
       " ['None'],\n",
       " [3, 1],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [6, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 5],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " [2, 3],\n",
       " [3, 6],\n",
       " [6, 5],\n",
       " [5, 5],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " [2, 2],\n",
       " [2, 5],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [2, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 2],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 6],\n",
       " ['None'],\n",
       " [3, 2],\n",
       " ['None'],\n",
       " [2, 2],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " [6, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [5, 3],\n",
       " [3, 5],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 6],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 6],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [6, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [3, 3],\n",
       " ['None'],\n",
       " [4, 4],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [6, 5],\n",
       " ['None'],\n",
       " [5, 6],\n",
       " ['None']]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cluster_seq_type</th>\n",
       "      <th>num_spikes</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>first_spike_time</th>\n",
       "      <th>event_length</th>\n",
       "      <th>last_spike_time</th>\n",
       "      <th>cluster_spike_times</th>\n",
       "      <th>cluster_neurons</th>\n",
       "      <th>spike_plotting_order</th>\n",
       "      <th>coactive_cluster_group</th>\n",
       "      <th>ordering_classification</th>\n",
       "      <th>rem_events</th>\n",
       "      <th>nrem_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>78.9772</td>\n",
       "      <td>78.9622</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>78.9772</td>\n",
       "      <td>[78.9769, 78.9622, 78.9755, 78.9757, 78.977, 7...</td>\n",
       "      <td>[79.0, 149.0, 163.0, 163.0, 206.0, 208.0, 208.0]</td>\n",
       "      <td>[147. 129.  72.  72. 145. 148. 148.]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>93.5430</td>\n",
       "      <td>93.4474</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>93.5430</td>\n",
       "      <td>[93.4474, 93.4562, 93.4626, 93.4476, 93.4564, ...</td>\n",
       "      <td>[40.0, 40.0, 40.0, 42.0, 42.0, 42.0, 48.0, 48....</td>\n",
       "      <td>[140. 140. 140. 143. 143. 143. 142. 142. 115. ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>114.2586</td>\n",
       "      <td>114.2036</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>114.2586</td>\n",
       "      <td>[114.2374, 114.2375, 114.2511, 114.2512, 114.2...</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 6.0, 206.0, 210.0]</td>\n",
       "      <td>[138. 138. 138. 138. 138. 145. 146.]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>115.0579</td>\n",
       "      <td>115.0205</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>115.0579</td>\n",
       "      <td>[115.0206, 115.0207, 115.0207, 115.0208, 115.0...</td>\n",
       "      <td>[6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 149.0, 149...</td>\n",
       "      <td>[138. 138. 138. 138. 138. 137. 137. 129. 129. ...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>119.7683</td>\n",
       "      <td>119.7589</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>119.7683</td>\n",
       "      <td>[119.7589, 119.768, 119.7682, 119.7683, 119.7679]</td>\n",
       "      <td>[21.0, 40.0, 42.0, 45.0, 48.0]</td>\n",
       "      <td>[116. 140. 143. 139. 142.]</td>\n",
       "      <td>18.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1911</td>\n",
       "      <td>1911</td>\n",
       "      <td>1911</td>\n",
       "      <td>1911</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>962.7765</td>\n",
       "      <td>962.7655</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>962.7765</td>\n",
       "      <td>[962.7655, 962.7667, 962.7715, 962.7764, 962.7...</td>\n",
       "      <td>[15.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 148...</td>\n",
       "      <td>[ 96. 105. 105. 105. 106. 106. 106. 182. 182.]</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1913</td>\n",
       "      <td>1913</td>\n",
       "      <td>1913</td>\n",
       "      <td>1913</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>968.9051</td>\n",
       "      <td>968.8036</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>968.9051</td>\n",
       "      <td>[968.8868, 968.8956, 968.8036, 968.8827, 968.8...</td>\n",
       "      <td>[15.0, 15.0, 101.0, 170.0, 170.0, 170.0, 170.0...</td>\n",
       "      <td>[ 96.  96. 117.  97.  97.  97.  97. 242. 242.]</td>\n",
       "      <td>978.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>969.7686</td>\n",
       "      <td>969.7467</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>969.7686</td>\n",
       "      <td>[969.7686, 969.7686, 969.7583, 969.7526, 969.7...</td>\n",
       "      <td>[68.0, 70.0, 200.0, 204.0, 212.0]</td>\n",
       "      <td>[100.  99. 101. 248. 111.]</td>\n",
       "      <td>980.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1916</td>\n",
       "      <td>1916</td>\n",
       "      <td>1916</td>\n",
       "      <td>1916</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>982.2133</td>\n",
       "      <td>982.1402</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>982.2133</td>\n",
       "      <td>[982.2066, 982.2067, 982.2069, 982.1887, 982.1...</td>\n",
       "      <td>[8.0, 10.0, 10.0, 62.0, 68.0, 70.0, 82.0, 82.0...</td>\n",
       "      <td>[212. 213. 213. 175. 100.  99. 108. 108. 108. ...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1918</td>\n",
       "      <td>1918</td>\n",
       "      <td>1918</td>\n",
       "      <td>1918</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>994.5238</td>\n",
       "      <td>994.5073</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>994.5238</td>\n",
       "      <td>[994.5198, 994.52, 994.5202, 994.511, 994.5173...</td>\n",
       "      <td>[8.0, 10.0, 10.0, 24.0, 24.0, 58.0, 70.0, 86.0...</td>\n",
       "      <td>[212. 213. 213.  95.  95.  13.  99. 185. 185. ...</td>\n",
       "      <td>133.0</td>\n",
       "      <td>sequential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>577 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  cluster_seq_type  \\\n",
       "0        9             9             9           9                 1   \n",
       "1       10            10            10          10                 1   \n",
       "2       17            17            17          17                 1   \n",
       "3       18            18            18          18                 1   \n",
       "4       21            21            21          21                 1   \n",
       "..     ...           ...           ...         ...               ...   \n",
       "572   1911          1911          1911        1911                 6   \n",
       "573   1913          1913          1913        1913                 6   \n",
       "574   1914          1914          1914        1914                 6   \n",
       "575   1916          1916          1916        1916                 6   \n",
       "576   1918          1918          1918        1918                 6   \n",
       "\n",
       "     num_spikes  num_neurons  first_spike_time  event_length  last_spike_time  \\\n",
       "0             7      78.9772           78.9622        0.0150          78.9772   \n",
       "1            15      93.5430           93.4474        0.0956          93.5430   \n",
       "2             7     114.2586          114.2036        0.0550         114.2586   \n",
       "3            11     115.0579          115.0205        0.0374         115.0579   \n",
       "4             5     119.7683          119.7589        0.0094         119.7683   \n",
       "..          ...          ...               ...           ...              ...   \n",
       "572           9     962.7765          962.7655        0.0110         962.7765   \n",
       "573           9     968.9051          968.8036        0.1015         968.9051   \n",
       "574           5     969.7686          969.7467        0.0219         969.7686   \n",
       "575          20     982.2133          982.1402        0.0731         982.2133   \n",
       "576          18     994.5238          994.5073        0.0165         994.5238   \n",
       "\n",
       "                                   cluster_spike_times  \\\n",
       "0    [78.9769, 78.9622, 78.9755, 78.9757, 78.977, 7...   \n",
       "1    [93.4474, 93.4562, 93.4626, 93.4476, 93.4564, ...   \n",
       "2    [114.2374, 114.2375, 114.2511, 114.2512, 114.2...   \n",
       "3    [115.0206, 115.0207, 115.0207, 115.0208, 115.0...   \n",
       "4    [119.7589, 119.768, 119.7682, 119.7683, 119.7679]   \n",
       "..                                                 ...   \n",
       "572  [962.7655, 962.7667, 962.7715, 962.7764, 962.7...   \n",
       "573  [968.8868, 968.8956, 968.8036, 968.8827, 968.8...   \n",
       "574  [969.7686, 969.7686, 969.7583, 969.7526, 969.7...   \n",
       "575  [982.2066, 982.2067, 982.2069, 982.1887, 982.1...   \n",
       "576  [994.5198, 994.52, 994.5202, 994.511, 994.5173...   \n",
       "\n",
       "                                       cluster_neurons  \\\n",
       "0     [79.0, 149.0, 163.0, 163.0, 206.0, 208.0, 208.0]   \n",
       "1    [40.0, 40.0, 40.0, 42.0, 42.0, 42.0, 48.0, 48....   \n",
       "2              [6.0, 6.0, 6.0, 6.0, 6.0, 206.0, 210.0]   \n",
       "3    [6.0, 6.0, 6.0, 6.0, 6.0, 7.0, 7.0, 149.0, 149...   \n",
       "4                       [21.0, 40.0, 42.0, 45.0, 48.0]   \n",
       "..                                                 ...   \n",
       "572  [15.0, 60.0, 60.0, 60.0, 61.0, 61.0, 61.0, 148...   \n",
       "573  [15.0, 15.0, 101.0, 170.0, 170.0, 170.0, 170.0...   \n",
       "574                  [68.0, 70.0, 200.0, 204.0, 212.0]   \n",
       "575  [8.0, 10.0, 10.0, 62.0, 68.0, 70.0, 82.0, 82.0...   \n",
       "576  [8.0, 10.0, 10.0, 24.0, 24.0, 58.0, 70.0, 86.0...   \n",
       "\n",
       "                                  spike_plotting_order  \\\n",
       "0                 [147. 129.  72.  72. 145. 148. 148.]   \n",
       "1    [140. 140. 140. 143. 143. 143. 142. 142. 115. ...   \n",
       "2                 [138. 138. 138. 138. 138. 145. 146.]   \n",
       "3    [138. 138. 138. 138. 138. 137. 137. 129. 129. ...   \n",
       "4                           [116. 140. 143. 139. 142.]   \n",
       "..                                                 ...   \n",
       "572     [ 96. 105. 105. 105. 106. 106. 106. 182. 182.]   \n",
       "573     [ 96.  96. 117.  97.  97.  97.  97. 242. 242.]   \n",
       "574                         [100.  99. 101. 248. 111.]   \n",
       "575  [212. 213. 213. 175. 100.  99. 108. 108. 108. ...   \n",
       "576  [212. 213. 213.  95.  95.  13.  99. 185. 185. ...   \n",
       "\n",
       "     coactive_cluster_group ordering_classification  rem_events  nrem_events  \n",
       "0                       8.0              sequential           0            1  \n",
       "1                       9.0              sequential           0            1  \n",
       "2                      15.0              sequential           0            1  \n",
       "3                      16.0              sequential           0            1  \n",
       "4                      18.0              sequential           0            1  \n",
       "..                      ...                     ...         ...          ...  \n",
       "572                  1078.0              sequential           0            1  \n",
       "573                   978.0              sequential           0            1  \n",
       "574                   980.0              sequential           0            1  \n",
       "575                   128.0              sequential           0            1  \n",
       "576                   133.0              sequential           0            1  \n",
       "\n",
       "[577 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_chunk_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        #2################################\n",
    "\n",
    "#                             current_sleep_start = sleep_start[mouse] - 400\n",
    "                            chunk_number = int(file.split('_')[0][-1])\n",
    "                            start_offset = ([0]+list(np.cumsum(np.diff(time_spans))))[chunk_number-1]\n",
    "\n",
    "\n",
    "                            # take away cumulative chunk offset - this gives time in terms of chunk\n",
    "                            f_spike_times = filtered_chunk_data.first_spike_time.values - start_offset\n",
    "                            # add on ephys time that chunk started - so its in ephys timestamps \n",
    "                            f_spike_times = f_spike_times + chunk_time[0]\n",
    "\n",
    "                            # now make relative to sleep start time\n",
    "                            f_spike_times_relative_to_so = f_spike_times - current_sleep_start \n",
    "                            # do the same but for rem and nrem start\n",
    "\n",
    "                            # filter out anything that happened before sleep onset\n",
    "                            f_spike_times_relative_to_so = f_spike_times_relative_to_so[f_spike_times_relative_to_so > 0]\n",
    "\n",
    "                            ## calculate rate over time:\n",
    "                            time_data = pd.Series(f_spike_times_relative_to_so)\n",
    "                            if len(time_data) > 0:\n",
    "#                                 # Calculate the number of bins required # 5 minute bins\n",
    "#                                 num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "#                                 # Create bins and count the occurrences in each bin\n",
    "#                                 chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "#                                 #remove extra final bin and convert to mins\n",
    "#                                 chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "                                # Calculate the number of bins required # 20s bins\n",
    "                            #     num_bins = int((time_data.max() - time_data.min()) // 40 + 1)\n",
    "                                if time_data.max() - time_data.min() > 19:\n",
    "                                    num_bins = int((time_data.max() - time_data.min())//20)\n",
    "                                    # Create bins and count the occurrences in each bin\n",
    "                                    chunk_event_rate, chunk_relative_time_bins = np.histogram(time_data, bins=num_bins)\n",
    "                                    #remove extra final bin and convert to mins\n",
    "                                    chunk_relative_time_bins = chunk_relative_time_bins[0:-1]/60\n",
    "\n",
    "\n",
    "                                    chunk_binned_rate += [list((chunk_event_rate*3).astype(float))] # *3 because its per 20s so we want it per minute )\n",
    "                                    chunk_bins_relative_so += [list(chunk_relative_time_bins.astype(float))]\n",
    "\n",
    "                        \n",
    "                        #3########################################################\n",
    "\n",
    "                        chunk_event_lens += list(filtered_chunk_data.event_length.values)\n",
    "\n",
    "                        #4 ################################################# coactive stuff -300ms = coactive\n",
    "                        event_proximity_filter =  0.3 #s (how close events have to be to each other to be clustered together as coacitve \n",
    "\n",
    "                        task_seqs = np.load(current_data_path + 'task_order_seqs.npy')+1\n",
    "            \n",
    "                        for motif_type in filtered_chunk_data.cluster_seq_type:\n",
    "                            if motif_type in task_seqs:\n",
    "                                task_related += 1\n",
    "                            else:\n",
    "                                non_task_related += 1\n",
    "        \n",
    "                        total_events += len(filtered_chunk_data.cluster_seq_type)\n",
    "\n",
    "                        # normalise by number of each type: \n",
    "#                         if (6-len(task_seqs)) == 0:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "#                         else:\n",
    "#                             chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]\n",
    "\n",
    "                        chunk_mid_time_post_onset += [((sum(chunk_time)/2)-current_sleep_start)]\n",
    "\n",
    "                        ### ignore the origonal clusterg rosp and remake them: \n",
    "                        start_times = filtered_chunk_data.first_spike_time.values\n",
    "                        end_times = filtered_chunk_data.last_spike_time.values\n",
    "\n",
    "                        clustered_events = cluster_events(start_times, end_times,event_proximity_filter)\n",
    "\n",
    "                        cluster_group = np.zeros(len(filtered_chunk_data))\n",
    "                        for index,cluster in enumerate(clustered_events):\n",
    "                            for item in cluster:\n",
    "                                cluster_group[item] = int(index)\n",
    "                        filtered_chunk_data['coactive_cluster_group'] = cluster_group\n",
    "\n",
    "                        # work out how mnay coacitve in chunk: \n",
    "                        current_coactive_freqs_chunk = {}\n",
    "                        for cluster in filtered_chunk_data.coactive_cluster_group.unique():\n",
    "                            num = list(filtered_chunk_data.coactive_cluster_group.values).count(cluster)\n",
    "                            if num in current_coactive_freqs_chunk:\n",
    "                                current_coactive_freqs_chunk[num] += 1\n",
    "                            else:\n",
    "                                current_coactive_freqs_chunk[num] = 1\n",
    "\n",
    "                        avs =[]\n",
    "                        for item in current_coactive_freqs_chunk:\n",
    "                            avs += current_coactive_freqs_chunk[item] * [item]\n",
    "                        av_coactive_len_per_chunk += [np.mean(avs)]\n",
    "                        if mouse in expert_mice:\n",
    "                            chunk_expert += [1]\n",
    "                        elif mouse in hlesion_mice:\n",
    "                            chunk_expert += [2]\n",
    "                        elif mouse in learning_mice:\n",
    "                            chunk_expert += [3]\n",
    "\n",
    "\n",
    "                        # make it relative:\n",
    "                        current_coactive_freqs_chunk = relative_dict(current_coactive_freqs_chunk)\n",
    "\n",
    "                        coactive_freqs_keys = list(current_coactive_freqs_chunk.keys())\n",
    "                        rel_coactive_freqs = list(current_coactive_freqs_chunk.values())\n",
    "                        for index,item in enumerate(rel_coactive_freqs):\n",
    "                            num = int(coactive_freqs_keys[index])\n",
    "                            if num in coactive_freqs_chunk:\n",
    "                                coactive_freqs_chunk[num] += [item]\n",
    "                            else:\n",
    "                                coactive_freqs_chunk[num] = [item]\n",
    "\n",
    "\n",
    "                        task_events = filtered_chunk_data[filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "                        non_task_events = filtered_chunk_data[~filtered_chunk_data.cluster_seq_type.isin(task_seqs)]\n",
    "\n",
    "                        chunk_task_num_spikes+=list(task_events.num_spikes)\n",
    "                        chunk_nontask_num_spikes+=list(non_task_events.num_spikes)\n",
    "                        chunk_task_e_len+=list(task_events.event_length)\n",
    "                        chunk_nontask_e_len+=list(non_task_events.event_length)\n",
    "\n",
    "\n",
    "                        # 5 ##############################################################################\n",
    "\n",
    "                        ############################################## split into multi clusters and process\n",
    "\n",
    "                        multi_cluster_df = pd.DataFrame({'cluster_seq_type':[],\n",
    "                         'num_spikes':[],\n",
    "                         'num_neurons':[],\n",
    "                         'first_spike_time':[],\n",
    "                         'event_length':[],\n",
    "                         'last_spike_time':[],\n",
    "                         'cluster_spike_times':[],\n",
    "                         'cluster_neurons':[],\n",
    "                         'spike_plotting_order':[],\n",
    "                         'coactive_cluster_group':[],\n",
    "                         'new_cluster_group':[],\n",
    "                         'cluster_order_first_spike_defined':[],\n",
    "                         'cluster_order_mean_weighted_spikes_defined':[],\n",
    "                         'pairs_mean_ordering':[],\n",
    "                         'catagories_mean_ordering':[],\n",
    "                         'pairs_fs_ordering':[],\n",
    "                         'catagories_fs_ordering':[],\n",
    "                         'real_sequence_order':[]})\n",
    "                        meaned_order = []\n",
    "                        fs_order = []\n",
    "                        event_times = []\n",
    "                        multi_cluster_df\n",
    "                        count = 0\n",
    "                        for i,group in enumerate(filtered_chunk_data.coactive_cluster_group.unique()):\n",
    "                            group_mask = filtered_chunk_data.coactive_cluster_group == group\n",
    "                            current_cluster = filtered_chunk_data[group_mask]\n",
    "                            if len(current_cluster) > 1:\n",
    "                                means = []\n",
    "                                event_types = []\n",
    "                                fs_orders = []\n",
    "                                for index,events in enumerate(current_cluster.cluster_spike_times):\n",
    "                                    event_types += [current_cluster.cluster_seq_type.values[index]]\n",
    "                                    # calculate event order based on spike time weighted mean\n",
    "                                    means += [np.mean(ast.literal_eval(events))]\n",
    "                                    # calculate order based on first spike time:\n",
    "                                    fs_orders += [current_cluster.first_spike_time.values[index]]\n",
    "\n",
    "                                # order by mean time:    \n",
    "                                meaned_order += [list(np.array(event_types)[np.argsort(means)])]\n",
    "                                # order by first spike:\n",
    "                                fs_order += [list(np.array(event_types)[np.argsort(fs_orders)])]\n",
    "\n",
    "                                event_times += [fs_orders]\n",
    "\n",
    "                                current_cluster['new_cluster_group'] =  [count]*len(current_cluster)\n",
    "                                current_cluster['cluster_order_first_spike_defined'] =  list(np.argsort(np.argsort(fs_orders)))\n",
    "                                current_cluster['cluster_order_mean_weighted_spikes_defined'] =  list(np.argsort(np.argsort(means)))\n",
    "\n",
    "                                if count == 0:\n",
    "                                    multi_cluster_df = current_cluster.copy()\n",
    "                                else:\n",
    "                                    # Concatenate the DataFrames vertically (row-wise)\n",
    "                                    multi_cluster_df = pd.concat([multi_cluster_df, current_cluster], axis=0)\n",
    "                                    # Reset the index if needed\n",
    "                                    multi_cluster_df = multi_cluster_df.reset_index(drop=True)\n",
    "\n",
    "                                count += 1\n",
    "\n",
    "                        ############################################## Load in seq order data \n",
    "\n",
    "                        awake_PP_path = r\"Z:\\projects\\sequence_squad\\organised_data\\ppseq_data\\finalised_output\\striatum\\awake\\\\\"\n",
    "\n",
    "                        for index_,M_I_R in enumerate(os.listdir(awake_PP_path)):\n",
    "                            if not M_I_R == 'not_suitable':\n",
    "                                mir = '_'.join(M_I_R.split('_')[0:3])\n",
    "                                if mir == mouse:\n",
    "                                    c_path = awake_PP_path + M_I_R + r\"\\analysis_output\\reordered_recolored\\\\\" \n",
    "\n",
    "                        sequence_order_df = pd.read_csv(awake_PP_path+\"sequence_order.csv\")\n",
    "\n",
    "                        import ast\n",
    "                        seq_order= ast.literal_eval(sequence_order_df[sequence_order_df.mir == mouse].seq_order.values[0])\n",
    "                        num_dominant_seqs = int(sequence_order_df[sequence_order_df.mir == mouse].dominant_task_seqs)\n",
    "\n",
    "                        ############################################## calculate catagory breakdown\n",
    "\n",
    "                        if len(multi_cluster_df.coactive_cluster_group.unique()) > 1:\n",
    "\n",
    "                            real_order = list(np.array(seq_order)+1)\n",
    "\n",
    "                            # # mean ordering first : \n",
    "                            if len(real_order) > 3: # 3 will always be ordered so exclude\n",
    "                                relative_amounts,amounts,pair_outcomes,pairs = catagorize_seqs(real_order,num_dominant_seqs,meaned_order)\n",
    "                                summed_amounts = [sum(items) for items in conactinate_nth_items(amounts)]\n",
    "                            #     labels = ['ordered','reverse','repeat','misordered','other_to_task','task_to_other','other']\n",
    "                            #     fig, ax = plt.subplots()\n",
    "                            #     ax.bar(labels,summed_amounts)\n",
    "                            #     ax.set_title('catagory occurances (seqs ordered by mean spike time)')\n",
    "\n",
    "                            #     SaveFig('catagory occurances_1___chunk'+ str(index_+1) + '.png',chunk_path)\n",
    "\n",
    "                                all_pair_outcomes_todf = []\n",
    "                                all_pairs_todf = []\n",
    "                                for group in multi_cluster_df.new_cluster_group.unique():\n",
    "                                    group_pairs = np.array(pairs)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    group_pair_outcomes = np.array(pair_outcomes)[multi_cluster_df[multi_cluster_df.new_cluster_group == group].index.values]\n",
    "                                    all_pairs = []\n",
    "                                    all_pair_outcomes = []\n",
    "                                    for index,pair_ in enumerate(group_pairs[0:-1]):\n",
    "                                        all_pairs += [pair_]\n",
    "                                        all_pair_outcomes += [group_pair_outcomes[index]]\n",
    "\n",
    "                                    all_pair_outcomes_todf  += [all_pair_outcomes] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "                                    all_pairs_todf += [all_pairs] * len(multi_cluster_df[multi_cluster_df.new_cluster_group == group])\n",
    "\n",
    "                                multi_cluster_df['pairs_mean_ordering'] = all_pairs_todf\n",
    "                                multi_cluster_df['catagories_mean_ordering'] = all_pair_outcomes_todf\n",
    "\n",
    "                                multi_cluster_df['real_sequence_order'] = [real_order]*len(multi_cluster_df)\n",
    "\n",
    "                                chunk_summed_amounts += [list(np.array(summed_amounts)/sum(summed_amounts))]\n",
    "\n",
    "                                chunk_ordered_sum += sum(summed_amounts[0:3])\n",
    "                                chunk_coactive_total += sum(summed_amounts[0:4])\n",
    "                            else:\n",
    "                                print('only 3 seqs')\n",
    "\n",
    "                            \n",
    "                            \n",
    "#                             print(chunk_summed_amounts)\n",
    "                            \n",
    "        \n",
    "                # outside of chunk loop ################################################\n",
    "                \n",
    "                # changed how i do this, now task freq is worke dout by adding up instances across all chunks and lookig at the proportion rather than averageing across chunks \n",
    "                if (6-len(task_seqs)) == 0:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related,(task_related/len(task_seqs))]]\n",
    "                else:\n",
    "                    chunk_total_nontask_task_related_events += [[non_task_related/(6-len(task_seqs)),(task_related/len(task_seqs))]]      \n",
    "\n",
    "                ### add to animal vars\n",
    "                #1\n",
    "                reactivations_per_min += [np.mean(chunk_rpm)]\n",
    "                if np.mean(chunk_rpm) < 3:\n",
    "                    print('!!!!!')\n",
    "                #2\n",
    "                event_rate_binned +=[chunk_binned_rate]\n",
    "                er_bins_relative_to_so +=[chunk_bins_relative_so]\n",
    "                #3\n",
    "                event_lens += [chunk_event_lens]\n",
    "\n",
    "\n",
    "                #4 #########    \n",
    "                relative = []\n",
    "                totals = [sum(item) for item in chunk_total_nontask_task_related_events]\n",
    "                for i,item in enumerate(chunk_total_nontask_task_related_events):\n",
    "                    relative += [list(np.array(item)/totals[i])]\n",
    "\n",
    "                all_total_events += [total_events]\n",
    "\n",
    "                num_task_order_seqs = len(np.load(current_data_path+ 'task_order_seqs.npy')+1)\n",
    "\n",
    "                rel_task_nontask += [[np.mean(conactinate_nth_items(relative)[1]),np.mean(conactinate_nth_items(relative)[0])]]\n",
    "\n",
    "                chunks_task_nontask += conactinate_nth_items(relative)[1]\n",
    "\n",
    "                for item in coactive_freqs_chunk:\n",
    "                    if mouse in expert_mice:\n",
    "                        if item in e_coactive_freqs_counts:\n",
    "                            e_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            e_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in hlesion_mice:\n",
    "                        if item in hl_coactive_freqs_counts:\n",
    "                            hl_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            hl_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "                    elif mouse in learning_mice:\n",
    "                        if item in l_coactive_freqs_counts:\n",
    "                            l_coactive_freqs_counts[item] += [np.mean(coactive_freqs_chunk[item])]\n",
    "                        else:\n",
    "                            l_coactive_freqs_counts[item] = [np.mean(coactive_freqs_chunk[item])]\n",
    "\n",
    "\n",
    "\n",
    "                task_nontask_num_spikes+= [[np.mean(chunk_task_num_spikes),np.mean(chunk_nontask_num_spikes)]]\n",
    "                task_nontask_e_len+= [[np.mean(chunk_task_e_len),np.mean(chunk_nontask_e_len)]]\n",
    "\n",
    "                #5 #############\n",
    "\n",
    "                if len(chunk_summed_amounts) > 0:\n",
    "                    c_summed_amounts = []\n",
    "                    for item in conactinate_nth_items(chunk_summed_amounts):\n",
    "                        c_summed_amounts +=[np.mean(item)]\n",
    "                    mouse_summed_amounts += [c_summed_amounts]\n",
    "                else:\n",
    "                    mouse_summed_amounts += [[]]\n",
    "                    \n",
    "                    \n",
    "                ordered_sum += [chunk_ordered_sum]\n",
    "                ordered_misordered_total += [chunk_coactive_total]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'EJT'in mir:\n",
    "    c_mir = mir.split('T')[-1]\n",
    "else:\n",
    "    c_mir = mir\n",
    "full_sleep_path = None\n",
    "for ppsleep_file in os.listdir(sleep_ppseq_path):\n",
    "    if c_mir in ppsleep_file:\n",
    "        'print sleep file found'\n",
    "        full_sleep_path = os.path.join(sleep_ppseq_path,ppsleep_file + '/analysis_output')\n",
    "if full_sleep_path is None:\n",
    "    raise Exception(f\"no sleep file found for {mir}\")\n",
    "\n",
    "os.listdir(full_sleep_path)\n",
    "\n",
    "chunk_paths = []\n",
    "for file in os.listdir(full_sleep_path):\n",
    "    if 'chunk' in file:\n",
    "        chunk_paths += [os.path.join(full_sleep_path,file)]     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
