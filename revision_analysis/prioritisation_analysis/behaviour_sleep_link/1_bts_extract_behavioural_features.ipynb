{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfaba58a",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e179ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm \n",
    "from utils.behaviour_processing_functions import *\n",
    "import pickle\n",
    "import bisect\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# loop over and load in behavioural data from useable mirs\n",
    "def find_organised_path(mir,dat_path):\n",
    "    dat_path_2 = None\n",
    "    recording = None\n",
    "    print(mir)\n",
    "    for animal_implant in os.listdir(dat_path):\n",
    "        current_m_i = '_'.join([animal_implant.split('_')[0],animal_implant.split('_')[-1][-1]])\n",
    "        mi = '_'.join(mir.split('_')[0:-1])\n",
    "        if current_m_i == mi:\n",
    "            dat_path_2 = os.path.join(dat_path,animal_implant)\n",
    "            break\n",
    "    print(dat_path_2)\n",
    "    for ind,item in enumerate([record.split('ing')[-1].split('_')[0] for record in os.listdir(dat_path_2)]):\n",
    "        if item == mir.split('_')[-1]:\n",
    "            recording = os.listdir(dat_path_2)[ind]\n",
    "    full_org_dat_path = os.path.join(dat_path_2,recording)\n",
    "    print(full_org_dat_path)\n",
    "    return full_org_dat_path\n",
    "\n",
    "def remove_last_folder(path: str) -> str:\n",
    "    # 1. Normalize: collapse duplicate slashes, strip trailing ones\n",
    "    normalized = os.path.normpath(path)\n",
    "    # 2. dirname: drop the last component\n",
    "    return os.path.dirname(normalized)\n",
    "\n",
    "def find_data_paths(all_mice_dict,sleep_path):\n",
    "    for file in os.listdir(sleep_path):\n",
    "        if 'run' in file:\n",
    "            paths_dict = {}\n",
    "            mir = file.split('run')[0][0:-1]\n",
    "            paths_dict['sleep_path'] = sleep_path + file\n",
    "            awake_base = os.path.join(remove_last_folder(sleep_path), 'awake')\n",
    "            for awake_file in os.listdir(awake_base):\n",
    "                if mir in awake_file:\n",
    "                    # add in check to make sure the last part of the mir matches the last part of the item\n",
    "                    if mir.split('_')[-1] == awake_file.split('_')[2]:\n",
    "                        paths_dict['awake_path'] = os.path.join(awake_base, awake_file)\n",
    "            try: \n",
    "                paths_dict['full_org_dat_path'] = find_organised_path('EJT' + mir,r\"Z:\\projects\\sequence_squad\\organised_data\\animals\\\\\")\n",
    "            except:\n",
    "                paths_dict['full_org_dat_path']  = find_organised_path(mir,r\"Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\\")\n",
    "            all_mice_dict[mir] = paths_dict\n",
    "    return all_mice_dict\n",
    "\n",
    "def remove_last_folder(path: str) -> str:\n",
    "    # 1. Normalize: collapse duplicate slashes, strip trailing ones\n",
    "    normalized = os.path.normpath(path)\n",
    "    # 2. dirname: drop the last component\n",
    "    return os.path.dirname(normalized)\n",
    "\n",
    "def find_data_paths(all_mice_dict,sleep_path):\n",
    "    for file in os.listdir(sleep_path):\n",
    "        if 'run' in file:\n",
    "            paths_dict = {}\n",
    "            mir = file.split('run')[0][0:-1]\n",
    "            paths_dict['sleep_path'] = sleep_path + file\n",
    "            awake_base = os.path.join(remove_last_folder(sleep_path), 'awake')\n",
    "            for awake_file in os.listdir(awake_base):\n",
    "                if mir in awake_file:\n",
    "                    # add in check to make sure the last part of the mir matches the last part of the item\n",
    "                    if mir.split('_')[-1] == awake_file.split('_')[2]:\n",
    "                        paths_dict['awake_path'] = os.path.join(awake_base, awake_file)\n",
    "            try: \n",
    "                paths_dict['full_org_dat_path'] = find_organised_path('EJT' + mir,r\"Z:\\projects\\sequence_squad\\organised_data\\animals\\\\\")\n",
    "            except:\n",
    "                paths_dict['full_org_dat_path']  = find_organised_path(mir,r\"Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\\")\n",
    "            all_mice_dict[mir] = paths_dict\n",
    "    return all_mice_dict\n",
    "\n",
    "def process_awake_data_return_seq_dfs(unmasked_spikes_df, chunk_time, awake_neuron_order, colors, plotting_limit,bin_size=0.2, seq_size_threshold=5):\n",
    "    \"\"\"\n",
    "    Processes spike data to extract time-localized spike events for each sequence type (1–6).\n",
    "    \"\"\"\n",
    "    seq_types = np.unique(unmasked_spikes_df.sequence_type_adjusted)\n",
    "\n",
    "    # Gather spike timestamps by sequence type\n",
    "    seq_spikes = [unmasked_spikes_df.timestamp[unmasked_spikes_df.sequence_type_adjusted == seq_type].values for seq_type in seq_types]\n",
    "\n",
    "    # Compute binned spike histograms\n",
    "    seq_spike_occurrence = [list(np.histogram(spikes, bins=np.arange(0, np.diff(chunk_time)[0], bin_size))[0]) for spikes in seq_spikes]\n",
    "\n",
    "    seq_event_dfs = []\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5))\n",
    "    for i in range(1, 7):  # process sequence types 1–6\n",
    "        print(f\"Processing sequence type: {i}\")\n",
    "        seq_spike_count = seq_spike_occurrence[i]\n",
    "        groups = return_inds_for_seq_groups(seq_spike_count)\n",
    "\n",
    "        # Plot sequence summary (raster + histogram)\n",
    "        plot_sequence_summary(ax1,ax2,unmasked_spikes_df, awake_neuron_order, colors, seq_spike_count, groups, i, plotting_limit,bin_size)\n",
    "\n",
    "        # Extract sequence events as separate DataFrames\n",
    "        seq_event_dfs.extend(\n",
    "            extract_sequence_events(unmasked_spikes_df, i, groups, bin_size, seq_size_threshold)\n",
    "        )\n",
    "\n",
    "    return seq_event_dfs\n",
    "\n",
    "def return_inds_for_seq_groups(lst):\n",
    "    groups = []\n",
    "    new = True\n",
    "    for ind,item in enumerate(lst):\n",
    "        if new:\n",
    "            if item > 0:\n",
    "                start = ind\n",
    "                new = False\n",
    "        else:\n",
    "            if item == 0:\n",
    "                end = ind-1\n",
    "                groups.append((start, end))\n",
    "                new = True\n",
    "    return groups\n",
    "\n",
    "def plot_sequence_summary(ax1,ax2,unmasked_spikes_df, awake_neuron_order, colors, seq_spike_count, groups, i, time_window, bin_size):\n",
    "    \"\"\"\n",
    "    Plots spike raster and sequence histogram for a given sequence type.\n",
    "    \"\"\"\n",
    "    # Filter spikes within the plotting window\n",
    "    mask = (unmasked_spikes_df.timestamp > time_window[0]) & (unmasked_spikes_df.timestamp < time_window[1])\n",
    "    visible_spikes = unmasked_spikes_df[mask]\n",
    "    valid_seq_mask = visible_spikes.sequence_type_adjusted >= 0\n",
    "    spike_colors = np.array(colors)[visible_spikes[valid_seq_mask].sequence_type_adjusted.values.astype(int)]\n",
    "\n",
    "    # Spike raster\n",
    "    ax1.scatter(\n",
    "        visible_spikes[valid_seq_mask].timestamp,\n",
    "        awake_neuron_order[mask][valid_seq_mask],\n",
    "        marker='o', s=40, linewidth=0, color=spike_colors, alpha=1\n",
    "    )\n",
    "\n",
    "    # Histogram and detected groups\n",
    "    ax2.plot(seq_spike_count, color=colors[i])\n",
    "    for start, end in groups:\n",
    "        ax2.plot([start, end], [-5, -5], color='red')\n",
    "\n",
    "    ax1.set_xlim([time_window[0], time_window[-1]])\n",
    "    ax2.set_xlim(time_window[0]/bin_size,time_window[-1] / bin_size)\n",
    "\n",
    "def extract_sequence_events(df, sequence_type, groups, bin_size, seq_size_threshold):\n",
    "    \"\"\"\n",
    "    Extracts spike events from continuous groups of time bins for a specific sequence type.\n",
    "    \"\"\"\n",
    "    extracted = []\n",
    "\n",
    "    for start, end in groups:\n",
    "        group_start_time = (start * bin_size) - 0.5\n",
    "        group_end_time = (end * bin_size) + 0.5\n",
    "\n",
    "        time_mask = (df.timestamp > group_start_time) & (df.timestamp < group_end_time)\n",
    "        group_spikes = df[time_mask]\n",
    "        matching_seq = group_spikes[group_spikes.sequence_type_adjusted == sequence_type]\n",
    "\n",
    "        if len(matching_seq) > seq_size_threshold:\n",
    "            extracted.append(matching_seq)\n",
    "\n",
    "    return extracted\n",
    "\n",
    "def split_sequence_events(seq_event_dfs):\n",
    "    # Split sequence events into a dictionary by sequence type.\n",
    "    # Each key is the sequence type, and the value is a list of DataFrames for those events\n",
    "    seq_events = {}\n",
    "    for event in seq_event_dfs:\n",
    "        # add the sequence type as a key if it doesn't exist\n",
    "        if str(int(event.sequence_type_adjusted.values[0])) not in seq_events:\n",
    "            seq_events[str(int(event.sequence_type_adjusted.values[0]))] = [event]\n",
    "        else:\n",
    "            seq_events[str(int(event.sequence_type_adjusted.values[0]))].append(event)\n",
    "    return seq_events\n",
    "\n",
    "def calcuate_neuron_consistency(seq_id, unmasked_spikes_df, seq_events_dict):\n",
    "    \"\"\"\n",
    "    Calculate the proportion of times each neuron appears in the sequence events for a given sequence type.\n",
    "    \"\"\"\n",
    "    proportion_appeared = [] \n",
    "    for neuron_id in unmasked_spikes_df.neuron.unique():\n",
    "        appears = 0\n",
    "        for event in seq_events_dict[str(seq_id)]:\n",
    "            if neuron_id in event.neuron.values:\n",
    "                appears += 1       \n",
    "        if appears > 0:\n",
    "            total_events = len(seq_events_dict[str(seq_id)])\n",
    "            proportion_appeared += [appears/total_events]\n",
    "    return proportion_appeared\n",
    "\n",
    "def calculate_standard_deviation_of_relative_spiking_positions(unmasked_spikes_df, seq_events_dict,seq_id):\n",
    "    perneuron_relative_positions =[]\n",
    "    for neuron_id in unmasked_spikes_df.neuron.unique():\n",
    "        relative_positions = []\n",
    "        for event in seq_events_dict[str(seq_id)]:\n",
    "            if neuron_id in event.neuron.values:\n",
    "                # find the times that neuron fired for this event and find average\n",
    "                neuron_event_mean_firing_time = np.nanmean(event.timestamp.values[np.where(event.neuron == neuron_id)[0]])\n",
    "                start = min(event.timestamp.values)\n",
    "                end = max(event.timestamp.values)\n",
    "                # determine where the event time is compared to start and end of event\n",
    "                gap = neuron_event_mean_firing_time - start\n",
    "                if gap == 0:\n",
    "                    position = 0\n",
    "                else:\n",
    "                    position = (gap/np.diff([start,end]))[0]     \n",
    "                relative_positions += [position]\n",
    "        if len(relative_positions) > 0:\n",
    "            # calculate the standard deviation of the relative positions\n",
    "            perneuron_relative_positions += [np.std(relative_positions)]\n",
    "    return np.nanmean(perneuron_relative_positions)\n",
    "\n",
    "# Function to find the closest index using np.searchsorted\n",
    "def find_closest_indices(timestamps, target_times):\n",
    "    indices = np.searchsorted(timestamps, target_times)\n",
    "    indices = np.clip(indices, 1, len(timestamps) - 1)  # Ensure indices are within bounds\n",
    "    \n",
    "    # Compare target_time with its neighbors to find the closest\n",
    "    left_indices = indices - 1\n",
    "    right_indices = indices\n",
    "    left_diffs = np.abs(timestamps[left_indices] - target_times)\n",
    "    right_diffs = np.abs(timestamps[right_indices] - target_times)\n",
    "    \n",
    "    return np.where(left_diffs <= right_diffs, left_indices, right_indices)\n",
    "\n",
    "\n",
    "def get_tracking_data_new_data(full_org_dat_path):\n",
    "    track_path = os.path.join(full_org_dat_path,'video/tracking/')\n",
    "\n",
    "    for tracking_file in os.listdir(track_path):\n",
    "        if 'BACK' in tracking_file and not 'PORTS' in tracking_file and '.h5' in tracking_file:\n",
    "            task_tracking_csv = os.path.join(track_path,tracking_file)\n",
    "            break\n",
    "    for tracking_file in os.listdir(track_path):\n",
    "        if 'BACK' in tracking_file and 'PORTS' in tracking_file and '.h5' in tracking_file:\n",
    "            port_tracking_csv = os.path.join(track_path,tracking_file)\n",
    "            break\n",
    "        \n",
    "    # load in tracking data:        \n",
    "    back_head_centre = get_dlc_data(task_tracking_csv,interp = True,val = 0.9995)\n",
    "    back_ports = get_dlc_data(port_tracking_csv,interp = True,val = 0.95)\n",
    "\n",
    "    if 'head_centre' in list(back_head_centre):\n",
    "        back_head_centre_df = back_head_centre['head_centre'][0] \n",
    "        \n",
    "    p1,p2,p3,p4,p5 = back_ports['Port2'][0],back_ports['Port1'][0],back_ports['Port6'][0],back_ports['Port3'][0],back_ports['Port7'][0]\n",
    "        \n",
    "    return back_head_centre_df,p1,p2,p3,p4,p5\n",
    "\n",
    "def Define_task_period_plot_ports(ax,behav_sync,back_p1,back_p2,back_p3,back_p4,back_p5):\n",
    "    try:\n",
    "        # find the start and end frames for the back camera during task period\n",
    "        back_cam_task_period_s,back_cam_task_period_e = behav_sync.backcam_trialstart_closest_cameraframes.values[0], behav_sync.backcam_trialstart_closest_cameraframes.values[-1]\n",
    "        # make a mask to cut down to this period. \n",
    "        task_period_backcam_mask = (back_p1.index.values > back_cam_task_period_s) * (back_p1.index.values < back_cam_task_period_e)\n",
    "\n",
    "        port_locations = []\n",
    "        for item in [back_p1[task_period_backcam_mask],back_p2[task_period_backcam_mask],back_p3[task_period_backcam_mask],back_p4[task_period_backcam_mask],back_p5[task_period_backcam_mask]]:\n",
    "            ax.plot(np.median(item['interped_x'].values),np.median(item['interped_y'].values),'o',color = 'grey', markersize = 80)\n",
    "            port_locations += [[np.median(item['interped_x'].values),np.median(item['interped_y'].values)]]\n",
    "    except:\n",
    "        port_locations = []\n",
    "        for item in [back_p1,back_p2,back_p3,back_p4,back_p5]:\n",
    "            ax.plot(np.median(item['interped_x'].values),np.median(item['interped_y'].values),'o',color = 'grey', markersize = 80)\n",
    "            port_locations += [[np.median(item['interped_x'].values),np.median(item['interped_y'].values)]]\n",
    "    return port_locations\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "def distance_to_next_reward(start, end, rewards):\n",
    "\n",
    "    # 1. Filter to rewards at or after the event start\n",
    "    future_rewards = [r for r in rewards if r >= start]\n",
    "    if not future_rewards:\n",
    "        return None  # no reward after start\n",
    "    \n",
    "    # 2. Find the earliest such reward\n",
    "    next_reward = min(future_rewards)\n",
    "    \n",
    "    # 3. If it falls on or before the event end → distance is zero\n",
    "    if next_reward <= end:\n",
    "        return 0.0\n",
    "    \n",
    "    # 4. Otherwise → distance from start\n",
    "    return next_reward - start\n",
    "\n",
    "def get_trajectories_for_each_sequence_instance(behav_sync_df, back_head_centre_df, camera_timestamps_df, awake_time_span, cam_ephys_time_offset, seq_events_dict, p1, p2, p3, p4, p5):\n",
    "    seq_by_seq_xy_trajectories = [] \n",
    "    seq_by_seq_trajectory_times = []\n",
    "    fig, ax = plt.subplots(1, 6,figsize=(40, 6))\n",
    "    for seq_id in range(1,7):\n",
    "        index = int(seq_id) -1 \n",
    "        # SET THE AXES:\n",
    "        port_locations = Define_task_period_plot_ports(ax[index],behav_sync_df,p1,p2,p3,p4,p5)\n",
    "        min_x = port_locations[1][0] - (port_locations[0][0] - port_locations[1][0]) # port 2x - (port1x - port2x)\n",
    "        max_x = port_locations[3][0] + (port_locations[0][0] - port_locations[1][0]) # port 4x + (port1x - port2x)\n",
    "        min_y = port_locations[2][1] - (port_locations[0][1] - port_locations[2][1]) # port 3y - (port1y - port3y)\n",
    "        max_y = port_locations[0][1] + (port_locations[0][1] - port_locations[2][1]) # port 1y + (port1y - port3y)\n",
    "        ax[index].set_xlim(min_x,max_x)\n",
    "        ax[index].set_ylim(min_y,max_y)\n",
    "        ax[index].invert_yaxis()\n",
    "        \n",
    "        sequence_trajectories = []\n",
    "        sequence_time =[]\n",
    "        for event in seq_events_dict[str(seq_id)]:\n",
    "            # get the start and end times of the event in ephys time\n",
    "            event_start_ephys = awake_time_span[0] + min(event.timestamp.values)\n",
    "            event_end_ephys = awake_time_span[0] + max(event.timestamp.values)\n",
    "            # convert to camera time\n",
    "            start_time_cam = event_start_ephys - cam_ephys_time_offset\n",
    "            end_time_cam = event_end_ephys - cam_ephys_time_offset\n",
    "            # find the closest indices in the camera timestamps to the start and end times of the event\n",
    "            start_end_cam_inds = find_closest_indices(camera_timestamps_df['Time Stamps'].values,[start_time_cam, end_time_cam])\n",
    "            \n",
    "            x = back_head_centre_df['x'][start_end_cam_inds[0]:start_end_cam_inds[1]].values\n",
    "            y = back_head_centre_df['y'][start_end_cam_inds[0]:start_end_cam_inds[1]].values\n",
    "            \n",
    "            sequence_trajectories += [[x,y]]\n",
    "            sequence_time += [[end_time_cam - start_time_cam]]\n",
    "\n",
    "        for item in sequence_trajectories:\n",
    "            x_values = item[0]\n",
    "            y_values = item[1]\n",
    "            ax[index].plot(x_values,y_values,'-',color = ['red','green','yellow','purple','blue','orange'][index], alpha = 0.1)\n",
    "            \n",
    "        seq_by_seq_xy_trajectories += [sequence_trajectories]\n",
    "        seq_by_seq_trajectory_times += [sequence_time]\n",
    "    return seq_by_seq_xy_trajectories,seq_by_seq_trajectory_times,port_locations\n",
    "\n",
    "\n",
    "def closest_point_on_curve(curve, port):\n",
    "    \"\"\"\n",
    "    Finds the closest point on the curve to the given port.\n",
    "    \n",
    "    curve: List of (x, y) tuples representing the curve (circular path).\n",
    "    port: (x, y) tuple representing the port location.\n",
    "    \n",
    "    Returns a tuple (closest_point, index) where:\n",
    "      - closest_point is the (x, y) closest point on the curve.\n",
    "      - index is the index of the closest point in the curve.\n",
    "    \"\"\"\n",
    "    distances = [distance.euclidean(port, point) for point in curve]\n",
    "    closest_idx = np.argmin(distances)\n",
    "    return curve[closest_idx], closest_idx\n",
    "\n",
    "def associate_ports_with_curve(curve, ports):\n",
    "    \"\"\"\n",
    "    Associates each port with the closest deliberate visit on the curve, moving chronologically.\n",
    "    \n",
    "    curve: List of (x, y) tuples representing the curve (circular path).\n",
    "    ports: List of (x, y) tuples representing the port locations in the order of visits.\n",
    "    \n",
    "    Returns a list of (port, closest_point_on_curve, percentage) tuples where:\n",
    "      - closest_point_on_curve is the closest (x, y) point on the curve.\n",
    "      - percentage is the location of the closest point as a percentage of the curve length.\n",
    "    \"\"\"\n",
    "    visited_ports = []\n",
    "    percentage_locations = []\n",
    "    curve_length = len(curve)  # Total number of points on the curve\n",
    "    \n",
    "    for port in ports:\n",
    "        # Find the closest point to the current port and its index\n",
    "        closest_point, closest_idx = closest_point_on_curve(curve, port)\n",
    "        \n",
    "        # Calculate the percentage position along the curve\n",
    "        percentage = (closest_idx / curve_length) * 100\n",
    "        \n",
    "        # Add the port, closest point, and percentage to the list\n",
    "        visited_ports.append(closest_point)\n",
    "        percentage_locations.append(percentage)\n",
    "    \n",
    "    return visited_ports,percentage_locations\n",
    "\n",
    "\n",
    "def circular_distance(a, b, circumference=100.0):\n",
    "    \"\"\"Minimal distance on a circle of given circumference.\"\"\"\n",
    "    diff = abs(a - b) % circumference\n",
    "    return min(diff, circumference - diff)\n",
    "\n",
    "def find_best_ports(segments, ports):\n",
    "    \"\"\"\n",
    "    For each (start, end) segment on [0,100):\n",
    "      - pick the port closest to start\n",
    "      - pick the port closest to end\n",
    "      - but if those two ports are identical, fall back to enclosing ports\n",
    "    Returns a list of (idx_start_port, idx_end_port).\n",
    "    \"\"\"\n",
    "    # Pre-sort ports and keep original indices\n",
    "    sorted_ports = sorted((p, i) for i, p in enumerate(ports))\n",
    "    locs, orig_idx = zip(*sorted_ports)\n",
    "    n = len(locs)\n",
    "\n",
    "    def enclosing_indices(start, end):\n",
    "        # same logic as before\n",
    "        i_after_start = bisect.bisect_right(locs, start)\n",
    "        i_before_start = (i_after_start - 1) % n\n",
    "        i_after_end = bisect.bisect_left(locs, end) % n\n",
    "        return orig_idx[i_before_start], orig_idx[i_after_end]\n",
    "\n",
    "    results = []\n",
    "    for start, end in segments:\n",
    "        # find closest to start\n",
    "        dists_start = [circular_distance(start, p) for p in locs]\n",
    "        best_i_start = int(np.argmin(dists_start))\n",
    "        # find closest to end\n",
    "        dists_end = [circular_distance(end, p) for p in locs]\n",
    "        best_i_end = int(np.argmin(dists_end))\n",
    "\n",
    "        idx_start, idx_end = orig_idx[best_i_start], orig_idx[best_i_end]\n",
    "\n",
    "        # if they collide, fall back\n",
    "        if idx_start == idx_end:\n",
    "            idx_start, idx_end = enclosing_indices(start, end)\n",
    "\n",
    "        results.append((idx_start, idx_end))\n",
    "\n",
    "    return results\n",
    "\n",
    "def compute_transition_accuracy(\n",
    "    transitions,\n",
    "    transit_goal,\n",
    "    n_ports=5\n",
    "):\n",
    "    \"\"\"\n",
    "    transitions: list of ['pause'] or [start:int, end:int]\n",
    "    transit_goal: 1D array or list of port numbers defining the template\n",
    "    n_ports: total ports in the system (default 5)\n",
    "    \n",
    "    Returns: dict mapping (a,b) -> stats dict with counts and percentages.\n",
    "    \"\"\"\n",
    "    goal = list(map(int, transit_goal))\n",
    "    pairs = []\n",
    "    # Build straight pairs\n",
    "    for i in range(len(goal)-1):\n",
    "        pairs.append((goal[i], goal[i+1]))\n",
    "    # If goal spans all ports, add the wrap‐around pair\n",
    "    if len(goal) == n_ports:\n",
    "        pairs.append((goal[-1], goal[0]))\n",
    "    \n",
    "    # Initialize counters\n",
    "    stats = {pair: Counter() for pair in pairs}\n",
    "    \n",
    "    # Tally real transitions\n",
    "    for t in transitions:\n",
    "        if t == ['pause']:\n",
    "            continue\n",
    "        start, end = int(t[0]), int(t[1])\n",
    "        # only consider if this start port matches one of our template-from ports\n",
    "        if (start, end) in stats:\n",
    "            stats[(start, end)]['correct'] += 1\n",
    "        else:\n",
    "            # if it started at any template-from port but went elsewhere, count error\n",
    "            for pair in pairs:\n",
    "                if start == pair[0]:\n",
    "                    stats[pair]['error'] += 1\n",
    "                    break\n",
    "    \n",
    "    # Compute percentages\n",
    "    results = {}\n",
    "    for pair, cnt in stats.items():\n",
    "        total = cnt['correct'] + cnt['error']\n",
    "        if total == 0:\n",
    "            pct_correct = pct_error = None\n",
    "        else:\n",
    "            pct_correct = 100 * cnt['correct'] / total\n",
    "            pct_error   = 100 - pct_correct\n",
    "        results[pair] = {\n",
    "            'total_attempts': total,\n",
    "            'correct': cnt['correct'],\n",
    "            'error': cnt['error'],\n",
    "            'pct_correct': pct_correct,\n",
    "            'pct_error': pct_error\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def port_transitions(start_idx, end_idx, n_ports=5):\n",
    "    \"\"\"\n",
    "    Returns the list of port indices traversed from start_idx to end_idx\n",
    "    (inclusive), stepping +1 each time and wrapping around modulo n_ports.\n",
    "    \n",
    "    Example:\n",
    "        port_transitions(2, 0) -> [2, 3, 4, 0]\n",
    "    \"\"\"\n",
    "    if not (0 <= start_idx < n_ports) or not (0 <= end_idx < n_ports):\n",
    "        raise ValueError(\"start_idx and end_idx must be in [0, n_ports)\")\n",
    "    \n",
    "    # If start ≤ end, it's just a direct range; otherwise wrap around.\n",
    "    if start_idx <= end_idx:\n",
    "        return list(range(start_idx, end_idx + 1))\n",
    "    else:\n",
    "        return list(range(start_idx, n_ports)) + list(range(0, end_idx + 1))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f4e239",
   "metadata": {},
   "source": [
    "#  find all data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641fd67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJT136_1_3\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT136_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT136_implant1\\recording3_11-11-2021\n",
      "EJT136_1_4\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT136_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT136_implant1\\recording4_12-11-2021\n",
      "EJT148_2_2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT148_implant2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT148_implant2\\recording2_19-10-2020\n",
      "EJT149_1_1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT149_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT149_implant1\\recording1_16-11-2021\n",
      "EJT178_1_4\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording4_18-03-2022\n",
      "EJT178_1_5\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording5_21-03-2022\n",
      "EJT178_1_6\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording6_29-03-2022\n",
      "EJT178_1_7\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording7_30-03-2022\n",
      "EJT178_1_8\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording8_31-03-2022\n",
      "EJT178_1_9\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant1\\recording9_01-04-2022\n",
      "EJT178_2_1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\\recording1_04-04-2022\n",
      "EJT178_2_2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\\recording2_05-04-2022\n",
      "EJT178_2_4\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT178_implant2\\recording4_07-04-2022\n",
      "EJT269_1_1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording1_13-05-2023\n",
      "EJT269_1_3\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording3_16-05-2023\n",
      "EJT269_1_4\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording4_18-05-2023\n",
      "EJT269_1_7\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording7_23-05-2023\n",
      "EJT270_1_3\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording3_14-05-2023\n",
      "EJT270_1_5\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording5_17-05-2023\n",
      "EJT270_1_6\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording6_19-05-2023\n",
      "EJTseq006_1_11\n",
      "None\n",
      "seq006_1_11\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording11_28-11-2024\n",
      "EJT268_1_2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT268_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT268_implant1\\recording2_02-05-2023\n",
      "EJT269_1_1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording1_13-05-2023\n",
      "EJT269_1_2\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording2_15-05-2023\n",
      "EJT269_1_3\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT269_implant1\\recording3_16-05-2023\n",
      "EJT270_1_1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording1_10-05-2023\n",
      "EJT270_1_3\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording3_14-05-2023\n",
      "EJTap5R_1_1\n",
      "None\n",
      "ap5R_1_1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\\recording1_16-11-2024\n",
      "EJTap5R_1_3\n",
      "None\n",
      "ap5R_1_3\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\\recording3_19-11-2024\n",
      "EJTseq006_1_1\n",
      "None\n",
      "seq006_1_1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording1_15-11-2024\n",
      "EJTseq006_1_4\n",
      "None\n",
      "seq006_1_4\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording4_19-11-2024\n",
      "EJTseq006_1_5\n",
      "None\n",
      "seq006_1_5\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording5_20-11-2024\n",
      "EJTseq006_1_6\n",
      "None\n",
      "seq006_1_6\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording6_21-11-2024\n",
      "EJTseq007_1_1\n",
      "None\n",
      "seq007_1_1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\\recording1_18-11-2024\n",
      "EJTseq007_1_2\n",
      "None\n",
      "seq007_1_2\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\\recording2_19-11-2024\n",
      "EJTseq007_1_3\n",
      "None\n",
      "seq007_1_3\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq007_implant1\\recording3_20-11-2024\n",
      "EJTap5R_1_2\n",
      "None\n",
      "ap5R_1_2\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\ap5R_implant1\\recording2_18-11-2024\n",
      "EJTseq006_1_10\n",
      "None\n",
      "seq006_1_10\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording10_27-11-2024\n",
      "EJTseq006_1_3\n",
      "None\n",
      "seq006_1_3\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording3_18-11-2024\n",
      "EJTseq006_1_8\n",
      "None\n",
      "seq006_1_8\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording8_25-11-2024\n",
      "EJTseq006_1_9\n",
      "None\n",
      "seq006_1_9\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\n",
      "Z:\\projects\\sequence_squad\\revision_data\\organised_data\\animals\\\\seq006_implant1\\recording9_26-11-2024\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get all the mice and paths from the expert and learning data\n",
    "all_mice_dict = {}\n",
    "all_mice_dict = find_data_paths(all_mice_dict,'Z:\\projects\\sequence_squad\\ppseq_finalised_publication_data\\expert\\postsleep\\\\')\n",
    "all_mice_dict = find_data_paths(all_mice_dict,'Z:\\projects\\sequence_squad\\ppseq_finalised_publication_data\\learning\\postsleep\\\\')\n",
    "all_mice_dict = find_data_paths(all_mice_dict,'Z:\\projects\\sequence_squad\\ppseq_finalised_publication_data\\prioritisation_data\\postsleep\\\\')\n",
    "print('____________________________________________________________________________________________________')\n",
    "print('____________________________________________________________________________________________________')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce008b",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525fe4dd",
   "metadata": {},
   "source": [
    "- total sequence expression\n",
    "- movement variability\n",
    "- movement speed\n",
    "- error rate \n",
    "- proportion linked to reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "\u001b[1m Processing: 270_1_3\u001b[0m\n",
      "Z:\\projects\\sequence_squad\\organised_data\\animals\\\\EJT270_implant1\\recording3_14-05-2023\\behav_sync/2_task\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmett Thompson\\AppData\\Local\\Temp\\ipykernel_19120\\2567941363.py:26: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  unmasked_spikes_df = pickle.load(handle)\n"
     ]
    }
   ],
   "source": [
    "# behaviour to sleep \n",
    "behav_to_sleep_animals = ['EJT136_1_3','EJT136_1_4','EJT149_1_1','EJT178_1_4','EJT178_1_5','EJT178_1_6','EJT178_1_7','EJT178_1_8','EJT178_1_9','EJT178_2_1','EJT178_2_2','EJT178_2_4','EJT269_1_1','EJT269_1_3','EJT269_1_4','EJT269_1_7','EJT270_1_3','EJT270_1_5','EJT270_1_6','seq006_1_11','EJT268_1_2','EJT269_1_2','EJT270_1_1','ap5R_1_1','ap5R_1_3','seq006_1_4','seq006_1_5','seq006_1_6','seq007_1_1','seq007_1_2','seq007_1_3','seq006_1_8','seq006_1_9','seq006_1_10','ap5R_1_2']\n",
    "\n",
    "behav_to_sleep_animals = ['EJT270_1_3']\n",
    "\n",
    "for mouse in behav_to_sleep_animals:\n",
    "    # extract paths from the dict \n",
    "    if 'EJT' in mouse:\n",
    "        mouse = mouse.split('EJT')[-1]\n",
    "    sleep_path = all_mice_dict[mouse]['sleep_path']\n",
    "    awake_path = all_mice_dict[mouse]['awake_path']\n",
    "    full_org_dat_path = all_mice_dict[mouse]['full_org_dat_path']\n",
    "    \n",
    "    print('____________________________________________________________________________________________________')\n",
    "    print(f\"\\033[1m Processing: {mouse}\\033[0m\")\n",
    "    \n",
    "    ############\n",
    "    # LOAD STUFF\n",
    "    ############\n",
    "    \n",
    "    # load behavioural data\n",
    "    behav_sync_df,transition_sync_df = load_behav_sync(all_mice_dict[mouse]['full_org_dat_path'])\n",
    "    \n",
    "    ### load in awake ppseq data for mouse\n",
    "    with open(all_mice_dict[mouse]['awake_path'] + r'\\analysis_output\\\\' + 'spikes_seq_type_adjusted.pickle', 'rb') as handle:\n",
    "        unmasked_spikes_df = pickle.load(handle)\n",
    "        \n",
    "    with open(all_mice_dict[mouse]['awake_path'] + r'\\analysis_output\\reordered_recolored\\\\' + 'neuron_order', 'rb') as handle:\n",
    "        awake_neuron_order = pickle.load(handle)\n",
    "\n",
    "    colors = pd.read_pickle(all_mice_dict[mouse]['awake_path'] + r\"\\analysis_output\\reordered_recolored\\\\\" + 'colors')\n",
    "    \n",
    "    #load json\n",
    "    import json\n",
    "    params = None\n",
    "    for file in os.listdir(all_mice_dict[mouse]['awake_path'] + r'\\trainingData\\\\'):\n",
    "        if 'json' in file:\n",
    "            param_path = os.path.join(all_mice_dict[mouse]['awake_path'] + r'\\trainingData\\\\', file)\n",
    "            with open(param_path,'r') as f:\n",
    "                params = json.load(f)\n",
    "    awake_time_span = params['time_span'][0]\n",
    "    \n",
    "    # cluster the awake spikes into individual sequence events\n",
    "    seq_event_dfs = process_awake_data_return_seq_dfs(unmasked_spikes_df,awake_time_span,awake_neuron_order,colors,[100,120]) \n",
    "    ## spit the sequence events into individual sequence types\n",
    "    seq_events_dict = split_sequence_events(seq_event_dfs)\n",
    "    \n",
    "    # load sequence order\n",
    "    sequence_order = pd.read_csv(r'Z:\\projects\\sequence_squad\\ppseq_finalised_publication_data\\sequence_order.csv')\n",
    "    mir_row = None\n",
    "    for ind, row in sequence_order.iterrows():\n",
    "        if row.mir in mouse:\n",
    "            mir_row = row\n",
    "    seq_order = literal_eval(mir_row.seq_order)\n",
    "    \n",
    "    ############################# movement variability for each motif region ####################\n",
    "    ## TRACKING PREP - laod in data, find average curves etc. \n",
    "    #############################################################################################\n",
    "\n",
    "    try:\n",
    "        back_head_centre_df,p1,p2,p3,p4,p5 = get_tracking_data_EJT_data(full_org_dat_path)\n",
    "    except:\n",
    "        back_head_centre_df,p1,p2,p3,p4,p5 = get_tracking_data_new_data(full_org_dat_path)\n",
    "\n",
    "    if not mouse == '148_2_2':\n",
    "        # search for the timestamps df, if it doesnt exist (it wont for the old data, only for the newer recordings) then remake it\n",
    "        camera_timestamps_df = None\n",
    "        for files in os.listdir(full_org_dat_path + r'\\video\\videos\\\\'):\n",
    "            if '.csv' in files:\n",
    "                if 'BACK' in files:\n",
    "                    camera_timestamps_df = pd.read_csv(full_org_dat_path + r'\\video\\videos\\\\'+ files)\n",
    "        if camera_timestamps_df is None:\n",
    "            # process/uncycle the raw timestamps\n",
    "            camera_timestamps_df = process_raw_timestamps(full_org_dat_path)\n",
    "            \n",
    "    # get continuous regions information\n",
    "    continuous_regions_df = get_sequence_regions(mouse,awake_path,sequence_order)\n",
    "\n",
    "\n",
    "    if 'epoch' in list(camera_timestamps_df):\n",
    "        task_mask = camera_timestamps_df.epoch == 'task'\n",
    "\n",
    "        # find task relevant tracking periods, extract times mouse is close to each behavioural port\n",
    "        threshold_breaks,port_centroids,current_x,current_y,radius_used = find_task_relevant_tracking_points(back_head_centre_df[task_mask],p1[task_mask],p2[task_mask],p3[task_mask],p4[task_mask],p5[task_mask],radius = 45)\n",
    "    else:\n",
    "        # find task relevant tracking periods, extract times mouse is close to each behavioural port\n",
    "        threshold_breaks,port_centroids,current_x,current_y,radius_used = find_task_relevant_tracking_points(back_head_centre_df,p1,p2,p3,p4,p5,radius = 45) \n",
    "\n",
    "    ## each of these is a frame so we know the timing between them. ie. one frame is 1/60s \n",
    "    if not mouse == '148_2_2':\n",
    "        fps = 1/np.nanmean(np.diff(camera_timestamps_df['Time Stamps'].values))\n",
    "    else:\n",
    "        fps = 60\n",
    "    time_filter = 2 #in s\n",
    "    frame_filter = int(time_filter / (1/fps))\n",
    "\n",
    "    #we know when the mouse is close to each port, so find times when the mouse goes from port to port \n",
    "    start_port,end_port = 5,2\n",
    "    T1_start_ind, T1_end_ind = extract_port_to_port_trajetories(start_port,end_port,frame_filter,threshold_breaks,4,-1,-1)\n",
    "    start_port,end_port = 2,3\n",
    "    T2_start_ind, T2_end_ind = extract_port_to_port_trajetories(start_port,end_port,frame_filter,threshold_breaks,1,4,5)\n",
    "    start_port,end_port = 3,4\n",
    "    T3_start_ind, T3_end_ind = extract_port_to_port_trajetories(start_port,end_port,frame_filter,threshold_breaks,1,2,5)\n",
    "    start_port,end_port = 4,5\n",
    "    T4_start_ind, T4_end_ind = extract_port_to_port_trajetories(start_port,end_port,frame_filter,threshold_breaks,1,2,3)\n",
    "\n",
    "    # find average curves by taking traject lines and make them roughly equivalent by interpolating so they have the same number of trakcing points, then for each point in each trajectory find the average xy position to create an average trajectory line \n",
    "    a_curve1,a_curve2,a_curve3,a_curve4 = find_average_curves(port_centroids,T1_start_ind,T1_end_ind,T2_start_ind,T2_end_ind,T3_start_ind,T3_end_ind,T4_start_ind,T4_end_ind,current_x,current_y,buffer = 10, radius = 45)\n",
    "\n",
    "    # join each curve, join them at the point that they touch, or if they dont touch just join the two ends to each other\n",
    "    new = join_curves(a_curve1, a_curve2,cut = True)\n",
    "    new = join_curves(new, a_curve3,cut = True)\n",
    "    new = join_curves(new, a_curve4,cut = True)\n",
    "    # join the two ends together to make a complete circle\n",
    "    complete_average = join_make_full_circle(new)\n",
    "\n",
    "    #interpolate to make standardspace:\n",
    "    standard_av_curve = resample_curve(complete_average, num_points = 10000)\n",
    "\n",
    "    # shift the start point of the curve so that is the first time the mous eleaves port 5 radius\n",
    "    standard_av_curve = shift_curve_start(standard_av_curve,port_centroids[-1])\n",
    "\n",
    "    # plot this stuff to check it looks okay\n",
    "    plot_av_and_new_standard_line(complete_average,standard_av_curve,radius_used,port_centroids)\n",
    "\n",
    "    # load in the seq colours \n",
    "    seq_colours = np.load(all_mice_dict[mouse]['awake_path']+ r'/analysis_output/reordered_recolored/colors',allow_pickle=True)\n",
    "\n",
    "    ##### FIND THE MOTIF REGIONS - #################################\n",
    "    # find all the examples of each motif \n",
    "    ################################################################\n",
    "\n",
    "    # next define the regions of each motif \n",
    "    motif_start_ends_df = find_motif_points(continuous_regions_df,standard_av_curve,port_centroids,seq_colours,radius_used,num_intermediate_points=50)\n",
    "\n",
    "    #convert to xy coords\n",
    "    full_tracking_coords = []\n",
    "    for ind_,item in enumerate(current_x):\n",
    "        full_tracking_coords += [[item,current_y[ind_]]]\n",
    "\n",
    "    # now take these start and end points of each motif to find all motif examples:\n",
    "    motif_start_ends = []\n",
    "    for i in range(len(motif_start_ends_df)):\n",
    "\n",
    "        points = []\n",
    "        for column in list(motif_start_ends_df):\n",
    "            row = motif_start_ends_df[(f'{column}')][i]\n",
    "            points += [row]\n",
    "            \n",
    "        centroid_distance_threshold = 1000000  # You need to set an appropriate threshold based on your data.\n",
    "        radius_threshold = 30\n",
    "        similar_segments = find_similar_segments(full_tracking_coords, points, centroid_distance_threshold,radius_threshold)\n",
    "        ## each of these is a frame so we know the timing between them. ie. one frame is 1/60s \n",
    "        time_filter = 6 #in s\n",
    "        # minimum distance from start/end centroid\n",
    "        dist_filter = 60\n",
    "        # number of closest points to start/end centroid to find and chose from\n",
    "        num_points = 3\n",
    "        # number of points to add to the start and end of the trajectory\n",
    "        add_start_end = 5\n",
    "        valid_trajectories = process_and_validate_trajectories(full_tracking_coords, similar_segments, points,add_start_end,int(time_filter / (1/fps)),dist_filter,num_points)\n",
    "\n",
    "        # then remove any duplicates:\n",
    "        valid_trajectories_filtered = remove_overlaps(valid_trajectories)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1,figsize=(6, 4))\n",
    "        for index,port_centroid in enumerate(port_centroids):\n",
    "            circle1 = plt.Circle(port_centroid, 45, color='grey', alpha = 1)\n",
    "            ax.add_patch(circle1)\n",
    "\n",
    "        trajects = []\n",
    "        for ind in valid_trajectories_filtered:\n",
    "            traject = full_tracking_coords[ind[0]:ind[1]]\n",
    "            trajects += [traject]\n",
    "            x = [point[0] for point in traject]\n",
    "            y = [point[1] for point in traject]\n",
    "            ax.plot(x,y,'-', color = 'blue', alpha = 0.2)\n",
    "            ax.plot(x[0],y[0],'o', color = 'yellow', alpha = 0.2)\n",
    "            ax.plot(x[-1],y[-1],'o', color = 'yellow', alpha = 0.2)\n",
    "\n",
    "        x = [point[0] for point in points]\n",
    "        y = [point[1] for point in points]\n",
    "        ax.plot(x,y,'-', color = 'red', alpha = 1)\n",
    "\n",
    "        av_of_found = interpolate_to_longest_and_find_average_curve(trajects,500)\n",
    "        x = [point[0] for point in av_of_found]\n",
    "        y = [point[1] for point in av_of_found]\n",
    "        ax.plot(x,y,'-', color = 'k', alpha = 1)\n",
    "            \n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        print(len(valid_trajectories_filtered))\n",
    "        \n",
    "        motif_start_ends += [valid_trajectories_filtered]\n",
    "\n",
    "    ##### 1 FIND THE MOVEMENT VARIABILITY FOR EACH MOTIF - \n",
    "    # using two different methods, h distance and dtw\n",
    "    #############################################################################################\n",
    "\n",
    "    # needs to be large to make the h distance calcualtions accurate\n",
    "    motif_start_ends_df_large = find_motif_points(continuous_regions_df,standard_av_curve,port_centroids,seq_colours,radius_used,num_intermediate_points=10000)\n",
    "    plt.close()\n",
    "    # slightly smaller to save computational power when doing dtw\n",
    "    motif_start_ends_df_medium = find_motif_points(continuous_regions_df,standard_av_curve,port_centroids,seq_colours,radius_used,num_intermediate_points=300)\n",
    "    plt.close()\n",
    "\n",
    "    motif_dists = []\n",
    "    motif_std_dists = []\n",
    "    motif_median_dtws = []\n",
    "    motif_std_dtws = []\n",
    "    for i in tqdm(range(len(motif_start_ends_df_large))):\n",
    "\n",
    "        points = []\n",
    "        for column in list(motif_start_ends_df_large):\n",
    "            row = motif_start_ends_df_large[(f'{column}')][i]\n",
    "            points += [row]\n",
    "            \n",
    "        points2 = []\n",
    "        for column in list(motif_start_ends_df_medium):\n",
    "            row = motif_start_ends_df_medium[(f'{column}')][i]\n",
    "            points2 += [row]\n",
    "\n",
    "        motif_ranges = motif_start_ends[i]\n",
    "        median_distances = []\n",
    "        std_distances = []\n",
    "        dtws = []\n",
    "        for start, end in motif_ranges:\n",
    "            segment = full_tracking_coords[start:end]\n",
    "            \n",
    "            \"\"\" \n",
    "            a simplified version of the Hausdorff distance\n",
    "            \"\" Measures the greatest distance between any point on one trajectory to the closest point on the other.\n",
    "            determine deviation from average\n",
    "            - for each tracking point in each trajectory find the point on the relevant interpolated average line which it is closest to\n",
    "            - this gives us a list of distances (deviations) from the average for each trajectory line\n",
    "            - this can be used to find the standard devation of the average distance from the average line.\n",
    "            - this gives us a meausre of how steretyped the port-port trjectories were:\n",
    "            - stereotyped = similar to average line = smaller devation\n",
    "            - not stereotyped = different to average line = larger devation \"\"\n",
    "            \"\"\" \n",
    "            distances = closest_points_distances(segment, points)\n",
    "            median_distances.append(np.median(distances))\n",
    "            std_distances.append(np.std(distances))\n",
    "            \n",
    "            \"\"\"\n",
    "            dynamic time warping distance \n",
    "            WHAT IS THE DTW NUMBER:\n",
    "            here i take the mean , so the number represents, trajectories, when optimally aligned to teh average line, the mean amount by which they deviate in total (here in mm). This doesn't necessarily mean each corresponding point deviates that many mm—\n",
    "            it's the total sum of all point-to-point deviations, which can vary depending on the trajectory.\n",
    "            eg. \"The Dynamic Time Warping (DTW) distance between the two trajectories was xx mm, representing the total accumulated deviation over the entire alignment.\"\n",
    "            I calculate the dwt normalised to length of the trajectory\n",
    "            \"\"\"\n",
    "            dtws += [normalized_dtw(segment, points2)]\n",
    "            \n",
    "                    \n",
    "        # for h distance \n",
    "        motif_dists.append(median_distances)\n",
    "        motif_std_dists.append(std_distances)\n",
    "        # for dtw\n",
    "        motif_median_dtws.append(np.nanmean(dtws))\n",
    "        motif_std_dtws.append(np.std(dtws))\n",
    "\n",
    "    # put the data into vars\n",
    "    all_motif_mean_dists = [np.nanmean(dist) for dist in motif_dists]\n",
    "    all_motif_std_dists = [np.nanmean(std_dist) for std_dist in motif_std_dists]\n",
    "\n",
    "\n",
    "    ## convert to cm, we know distance bwteen two ports should be 3cm apart\n",
    "    port_pairs = [0,1],[0,3],[2,4],[0,2],[3,4]\n",
    "    ptp_distances = []\n",
    "    for pair in port_pairs:\n",
    "        ptp_distances += [math.sqrt((port_centroids[pair[0]][0] - port_centroids[pair[1]][0])**2 + (port_centroids[pair[0]][-1] - port_centroids[pair[1]][-1])**2)]\n",
    "    _1_mm = (np.nanmean(ptp_distances)/3)/10 \n",
    "\n",
    "    all_motif_mean_dists_mm = np.array(all_motif_mean_dists)/_1_mm\n",
    "    all_motif_std_dists_mm = np.array(all_motif_std_dists)/_1_mm\n",
    "\n",
    "    all_motif_mean_dtws_mm = np.array(motif_median_dtws)/_1_mm\n",
    "    all_motif_std_dtws_mm = np.array(motif_std_dtws)/_1_mm\n",
    "        \n",
    "\n",
    "    ### 2 FIND VARIANCE IN TIME TAKEN TO DO EACH MOTIF - also average movement speed\n",
    "    #############################################################################################\n",
    "\n",
    "    # average speed - distance over time\n",
    "    # speed variability, \n",
    "\n",
    "    all_motif_mean_speed_mm_s = []\n",
    "    all_motif_mean_std_speed_mm_s = []\n",
    "    for motif_ranges in motif_start_ends:\n",
    "        segments = []\n",
    "        for start, end in motif_ranges:\n",
    "            segments += [full_tracking_coords[start:end]]\n",
    "        # Calculate average speeds and speed variability\n",
    "        speed_std,speed_mean = calculate_speed_variability(segments, _1_mm, fps)\n",
    "\n",
    "        all_motif_mean_speed_mm_s += [speed_mean]\n",
    "        all_motif_mean_std_speed_mm_s += [speed_std]\n",
    "   \n",
    "   \n",
    "    ###################################################################\n",
    "    #GENERAL BEHAVIOURAL/TASK FEATURES\n",
    "    ###################################################################\n",
    "\n",
    "    # ########### 9 training level change in that session   \n",
    "    # t_level_change = max(behav_sync_df['TrainingLevel']) - min(behav_sync_df['TrainingLevel'])\n",
    "\n",
    "    ########### 3 relative proportion expressed. (was a sequence done more often by the mouse)\n",
    "    absolute_total_seqs  = []\n",
    "    for seq_id in seq_order:\n",
    "        absolute_total_seqs += [len(seq_events_dict[str(seq_id+1)])]\n",
    "    # sequence_expression_proportion = np.array(total_seqs)/sum(total_seqs)\n",
    "\n",
    "    ########### 11.+ 12. average distance (seconds) to next reward and proportion linked to reward. \n",
    "    # remove the nans from the reward column \n",
    "    reward_times = behav_sync_df.dropna(subset=['Reward_Times']).Reward_Times.values\n",
    "\n",
    "    # calcuate the ephys behaviour offset\n",
    "    ephys_behaviour_offset = behav_sync_df['FirstPoke_EphysTime'][0] - behav_sync_df['PokeIn_Time'][0]\n",
    "    mean_dist_to_reward = []\n",
    "    proportion_close_to_reward = []\n",
    "    for seq_id in seq_order:\n",
    "        current_seq = str(seq_id+1)\n",
    "        seq_events_dict[current_seq]\n",
    "        \n",
    "        dist_next_reward = []\n",
    "        for i in range(len(seq_events_dict[current_seq])):\n",
    "            # in ephys time\n",
    "            event_start_ephys = min(seq_events_dict[current_seq][i].timestamp) + awake_time_span[0]\n",
    "            event_end_ephys = max(seq_events_dict[current_seq][i].timestamp) + awake_time_span[0]\n",
    "            # in bpod time\n",
    "            event_start_bpod_time = event_start_ephys - ephys_behaviour_offset\n",
    "            event_end_bpod_time = event_end_ephys - ephys_behaviour_offset\n",
    "            \n",
    "            dist_next_reward += [distance_to_next_reward(event_start_bpod_time, event_end_bpod_time, reward_times)]\n",
    "        #remove extreme values\n",
    "        dist_next_reward_extremes_removed = [item for item in dist_next_reward if item is not None and item < 30]\n",
    "        mean_dist_to_reward += [np.nanmean(dist_next_reward_extremes_removed)]\n",
    "        proportion_close_to_reward += [len([item for item in dist_next_reward if item is not None and item < 3])/len(dist_next_reward)]\n",
    "        \n",
    "    ############## 13. motif error rate (take the closest two ports and see what the error rate was there?)  \n",
    "    ###################################\n",
    "    # find the closest two ports for each sequence type and then calculate the error rate\n",
    "\n",
    "    # define 'port' positions on the average curve, ie. the closest point on the trajectory to each port...when the mouse would have poked its nose \n",
    "    visited_ports_locations,visited_ports_prcnt = associate_ports_with_curve(standard_av_curve,port_centroids)\n",
    "\n",
    "    ## plot this for good measure\n",
    "    fig, ax = plt.subplots(1, 1,figsize=(6, 4))\n",
    "    for index,port_centroid in enumerate(port_centroids):\n",
    "        circle1 = plt.Circle(port_centroid, 45, color='grey', alpha = 1)\n",
    "        ax.add_patch(circle1)\n",
    "    x = [point[0] for point in standard_av_curve]\n",
    "    y = [point[1] for point in standard_av_curve]\n",
    "    ax.plot(x,y,'-', color = 'red', alpha = 0.3)\n",
    "    for i, point in enumerate(visited_ports_locations):\n",
    "        ax.plot(point[0], point[1], 'o',c = 'yellow', markersize=20)\n",
    "        ax.text(point[0]-4, point[1]+4, str(i), fontsize=12)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # find port-port transitions that best represent the sequence \n",
    "    seq_regions = [[continuous_regions_df.start[i],continuous_regions_df.end[i]] for i in range(len(continuous_regions_df))]\n",
    "    enclosing_ports = find_best_ports(seq_regions, visited_ports_prcnt)\n",
    "\n",
    "\n",
    "    ## find the transition errors \n",
    "    transitions = []\n",
    "    for i in range(1,len(behav_sync_df.Port.values)):\n",
    "        transit_time = behav_sync_df.PokeOut_Time.values[i] - behav_sync_df.PokeIn_Time.values[i-1]\n",
    "        if transit_time < 2:\n",
    "            transitions += [[behav_sync_df.Port.values[i-1],behav_sync_df.Port.values[i]]]\n",
    "        else:\n",
    "            transitions += [['pause']]\n",
    "\n",
    "    error_rate_by_motif = []      \n",
    "    for seq_ports in enclosing_ports:\n",
    "        transit_goal = port_transitions(seq_ports[0], seq_ports[1])\n",
    "\n",
    "        transit_goal_in_port_nums = np.array([2,1,6,3,7])[np.array(transit_goal)]\n",
    "        results = compute_transition_accuracy(transitions, transit_goal_in_port_nums)\n",
    "        error_rate_by_motif += [np.nanmean([results[item]['pct_error'] for item in results])]\n",
    "        \n",
    "        \n",
    "#####################################\n",
    "## SAVE THE DATA AND FIGURES\n",
    "##################################### \n",
    "\n",
    "tracking_output_df = pd.DataFrame({\n",
    "    \"mouse_id\": [mouse]*len(continuous_regions_df.sequence.values),\n",
    "    \"sequence_motif\" : continuous_regions_df.sequence.values+1,\n",
    "    \n",
    "    \"mean_h_distance_from_av_mm_per_motif\": all_motif_mean_dists_mm,\n",
    "    \"mean_dtw_distance_from_av_mm_per_motif\":all_motif_mean_dtws_mm,\n",
    "    \"mean_movement_speed_mm_s_per_motif\": all_motif_mean_speed_mm_s,\n",
    "    \n",
    "    \"av_distance_to_next_reward_per_motif\":mean_dist_to_reward,\n",
    "    \"proportion_of_sequences_linked_to_reward_per_motif\":proportion_close_to_reward,\n",
    "    \"error_rate_per_motif\": error_rate_by_motif,\n",
    "})\n",
    "\n",
    "\n",
    "out_path = r\"Z:\\projects\\sequence_squad\\revision_data\\emmett_revisions\\sleep_wake_link_data\\behaviour_to_replay\\processed_data\\\\\"\n",
    "## save data somewhere  \n",
    "full_out_path = os.path.join(out_path+mouse,'behaviour')\n",
    "if not os.path.isdir(full_out_path):\n",
    "    os.makedirs(full_out_path)\n",
    "tracking_output_df.to_csv(full_out_path + r'/processed_behavioural_features.csv',index=False)\n",
    "    \n",
    "# Save all figures  \n",
    "save_all_figs(full_out_path + mouse + r\".png\")\n",
    "plt.close('all')\n",
    "\n",
    "print('done')\n",
    "\n",
    "print('____________________________________________________________________________________________________')\n",
    "print('____________________________________________________________________________________________________')   \n",
    "print(f\"\\033[1m DATA SAVED FOR {mouse}\\033[0m\")\n",
    "print('____________________________________________________________________________________________________')\n",
    "print('____________________________________________________________________________________________________')   \n",
    "\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8f86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d933e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc46e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5a1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f23c7931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['136_1_3',\n",
       " '136_1_4',\n",
       " '148_2_2',\n",
       " '149_1_1',\n",
       " '178_1_4',\n",
       " '178_1_5',\n",
       " '178_1_6',\n",
       " '178_1_7',\n",
       " '178_1_8',\n",
       " '178_1_9',\n",
       " '178_2_1',\n",
       " '178_2_2',\n",
       " '178_2_4',\n",
       " '269_1_1',\n",
       " '269_1_3',\n",
       " '269_1_4',\n",
       " '269_1_7',\n",
       " '270_1_3',\n",
       " '270_1_5',\n",
       " '270_1_6',\n",
       " 'seq006_1_11',\n",
       " '268_1_2',\n",
       " '269_1_2',\n",
       " '270_1_1',\n",
       " 'ap5R_1_1',\n",
       " 'ap5R_1_3',\n",
       " 'seq006_1_1',\n",
       " 'seq006_1_4',\n",
       " 'seq006_1_5',\n",
       " 'seq006_1_6',\n",
       " 'seq007_1_1',\n",
       " 'seq007_1_2',\n",
       " 'seq007_1_3',\n",
       " 'ap5R_1_2',\n",
       " 'seq006_1_10',\n",
       " 'seq006_1_3',\n",
       " 'seq006_1_8',\n",
       " 'seq006_1_9']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_mice_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ebfde",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
