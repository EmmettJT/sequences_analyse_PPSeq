{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf563236",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/ceph/sjones/projects/sequence_squad/organised_data/animals//'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 114\u001b[0m\n\u001b[0;32m    109\u001b[0m dat_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ceph/sjones/projects/sequence_squad/organised_data/ppseq_data/output_data/striatum/New_Post_sleep//\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# current_mouse  = '178_2_1'\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# list out all possible datapaths\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m data_paths \u001b[38;5;241m=\u001b[39m \u001b[43mlist_all_datapaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m data_paths:\n\u001b[0;32m    117\u001b[0m \n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m#     print(path)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     a \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m::]\n",
      "Cell \u001b[1;32mIn[2], line 99\u001b[0m, in \u001b[0;36mlist_all_datapaths\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_all_datapaths\u001b[39m(data_path):\n\u001b[0;32m     98\u001b[0m     data_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEJT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m]:\n\u001b[0;32m    101\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m file_ \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path\u001b[38;5;241m+\u001b[39mfile):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/ceph/sjones/projects/sequence_squad/organised_data/animals//'"
     ]
    }
   ],
   "source": [
    "from open_ephys.analysis import Session\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def AlignToTriggersAndFIndEphysTimestamps(Port_intimes,trial_id,first_poke_times,trial_start,TrialStart_EphysTime,FirstPoke_EphysTime):\n",
    "\n",
    "    new_TS = []\n",
    "    for index, trial in enumerate(trial_id):\n",
    "        if np.isnan(Port_intimes[index]):\n",
    "            new_TS = new_TS + [np.nan]\n",
    "        else:\n",
    "            current_poke_event_time = Port_intimes[index]\n",
    "\n",
    "            # find ech relevant timestamps\n",
    "            CurrentTrial_startTS = trial_start[trial-1]\n",
    "            First_pokeTS = first_poke_times[trial-1]\n",
    "\n",
    "            # last trial has no next trial start\n",
    "            if trial == trial_id[-1]:\n",
    "                NextTrial_startTS = 9999999999999\n",
    "            else:\n",
    "                NextTrial_startTS = np.unique(trial_start)[trial]\n",
    "\n",
    "            # find the ts current poke event is closest to\n",
    "            trialstart_diff =  abs(CurrentTrial_startTS - current_poke_event_time)\n",
    "\n",
    "            EphysTS = TrialStart_EphysTime[trial-1]\n",
    "            current_dist = current_poke_event_time - CurrentTrial_startTS\n",
    "            distance = EphysTS + current_dist\n",
    "\n",
    "\n",
    "\n",
    "            new_TS = new_TS + [distance]\n",
    "\n",
    "    return(new_TS)\n",
    "\n",
    "\n",
    "def align_open_ephys_processors(main_processor_tuple, aux_processor_tuples, session_path=None, synch_channel=1):\n",
    "\n",
    "    session_data = Session(str(session_path))\n",
    "    if len(session_data.recordnodes) != 1:\n",
    "        raise ValueError(\"should be exactly one record node.\")\n",
    "    if len(session_data.recordnodes[0].recordings) != 1:\n",
    "        raise ValueError(\"Should be exactly one recording.\")\n",
    "\n",
    "    for rn, recordnode in enumerate(session_data.recordnodes):\n",
    "        for r, recording in enumerate(recordnode.recordings):\n",
    "            # Synch\n",
    "            recording.add_sync_line(\n",
    "                synch_channel,\n",
    "                main_processor_tuple[0],\n",
    "                main_processor_tuple[1],\n",
    "                main=True,\n",
    "            )\n",
    "            for aux_processor in aux_processor_tuples:\n",
    "                recording.add_sync_line(\n",
    "                    synch_channel,\n",
    "                    aux_processor[0],\n",
    "                    aux_processor[1],\n",
    "                    main=False,\n",
    "                )\n",
    "            print('this should be zero:')\n",
    "            print(rn)\n",
    "\n",
    "    return recording\n",
    "\n",
    "def find_files(filename, search_path):\n",
    "    result = []\n",
    "\n",
    "    #Walking top-down from the root\n",
    "    for root, dir, files in os.walk(search_path):\n",
    "        if filename in files:\n",
    "            result.append(os.path.join(root, filename))\n",
    "\n",
    "    return result\n",
    "\n",
    "def sequence_contains_sequence(haystack_seq, needle_seq, string):\n",
    "    start_index = []\n",
    "    for i in range(0, len(haystack_seq) - len(needle_seq) + 1):\n",
    "        if needle_seq == haystack_seq[i:i+len(needle_seq)]:\n",
    "            start_index = start_index + [i]\n",
    "            print(string + ' barcode found')\n",
    "    return start_index\n",
    "\n",
    "def find_folder_path(parent_folder, target_folder):\n",
    "    for root, dirs, files in os.walk(parent_folder):\n",
    "        if target_folder in dirs:\n",
    "            return os.path.join(root, target_folder)\n",
    "        # If the target folder is not found\n",
    "    return (print('not found'))\n",
    "\n",
    "def list_all_datapaths(data_path):\n",
    "    data_paths = []\n",
    "    for file in os.listdir(data_path):\n",
    "        if 'EJT' in file[0:5]:\n",
    "            for file_ in os.listdir(data_path+file):\n",
    "                if 'record' in file_:\n",
    "                    data_paths += [data_path+file+'//'+file_]\n",
    "    return data_paths\n",
    "\n",
    "# define paths:\n",
    "\n",
    "data_path = r'/ceph/sjones/projects/sequence_squad/organised_data/animals//'\n",
    "dat_path = r\"/ceph/sjones/projects/sequence_squad/organised_data/ppseq_data/output_data/striatum/New_Post_sleep//\"\n",
    "\n",
    "# current_mouse  = '178_2_1'\n",
    "\n",
    "# list out all possible datapaths\n",
    "data_paths = list_all_datapaths(data_path)\n",
    "\n",
    "for path in data_paths:\n",
    "\n",
    "#     print(path)\n",
    "\n",
    "    a = path.split('//')[-2].split('_')[0][3::]\n",
    "    b = path.split('//')[-2][-1]\n",
    "    c = path.split('//')[-1].split('_')[0][-1]\n",
    "    current_mouse = '_'.join([a,b,c])\n",
    "\n",
    "    for path_ in data_paths:\n",
    "\n",
    "        mir = path_.split('//')[-2].split('_')[0][3::] + '_' +  path_.split('//')[-2].split('_')[1][-1] + '_' + path_.split('//')[-1].split('_')[0][-1]\n",
    "        if mir == current_mouse:\n",
    "            print(mir)\n",
    "            recording_date = path_.split('//')[-1].split('_')[-1]\n",
    "            org_data_path = path_\n",
    "\n",
    "    print(org_data_path)\n",
    "\n",
    "\n",
    "### find OE processor path and OE_raw_path\n",
    "    OE_processor_path_base = r\"/ceph/sjones/projects/sequence_squad/data/raw_neuropixel/OE_DATA//\"\n",
    "\n",
    "    compress_date = ''.join(recording_date.split('-')[0:2]) + recording_date.split('-')[-1][-2::]\n",
    "\n",
    "    mouse_name = 'EJT' + current_mouse.split('_')[0]\n",
    "    if current_mouse.split('_')[1] == '2':\n",
    "        mouse_name = mouse_name + '_implant2'\n",
    "\n",
    "    current_path = os.path.join(OE_processor_path_base + mouse_name, compress_date) + '//'\n",
    "\n",
    "    OE_processor_path = glob.glob(os.path.join(current_path, '**', 'continuous'), recursive=True)[0]\n",
    "    OE_raw_path = '//'.join(OE_processor_path.split('//')[0:10]) + '//'\n",
    "\n",
    "    print(OE_processor_path)\n",
    "    print(os.listdir(OE_processor_path))\n",
    "\n",
    "    ### histology path\n",
    "    hist_path_base = r\"/ceph/sjones/projects/sequence_squad/data/histology/Neuropixel_tracks//\"\n",
    "\n",
    "    for item in os.listdir(hist_path_base):\n",
    "        if mouse_name.split('_')[0] in item:\n",
    "            mouse_name_ = item\n",
    "\n",
    "    hist_path = os.path.join((hist_path_base + mouse_name_),\"brainreg//\")\n",
    "    hist_path = glob.glob(os.path.join(hist_path, '**','tracks'),recursive = True)[0]\n",
    "\n",
    "    implant_files = []\n",
    "    for item in os.listdir(hist_path):\n",
    "        if 'csv' in item:\n",
    "            implant_files+=[item]\n",
    "\n",
    "    if len(implant_files) > 1:\n",
    "        for file in implant_files:\n",
    "            if current_mouse.split('_')[-2] in file:\n",
    "                implant_file = file\n",
    "    else:\n",
    "        implant_file = implant_files[0]\n",
    "\n",
    "    probe_track_file = os.path.join(hist_path,implant_file)\n",
    "    print(probe_track_file)\n",
    "\n",
    "    ######################### get processors\n",
    "    #sample rate:\n",
    "    Fs = 2500\n",
    "\n",
    "\n",
    "    implant_df = pd.read_csv(probe_track_file)\n",
    "\n",
    "    import re\n",
    "    count = 0\n",
    "    for processor in os.listdir(OE_processor_path):\n",
    "        if count == 0:\n",
    "            main1 = int(re.findall(r'\\d+', processor)[0])\n",
    "            main1_2 = processor.split('.')[-1]\n",
    "        elif count == 1:\n",
    "            main2 = int(re.findall(r'\\d+', processor)[0])\n",
    "            main2_2 = processor.split('.')[-1]\n",
    "        elif count == 2:\n",
    "            main3 = int(re.findall(r'\\d+', processor)[0])\n",
    "            main3_2 = processor.split('.')[-1]\n",
    "        count +=1\n",
    "\n",
    "    main_processor_tuple=(main1, main1_2)\n",
    "\n",
    "    aux_processor_tuples=((main2,main2_2),(main3,main3_2))\n",
    "\n",
    "    break\n",
    "    ############ DONT RUN MORE THAN ONCE! ITS SO SLOW! ######################\n",
    "\n",
    "    ### LOAD in data: this could take a few minutes\n",
    "    recording = align_open_ephys_processors(main_processor_tuple,aux_processor_tuples,OE_raw_path)\n",
    "    recording.compute_global_timestamps()\n",
    "\n",
    "    ############ DONT RUN MORE THAN ONCE! ITS SO SLOW! ######################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##### extract channels\n",
    "\n",
    "    data = recording.continuous[1].samples\n",
    "\n",
    "    if int(current_mouse.split('_')[0]) > 250:\n",
    "        timestamps = recording.continuous[1].timestamps\n",
    "    else:\n",
    "        timestamps = np.load(OE_processor_path + '//' + 'Neuropix-PXI-' + str(aux_processor_tuples[0][0]) + '.' + str(aux_processor_tuples[0][1]) + '//' + 'synchronized_timestamps.npy')\n",
    "\n",
    "    ## chose 6 channels: #\n",
    "    channels = [50,100,150,200,250,300,350]\n",
    "\n",
    "    ### add in region info based on depth:\n",
    "    try:\n",
    "        callosum_middle_index = int(np.median(np.where(implant_df['Region acronym'].values == 'ccb')))\n",
    "    except:\n",
    "        callosum_middle_index = int(np.median(np.where(implant_df['Region acronym'].values == 'ccg')))\n",
    "\n",
    "    proportion_in_motor_cortex = (callosum_middle_index/len(implant_df))\n",
    "    # there should be 400 channels per 4000um\n",
    "    # tot_channels = 384\n",
    "    # bank_spacing = 20 # 20um\n",
    "    # channels_per_bank = 2\n",
    "    first_cortex_channel = int(proportion_in_motor_cortex * 400)\n",
    "\n",
    "    # save out data:\n",
    "    timestamps_s = timestamps/2500\n",
    "    timestamps_s_offset_adjusted = timestamps_s - timestamps_s[0]\n",
    "\n",
    "    channel_regions = []\n",
    "    for channel in channels:\n",
    "        if channel > first_cortex_channel:\n",
    "            channel_regions.append('m_crtex')\n",
    "        elif channel < first_cortex_channel:\n",
    "            channel_regions.append('striatum')\n",
    "\n",
    "    # save timestamp data\n",
    "    save_file_path = org_data_path + r\"/ephys/LFP/\"\n",
    "    if not os.path.isdir(save_file_path):\n",
    "        os.makedirs(save_file_path)\n",
    "\n",
    "    np.save(save_file_path+ 'LFP_timestamps.npy',timestamps_s)\n",
    "    np.save(save_file_path+ 'aligned_LFP_timestamps.npy',timestamps_s_offset_adjusted)\n",
    "\n",
    "    ## free up memory\n",
    "    del timestamps_s\n",
    "    del timestamps_s_offset_adjusted\n",
    "\n",
    "\n",
    "\n",
    "    #### add in region info and extract data into useable format\n",
    "\n",
    "    ### add in region info based on depth:\n",
    "    for chosen_channel in channels:\n",
    "        data_channel = []\n",
    "        chunk_size = 2000 # adjust this value to balance speed and memory usage\n",
    "        for i in tqdm(range(0, len(data), chunk_size)):\n",
    "            chunk = [data[j][chosen_channel] for j in range(i, min(i+chunk_size, len(data)))]\n",
    "            data_channel += chunk\n",
    "\n",
    "        if chosen_channel > first_cortex_channel:\n",
    "            data_region = 'm-crtx'\n",
    "        elif chosen_channel < first_cortex_channel:\n",
    "            data_region = 'striatum'\n",
    "\n",
    "        save_path = save_file_path + 'channel-' + str(chosen_channel) + '_REGION-' + data_region + \"_LFP_data.npy\"\n",
    "\n",
    "        np.save(save_path,data_channel)\n",
    "        print('data saved for channel ' + str(chosen_channel))\n",
    "        # clean up for memory\n",
    "        del data_channel\n",
    "\n",
    "    print('done')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1eb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = \"Z:\\projects\\sequence_squad\\data\\raw_neuropixel\\OE_DATA\\EJT262\\180523\\2023-05-18_11-26-01\\Record Node 113\\experiment1\\recording2\\continuous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55084a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = align_open_ephys_processors(main_processor_tuple,aux_processor_tuples,OE_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d67029f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
